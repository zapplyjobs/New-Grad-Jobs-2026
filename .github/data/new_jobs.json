[
  {
    "job_title": "Product Operations Manager",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4971429008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: We're hiring several Product Operations Managers to work directly with our Product and Engineering teams to build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities. The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way. The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product processes. They should be passionate about creating scalable systems that help Product teams better understand users, make data-driven decisions, execute efficiently, and deliver exceptional products. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization's effectiveness. Responsibilities: Inputs to Product Teams – Ensuring product teams have the information they need to make great decisions Voice of customer synthesis and feedback routing from strategic to tactical Create high-leverage engagement points with partners throughout the product lifecycle Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems Streamline the most important decision points for teams and impacted partners Ops of the Product Org – Creating the operating systems that enable product teams to thrive Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc) Create reliable run-of-business systems across product Improve common product development processes and tooling Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams Outputs from Product Teams – Amplifying product impact by connecting what we build to those who need it Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products Maintain launch motions that allow us to ship with confidence and monitor impact Create cross-team roadmap visibility that drives cross-functional alignment Make clear to all of Anthropic what Product is working on and how it's going You may be a good fit if you have: 5+ years of experience in product operations, program management, or related operational roles in tech companies Track record of building processes and programs from 0 to 1 and scaling them thoughtfully Experience working deeply embedded with product teams, serving as an extension of product leadership Strong cross-functional partnership skills with ability to influence without authority Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments Experience with launch coordination, early access programs, or customer feedback loops A passion for iterative, user-driven product development Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists. Mission-aligned with building safe and beneficial AI systems The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$165,000 - $190,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4971429008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4971429008",
    "title": "Product Operations Manager",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4971429008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;We&#39;re hiring several Product Operations Managers to work directly with our Product and Engineering teams to build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will &amp;nbsp;work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way.&lt;/p&gt;\n&lt;p&gt;The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product processes. They should be passionate about creating scalable systems that help Product teams better understand users, make data-driven decisions, execute efficiently, and deliver exceptional products. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization&#39;s effectiveness.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Inputs to Product Teams&lt;/strong&gt; – Ensuring product teams have the information they need to make great decisions&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Voice of customer synthesis and feedback routing from strategic to tactical&lt;/li&gt;\n&lt;li&gt;Create high-leverage engagement points with partners throughout the product lifecycle&lt;/li&gt;\n&lt;li&gt;Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses&lt;/li&gt;\n&lt;li&gt;Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems&lt;/li&gt;\n&lt;li&gt;Streamline the most important decision points for teams and impacted partners&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Ops of the Product Org&lt;/strong&gt; – Creating the operating systems that enable product teams to thrive&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc)&lt;/li&gt;\n&lt;li&gt;Create reliable run-of-business systems across product&lt;/li&gt;\n&lt;li&gt;Improve common product development processes and tooling&lt;/li&gt;\n&lt;li&gt;Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Outputs from Product Teams&lt;/strong&gt; – Amplifying product impact by connecting what we build to those who need it&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products&lt;/li&gt;\n&lt;li&gt;Maintain launch motions that allow us to ship with confidence and monitor impact&lt;/li&gt;\n&lt;li&gt;Create cross-team roadmap visibility that drives cross-functional alignment&lt;/li&gt;\n&lt;li&gt;Make clear to all of Anthropic what Product is working on and how it&#39;s going&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in product operations, program management, or related operational roles in tech companies&lt;/li&gt;\n&lt;li&gt;Track record of building processes and programs from 0 to 1 and scaling them thoughtfully&lt;/li&gt;\n&lt;li&gt;Experience working deeply embedded with product teams, serving as an extension of product leadership&lt;/li&gt;\n&lt;li&gt;Strong cross-functional partnership skills with ability to influence without authority&lt;/li&gt;\n&lt;li&gt;Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations&lt;/li&gt;\n&lt;li&gt;Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments&lt;/li&gt;\n&lt;li&gt;Experience with launch coordination, early access programs, or customer feedback loops&lt;/li&gt;\n&lt;li&gt;A passion for iterative, user-driven product development&lt;/li&gt;\n&lt;li&gt;Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists.&lt;/li&gt;\n&lt;li&gt;Mission-aligned with building safe and beneficial AI systems&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$165,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$190,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4971429008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Operations Manager, Launch Readiness ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4978674008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: We're hiring a Product Operations Manager - Launch Readiness to own and continuously improve how Anthropic launches products. This is a product-wide, horizontal role that will establish the operating system for all customer-facing launches across our portfolio. Launching at Anthropic is uniquely dynamic. We're building on frontier models that evolve constantly, serving customers from individual developers to the largest enterprises, across multiple surfaces (API, claude.ai, Claude Code). This role will coordinate launches across Product teams and critical partners including Security, Legal, GTM, Finance, DevRel, and Safety. You'll establish common language, document repeatable launch motions, and build an AI-native toolkit that makes excellent launches feel effortless. You treat launch readiness as a product. You're obsessed with making the \"happy path\" so helpful that teams obviously want to follow it. You build systems that accelerate product velocity, never gate it. You treat launch readiness as a product. You’re obsessed with making the “happy path” so helpful that teams obviously want to follow it. You build systems that accelerate product velocity, not gate it. You think like a product manager, not a compliance officer. Your work will directly impact every customer-facing launch at Anthropic, making them faster, safer, and better coordinated.ct manager, not a compliance officer. Your work will directly impact every customer-facing launch at Anthropic, making them faster, safer, and more coordinated. Responsibilities: You’ll own the operating system for customer-facing product launches at Anthropic. Working horizontally across Product teams and critical partners—including Security, Legal, GTM, Finance, DevRel, and Safety—you’ll establish frameworks, toolkits, and processes that enable teams to ship with confidence. You’ll drive adoption through influence, making launch readiness effortless and creating visibility across all launches. Launch calendar & system of record Own our launch calendar as the source of truth for all customer-facing launches. Create visibility and predictability across Product and XFN teams. Build workflows that reinforce our central system of record without becoming a documentation tax. Integrate with team operating rhythms and obsess over the user experience of our internal tools. Repeatable Launch Processes Document and iterate on “happy path” launch processes across the launch lifecycle. Establish common language and conventions that work across diverse launch types. Cross-Functional Coordination Partner with Security, Legal, GTM, Finance, DevRel, and other XFN teams to define clear engagement models. These “APIs between teams” make coordination seamless and reliable. Enable the right teams to engage with the right projects at the right time. Create a federated operating model that gives teams autonomy while maintaining common standards. AI-Native Launch Toolkit Build Claude-powered assistants and automation to streamline launch workflows. Experiment with ambient intelligence to pull information from across the org. Automate intake workflows, documentation generation, and status tracking. Partner with Engineering on tooling strategy and integrations. Continuous Improvement Define and track success metrics for Define and track success metrics for launch excellence to identify bottlenecks through data and feedback.launch excellence in order to identify bottlenecks through data and feedback. Run post-launch retros and feed learnings back into process improvements. Scale best practices across teams through documentation and education. You may be a good fit if you: 7+ years in product operations, program management, launch management, or related operational roles in fast-paced tech companies. Have experience in hyperscale companies Have experience in hypergrowth companies navigating rapid scaling and creating process that accelerates teams without slowing them down.navigating rapid growth creating common process that accelerates teams and never slows them down.Are quick to experiment with AI to streamline business processes and see optimization opportunities everywhere. Excel at building strong relationships with technical and non-technical stakeholders. Are quick to experiment with AI to streamline business processes and see opportunities everywhere for further optimization. Have experience managing launch motions across diverse technical surfaces (API, web apps, desktop/mobile) for high visibility launches. Are comfortable with ambiguity and can create structure where none exists. You're service-oriented and obsessed with making it easy for others to do great work. Strong candidates may also have experience with: Building AI-native workflows and pushing the boundaries of automation. Product Management and/or Product Marketing You treat process as a product with users, metrics, and continuous iteration. Track record of building and scaling operations teams The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$260,000 - $325,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4978674008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4978674008",
    "title": "Product Operations Manager, Launch Readiness ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4978674008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;We&#39;re hiring a Product Operations Manager - Launch Readiness to own and continuously improve how Anthropic launches products. This is a product-wide, horizontal role that will establish the operating system for all customer-facing launches across our portfolio.&lt;/p&gt;\n&lt;p&gt;Launching at Anthropic is uniquely dynamic. We&#39;re building on frontier models that evolve constantly, serving customers from individual developers to the largest enterprises, across multiple surfaces (API, claude.ai, Claude Code). This role will coordinate launches across Product teams and critical partners including Security, Legal, GTM, Finance, DevRel, and Safety. You&#39;ll establish common language, document repeatable launch motions, and build an AI-native toolkit that makes excellent launches feel effortless.&lt;/p&gt;\n&lt;p&gt;You treat launch readiness as a product. You&#39;re obsessed with making the &quot;happy path&quot; so helpful that teams obviously want to follow it. You build systems that accelerate product velocity, never gate it. You treat launch readiness as a product. You’re obsessed with making the “happy path” so helpful that teams obviously want to follow it. You build systems that accelerate product velocity, not gate it. You think like a product manager, not a compliance officer. Your work will directly impact every customer-facing launch at Anthropic, making them faster, safer, and better coordinated.ct manager, not a compliance officer. Your work will directly impact every customer-facing launch at Anthropic, making them faster, safer, and more coordinated.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;p&gt;You’ll own the operating system for customer-facing product launches at Anthropic. Working horizontally across Product teams and critical partners—including Security, Legal, GTM, Finance, DevRel, and Safety—you’ll establish frameworks, toolkits, and processes that enable teams to ship with confidence. You’ll drive adoption through influence, making launch readiness effortless and creating visibility across all launches.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Launch calendar &amp;amp; system of record&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Own our launch calendar as the source of truth for all customer-facing launches. Create visibility and predictability across Product and XFN teams.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Build workflows that reinforce our central system of record without becoming a documentation tax. Integrate with team operating rhythms and obsess over the user experience of our internal tools.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Repeatable Launch Processes&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Document and iterate on “happy path” launch processes across the launch lifecycle.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Establish common language and conventions that work across diverse launch types.&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Cross-Functional Coordination&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Partner with Security, Legal, GTM, Finance, DevRel, and other XFN teams to define clear engagement models. These “APIs between teams” make coordination seamless and reliable.&lt;/li&gt;\n&lt;li&gt;Enable the right teams to engage with the right projects at the right time.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Create a federated operating model that gives teams autonomy while maintaining common standards.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;AI-Native Launch Toolkit&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Build Claude-powered assistants and automation to streamline launch workflows.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Experiment with ambient intelligence to pull information from across the org.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Automate intake workflows, documentation generation, and status tracking. Partner with Engineering on tooling strategy and integrations.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Continuous Improvement&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Define and track success metrics for Define and track success metrics for launch excellence to identify bottlenecks through data and feedback.launch excellence in order to identify bottlenecks through data and feedback.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Run post-launch retros and feed learnings back into process improvements. Scale best practices across teams through documentation and education.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;7+ years&lt;/strong&gt; in product operations, program management, launch management, or related operational roles in fast-paced tech companies.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Have experience in hyperscale companies Have experience in hypergrowth companies navigating rapid scaling and creating process that accelerates teams without slowing them down.navigating rapid growth creating common process that accelerates teams and never slows them down.Are quick to experiment with AI to streamline business processes and see optimization opportunities everywhere.&lt;/li&gt;\n&lt;li&gt;Excel at building strong relationships with technical and non-technical stakeholders.&lt;/li&gt;\n&lt;li&gt;Are quick to experiment with AI to streamline business processes and see opportunities everywhere for further optimization.&lt;/li&gt;\n&lt;li&gt;Have experience managing launch motions across diverse technical surfaces (API, web apps, desktop/mobile) for high visibility launches.&lt;/li&gt;\n&lt;li&gt;Are comfortable with ambiguity and can create structure where none exists.&lt;/li&gt;\n&lt;li&gt;You&#39;re service-oriented and obsessed with making it easy for others to do great work.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&amp;nbsp;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Building AI-native workflows and pushing the boundaries of automation.&lt;/li&gt;\n&lt;li&gt;Product Management and/or Product Marketing&lt;/li&gt;\n&lt;li&gt;You treat process as a product with users, metrics, and continuous iteration.&lt;/li&gt;\n&lt;li&gt;Track record of building and scaling operations teams&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$260,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$325,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4978674008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Operations Manager, Public Sector ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4992055008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role: We're hiring a Product Operations Manager to work directly with our Product and Engineering teams on our Growth, Enterprise, and Verticals team. They will build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities. The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way. The Public Sector (PubSec) Product Team is responsible for launching our new models into Public Sector organizations. They are obsessed with the specific use cases and impact our work can have within Public Sector organizations and are willing to get into the weeds to break down any barriers to adoption or engagement. The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product delivery. They are passionate about creating scalable systems that help Product teams better understand users. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization's effectiveness. Responsibilities: Inputs to Product Teams – Ensuring product teams have the information they need to make great decisions Voice of customer synthesis and feedback routing from strategic to tactical Create high-leverage engagement points with partners throughout the product lifecycle Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems Streamline the most important decision points for teams and impacted partners Ops of the Product Org – Creating the operating systems that enable product teams to thrive Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc) Create reliable run-of-business systems across product Improve common product development processes and tooling Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams Outputs from Product Teams – Amplifying product impact by connecting what we build to those who need it Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products Maintain launch motions that allow us to ship with confidence and monitor impact Create cross-team roadmap visibility that drives cross-functional alignment Make clear to all of Anthropic what Product is working on and how it's going You may be a good fit if you have: 5+ years of experience in product operations, program management, or related operational roles in hyper-scaling tech companies Mission-aligned with building safe and beneficial AI systems Experience working with Public Sector organizations Track record of building processes and programs from 0 to 1 and scaling them thoughtfully Experience working deeply with AI and frontier models Strong cross-functional partnership skills with ability to influence without authority Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments Experience with launch coordination, early access programs, or customer feedback loops A passion for iterative, user-driven product development Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists. This position requires verification of U.S. citizenship due to citizenship-based legal restrictions. Specifically, this position supports a United States federal, state, and/or local government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law. To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government clearance.The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$210,000 - $240,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4992055008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4992055008",
    "title": "Product Operations Manager, Public Sector ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4992055008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the Role:&lt;/h2&gt;\n&lt;p&gt;We&#39;re hiring a Product Operations Manager to work directly with our Product and Engineering teams on our Growth, Enterprise, and Verticals team. They will build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will&amp;nbsp; work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way.&lt;/p&gt;\n&lt;p&gt;The Public Sector (PubSec) Product Team is responsible for launching our new models into Public Sector organizations. They are obsessed with the specific use cases and impact our work can have within Public Sector organizations and are willing to get into the weeds to break down any barriers to adoption or engagement.&lt;/p&gt;\n&lt;p&gt;The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product delivery. They are passionate about creating scalable systems that help Product teams better understand users. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization&#39;s effectiveness.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Inputs to Product Teams&lt;/strong&gt; – Ensuring product teams have the information they need to make great decisions&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Voice of customer synthesis and feedback routing from strategic to tactical&lt;/li&gt;\n&lt;li&gt;Create high-leverage engagement points with partners throughout the product lifecycle&lt;/li&gt;\n&lt;li&gt;Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses&lt;/li&gt;\n&lt;li&gt;Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems&lt;/li&gt;\n&lt;li&gt;Streamline the most important decision points for teams and impacted partners&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Ops of the Product Org&lt;/strong&gt; – Creating the operating systems that enable product teams to thrive&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc)&lt;/li&gt;\n&lt;li&gt;Create reliable run-of-business systems across product&lt;/li&gt;\n&lt;li&gt;Improve common product development processes and tooling&lt;/li&gt;\n&lt;li&gt;Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Outputs from Product Teams&lt;/strong&gt; – Amplifying product impact by connecting what we build to those who need it&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products&lt;/li&gt;\n&lt;li&gt;Maintain launch motions that allow us to ship with confidence and monitor impact&lt;/li&gt;\n&lt;li&gt;Create cross-team roadmap visibility that drives cross-functional alignment&lt;/li&gt;\n&lt;li&gt;Make clear to all of Anthropic what Product is working on and how it&#39;s going&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in product operations, program management, or related operational roles in hyper-scaling tech companies&lt;/li&gt;\n&lt;li&gt;Mission-aligned with building safe and beneficial AI systems&lt;/li&gt;\n&lt;li&gt;Experience working with Public Sector organizations&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Track record of building processes and programs from 0 to 1 and scaling them thoughtfully&lt;/li&gt;\n&lt;li&gt;Experience working deeply with AI and frontier models&lt;/li&gt;\n&lt;li&gt;Strong cross-functional partnership skills with ability to influence without authority&lt;/li&gt;\n&lt;li&gt;Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations&lt;/li&gt;\n&lt;li&gt;Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments&lt;/li&gt;\n&lt;li&gt;Experience with launch coordination, early access programs, or customer feedback loops&lt;/li&gt;\n&lt;li&gt;A passion for iterative, user-driven product development&lt;/li&gt;\n&lt;li&gt;Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;This position requires verification of U.S. citizenship due to citizenship-based legal restrictions. Specifically, this position supports a United States federal, state, and/or local government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law. To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government clearance.&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$210,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$240,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4992055008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Operations Manager, Research Product ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4992071008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role: We're hiring a Product Operations Manager to work directly with our Product and Engineering teams on our Growth, Enterprise, and Verticals team. They will build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities. The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way. The Research Product Team is responsible for launching our new models into the wild. They are the connective tissue between our Research Org, our internal product teams, and our users themselves. The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product delivery. They are passionate about creating scalable systems that help Product teams better understand users. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization's effectiveness. Responsibilities: Inputs to Product Teams – Ensuring product teams have the information they need to make great decisions Voice of customer synthesis and feedback routing from strategic to tactical Create high-leverage engagement points with partners throughout the product lifecycle Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems Streamline the most important decision points for teams and impacted partners Ops of the Product Org – Creating the operating systems that enable product teams to thrive Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc) Create reliable run-of-business systems across product Improve common product development processes and tooling Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams Outputs from Product Teams – Amplifying product impact by connecting what we build to those who need it Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products Maintain launch motions that allow us to ship with confidence and monitor impact Create cross-team roadmap visibility that drives cross-functional alignment Make clear to all of Anthropic what Product is working on and how it's going You may be a good fit if you have: 4+ years of experience in product operations, program management, or related operational roles in hyper-scaling tech companies Mission-aligned with building safe and beneficial AI systems Track record of building processes and programs from 0 to 1 and scaling them thoughtfully Experience working deeply with AI and frontier models Strong cross-functional partnership skills with ability to influence without authority Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments Experience with launch coordination, early access programs, or customer feedback loops A passion for iterative, user-driven product development Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists. The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$210,000 - $240,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4992071008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4992071008",
    "title": "Product Operations Manager, Research Product ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4992071008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the Role:&lt;/h2&gt;\n&lt;p&gt;We&#39;re hiring a Product Operations Manager to work directly with our Product and Engineering teams on our Growth, Enterprise, and Verticals team. They will build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will&amp;nbsp; work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way.&lt;/p&gt;\n&lt;p&gt;The Research Product Team is responsible for launching our new models into the wild. They are the connective tissue between our Research Org, our internal product teams, and our users themselves.&amp;nbsp;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product delivery. They are passionate about creating scalable systems that help Product teams better understand users. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization&#39;s effectiveness.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Inputs to Product Teams&lt;/strong&gt; – Ensuring product teams have the information they need to make great decisions&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Voice of customer synthesis and feedback routing from strategic to tactical&lt;/li&gt;\n&lt;li&gt;Create high-leverage engagement points with partners throughout the product lifecycle&lt;/li&gt;\n&lt;li&gt;Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses&lt;/li&gt;\n&lt;li&gt;Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems&lt;/li&gt;\n&lt;li&gt;Streamline the most important decision points for teams and impacted partners&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Ops of the Product Org&lt;/strong&gt; – Creating the operating systems that enable product teams to thrive&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc)&lt;/li&gt;\n&lt;li&gt;Create reliable run-of-business systems across product&lt;/li&gt;\n&lt;li&gt;Improve common product development processes and tooling&lt;/li&gt;\n&lt;li&gt;Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Outputs from Product Teams&lt;/strong&gt; – Amplifying product impact by connecting what we build to those who need it&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products&lt;/li&gt;\n&lt;li&gt;Maintain launch motions that allow us to ship with confidence and monitor impact&lt;/li&gt;\n&lt;li&gt;Create cross-team roadmap visibility that drives cross-functional alignment&lt;/li&gt;\n&lt;li&gt;Make clear to all of Anthropic what Product is working on and how it&#39;s going&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;4+ years of experience in product operations, program management, or related operational roles in hyper-scaling tech companies&lt;/li&gt;\n&lt;li&gt;Mission-aligned with building safe and beneficial AI systems&lt;/li&gt;\n&lt;li&gt;Track record of building processes and programs from 0 to 1 and scaling them thoughtfully&lt;/li&gt;\n&lt;li&gt;Experience working deeply with AI and frontier models&lt;/li&gt;\n&lt;li&gt;Strong cross-functional partnership skills with ability to influence without authority&lt;/li&gt;\n&lt;li&gt;Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations&lt;/li&gt;\n&lt;li&gt;Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments&lt;/li&gt;\n&lt;li&gt;Experience with launch coordination, early access programs, or customer feedback loops&lt;/li&gt;\n&lt;li&gt;A passion for iterative, user-driven product development&lt;/li&gt;\n&lt;li&gt;Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists.&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$210,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$240,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4992071008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Support Manager",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4983655008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: We are hiring a Product Support Manager in NYC, Seattle, or San Francisco to manage a team of Product Support Specialists and focus on enhancing our Enterprise Support offering. In this role, you’ll be responsible for building and managing a happy and high-performing Specialist team that is at the front lines of safely delivering AI to the world. As part of a global Support organization, you’ll collaborate closely with peers in other regions to ensure users of all types have a great experience with Anthropic’s products. Responsibilities: Hire, lead, and develop a team of happy, high-performing Product Support Specialists Provide thoughtful coaching and feedback to your direct reports, and partner with them on their career development goals and growth Monitor team performance and course correct both in real-time and strategically as needed Manage day to day team operations, including proactive capacity management and ad hoc unblocking of your Specialists as they action their daily work Partner with peer leaders in other regions to ensure consistent global support delivery in routine casework as well as on-call or high-urgency responsibilities Work closely with go-to-market (GTM) stakeholders to scope, execute, and iterate upon our offerings for our most strategic customers; interact with these internal users daily Drive large-scale initiatives that raise the bar for our organization, leveraging data to make decisions and with a keen understanding of broader business goals Continuously strive for exceptional user experiences, with a focus on high-touch Enterprise Support Partner with cross-functional stakeholders across the organization to build efficiencies and improve user experience Communicate clearly and effectively with your team, stakeholders, and external customers You may be a good fit if you: Have 6+ years of product support experience and 3+ years in a people management role Have been part of a B2B Enterprise or Strategic Support team (as a bonus, you also understand the needs of Consumer, scaled support users) Thrive in a fast-paced, ever-changing environment, and have demonstrated success in bringing your team along during periods of rapid growth Successfully operate in ambiguity, practicing good judgment and awareness of broader priorities in order to make decisions and get things done Care deeply about continuous improvement and elevating ambitions in the name of user experience Enjoy building trust and collaborating closely with cross-functional partners Can capably navigate tough conversations, empathetically driving solutions and steps forward Value regularly seeking, providing, and incorporating feedback when it comes to the way you and your team operate Are interested in developing deep product expertise in order to comprehensively support your team and knowledgeably role model user first behaviors Prefer to use data to make decisions or advocate for users, and know your way around basic to intermediate SQL queries Consider yourself at least somewhat knowledgeable with APIs and capable of confidently understanding technical documentation in order to help debug errors Are comfortable working with a globally distributed team and building strong remote and in-office relationships Are excited about Anthropic’s products and already familiar with some of the ways AI can have a positive impact on your work The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$165,000 - $210,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4983655008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4983655008",
    "title": "Product Support Manager",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4983655008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;We are hiring a Product Support Manager in NYC, Seattle, or San Francisco to manage a team of Product Support Specialists and focus on enhancing our Enterprise Support offering. In this role, you’ll be responsible for building and managing a happy and high-performing Specialist team that is at the front lines of safely delivering AI to the world. As part of a global Support organization, you’ll collaborate closely with peers in other regions to ensure users of all types have a great experience with Anthropic’s products.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Hire, lead, and develop a team of happy, high-performing Product Support Specialists&lt;/li&gt;\n&lt;li&gt;Provide thoughtful coaching and feedback to your direct reports, and partner with them on their career development goals and growth&lt;/li&gt;\n&lt;li&gt;Monitor team performance and course correct both in real-time and strategically as needed&lt;/li&gt;\n&lt;li&gt;Manage day to day team operations, including proactive capacity management and ad hoc unblocking of your Specialists as they action their daily work&lt;/li&gt;\n&lt;li&gt;Partner with peer leaders in other regions to ensure consistent global support delivery in routine casework as well as on-call or high-urgency responsibilities&lt;/li&gt;\n&lt;li&gt;Work closely with go-to-market (GTM) stakeholders to scope, execute, and iterate upon our offerings for our most strategic customers; interact with these internal users daily&lt;/li&gt;\n&lt;li&gt;Drive large-scale initiatives that raise the bar for our organization, leveraging data to make decisions and with a keen understanding of broader business goals&lt;/li&gt;\n&lt;li&gt;Continuously strive for exceptional user experiences, with a focus on high-touch Enterprise Support&lt;/li&gt;\n&lt;li&gt;Partner with cross-functional stakeholders across the organization to build efficiencies and improve user experience&lt;/li&gt;\n&lt;li&gt;Communicate clearly and effectively with your team, stakeholders, and external customers&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 6+ years of product support experience and 3+ years in a people management role&lt;/li&gt;\n&lt;li&gt;Have been part of a B2B Enterprise or Strategic Support team (as a bonus, you also understand the needs of Consumer, scaled support users)&lt;/li&gt;\n&lt;li&gt;Thrive in a fast-paced, ever-changing environment, and have demonstrated success in bringing your team along during periods of rapid growth&lt;/li&gt;\n&lt;li&gt;Successfully operate in ambiguity, practicing good judgment and awareness of broader priorities in order to make decisions and get things done&lt;/li&gt;\n&lt;li&gt;Care deeply about continuous improvement and elevating ambitions in the name of user experience&lt;/li&gt;\n&lt;li&gt;Enjoy building trust and collaborating closely with cross-functional partners&lt;/li&gt;\n&lt;li&gt;Can capably navigate tough conversations, empathetically driving solutions and steps forward&lt;/li&gt;\n&lt;li&gt;Value regularly seeking, providing, and incorporating feedback when it comes to the way you and your team operate&lt;/li&gt;\n&lt;li&gt;Are interested in developing deep product expertise in order to comprehensively support your team and knowledgeably role model user first behaviors&lt;/li&gt;\n&lt;li&gt;Prefer to use data to make decisions or advocate for users, and know your way around basic to intermediate SQL queries&lt;/li&gt;\n&lt;li&gt;Consider yourself at least somewhat knowledgeable with APIs and capable of confidently understanding technical documentation in order to help debug errors&lt;/li&gt;\n&lt;li&gt;Are comfortable working with a globally distributed team and building strong remote and in-office relationships&lt;/li&gt;\n&lt;li&gt;Are excited about Anthropic’s products and already familiar with some of the ways AI can have a positive impact on your work&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$165,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$210,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4983655008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Support Specialist",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4979585008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As a Product Support Specialist, you’ll be at the front lines of safely delivering AI to the world by responding to, investigating, and tracking user needs in your day to day. Additionally, you’ll help us identify – and close – gaps in our team’s technical knowledge, provide high-touch support to strategic customers, and demonstrate deep care for how we systematically support customers at scale. Note: Specialists will work either Tues - Sat or Sun - Thurs Responsibilities: Become an expert in all Anthropic products Respond to user support cases with a variety of complexity, from questions for individuals to complex API debugging for large businesses Clearly and empathetically communicate with a wide range of user personas, context-switching between guiding executives in a high-touch model to assisting consumer users in a rapid pace Manage on-call tasks for high-urgency user issues with extreme ownership Prioritize critically and comfortably adapt to an ever-evolving product landscape Operate in ambiguity, making informed decisions even in never-before-seen situations Partner with engineers, teammates, and other internal stakeholders to diagnose and resolve user issues, both individually and at scale Suggest and drive improvements to increase user satisfaction through support processes as well as own initiatives that increase efficiency and drive down contact rates Uplevel our team’s technical knowledge by scoping gaps, working with cross-functional partners to deeply understand relevant nuances, and building resources that grow with our products You may be a good fit if you: Have experience in technical product support, including API debugging, preferably in a second tier, escalated, or priority support team Are familiar with APIs and technical SaaS products and can deeply understand technical docs with ease Have demonstrated an ability to thrive in fast-paced, reactive situations while meeting core support metrics targets (e.g. CSAT, SLA, etc.) Possess strong user empathy and are expert in the lifecycle of a support case; you can read between the lines of a user’s question, put yourself in their shoes, and get at the heart of their needs for a speedy, satisfying resolution Have crisp but kind written communication skills and a deep care for the details Enjoy helping others learn about new features and complex concepts Are persistent and curious; you delight in the hunt of tracking down a bug or issue, and are energized by fixing this for all similar users going forward Have experience contributing to the foundations of a support team – this is essential, highly valuable, but often unglamorous work Are proficient at working in a technical environment and are interested in Anthropic’s products Possess a deep sense of ownership, and are excited to help us build our team! The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$116,480 - $165,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4979585008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4979585008",
    "title": "Product Support Specialist",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4979585008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;As a Product Support Specialist, you’ll be at the front lines of safely delivering AI to the world by responding to, investigating, and tracking user needs in your day to day. Additionally, you’ll help us identify – and close – gaps in our team’s technical knowledge, provide high-touch support to strategic customers, and demonstrate deep care for how we systematically support customers at scale.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Specialists will work either Tues - Sat or Sun - Thurs&amp;nbsp;&amp;nbsp;&lt;/p&gt;\n&lt;h2 class=&quot;p1&quot;&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul class=&quot;ul1&quot;&gt;\n&lt;li class=&quot;li1&quot;&gt;Become an expert in all Anthropic products&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Respond to user support cases with a variety of complexity, from questions for individuals to complex API debugging for large businesses&amp;nbsp;&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Clearly and empathetically communicate with a wide range of user personas, context-switching between guiding executives in a high-touch model to assisting consumer users in a rapid pace&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Manage on-call tasks for high-urgency user issues with extreme ownership&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Prioritize critically and comfortably adapt to an ever-evolving product landscape&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Operate in ambiguity, making informed decisions even in never-before-seen situations&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Partner with engineers, teammates, and other internal stakeholders to diagnose and resolve user issues, both individually and at scale&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Suggest and drive improvements to increase user satisfaction through support processes as well as own initiatives that increase efficiency and drive down contact rates&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Uplevel our team’s technical knowledge by scoping gaps, working with cross-functional partners to deeply understand relevant nuances, and building resources that grow with our products&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;p1&quot;&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul class=&quot;ul1&quot;&gt;\n&lt;li class=&quot;li1&quot;&gt;Have experience in technical product support, including API debugging, preferably in a second tier, escalated, or priority support team&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Are familiar with APIs and technical SaaS products and can deeply understand technical docs with ease&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Have demonstrated an ability to thrive in fast-paced, reactive situations while meeting core support metrics targets (e.g. CSAT, SLA, etc.)&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Possess strong user empathy and are expert in the lifecycle of a support case; you can read between the lines of a user’s question, put yourself in their shoes, and get at the heart of their needs for a speedy, satisfying resolution&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Have crisp but kind written communication skills and a deep care for the details&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Enjoy helping others learn about new features and complex concepts&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Are persistent and curious; you delight in the hunt of tracking down a bug or issue, and are energized by fixing this for all similar users going forward&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Have experience contributing to the foundations of a support team – this is essential, highly valuable, but often unglamorous work&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Are proficient at working in a technical environment and are interested in Anthropic’s products&lt;/li&gt;\n&lt;li class=&quot;li1&quot;&gt;Possess a deep sense of ownership, and are excited to help us build our team!&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$116,480&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$165,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4979585008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Recruiter, AI Research",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4604015008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role: Anthropic is looking for a talented AI Research Recruiter to partner with our Research teams. In this pivotal role, you will be instrumental in shaping the future of our organization by identifying, engaging, and hiring the best and brightest minds across a range of disciplines. As we continue to push the boundaries of AI research and development, we need a passionate recruiter who can help us build a world-class team dedicated to creating safe and beneficial AI systems. Responsibilities: Develop and execute strategic recruiting plans to identify, source, and hire highly qualified candidates, with a focus on Machine Learning and AI research talent Partner with Research hiring managers and interviewers to understand hiring needs, team matching, required skills and qualifications Enhance and implement recruiting processes and programs while maintaining an inclusive and high talent bar, such as developing targeted outreach campaigns, building connections with industry leaders, and removing any unfair biases from the hiring process Collaborate with leadership and cross-functional partners to understand organizational needs and map out long-term talent acquisition strategies that balance priorities across all technical teams Enhance Anthropic's employer brand within the research and science community to showcase our mission, culture, and values to candidates Stay up-to-date on recruiting best practices, emerging sourcing techniques, interview innovations, and workplace trends You may be a good fit if you: Have 5+ years of experience in full life cycle recruiting supporting technical research teams Have a passion for AI's potential to positively impact the world and realistic assessment of its risks and limitations Are experimental and are open to new, creative recruiting ideas, or have experience working with hiring managers who are open to non-traditional talent strategies Thrive in fast-paced, dynamic environments and enjoy juggling multiple priorities Possess strong technical aptitude with the ability to understand and evaluate technical qualifications Have enthusiasm for deeply understanding the needs of researchers and innovating on recruiting processes to make them more tailored to the world of research Have excellent organizational skills and attention to detail, as well as a proactive mindset and ability to operate with autonomy Have experience partnering with researchers and hiring talent that work on GenAI and LLMs Have a proven track record of scaling and building diverse and high-performing teams in a fast-paced, high-growth startup environment Strong candidates may also: Bring a deep interest in AI safety research Have experience partnering with researchers and hiring talent that work on GenAI and LLMs Have experience with academic recruitment and research communities Deadline to apply: None. Applications will be reviewed on a rolling basis.The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$170,000 - $295,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4604015008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4604015008",
    "title": "Recruiter, AI Research",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4604015008",
    "departments": [
      "People"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the Role:&amp;nbsp;&lt;/h2&gt;\n&lt;p&gt;Anthropic is looking for a talented AI Research Recruiter to partner with our Research teams. In this pivotal role, you will be instrumental in shaping the future of our organization by identifying, engaging, and hiring the best and brightest minds across a range of disciplines. As we continue to push the boundaries of AI research and development, we need a passionate recruiter who can help us build a world-class team dedicated to creating safe and beneficial AI systems.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and execute strategic recruiting plans to identify, source, and hire highly qualified candidates, with a focus on Machine Learning and AI research talent&lt;/li&gt;\n&lt;li&gt;Partner with Research hiring managers and interviewers to understand hiring needs, team matching, required skills and qualifications&lt;/li&gt;\n&lt;li&gt;Enhance and implement recruiting processes and programs while maintaining an inclusive and high talent bar, such as developing targeted outreach campaigns, building connections with industry leaders, and removing any unfair biases from the hiring process&lt;/li&gt;\n&lt;li&gt;Collaborate with leadership and cross-functional partners to understand organizational needs and map out long-term talent acquisition strategies that balance priorities across all technical teams&lt;/li&gt;\n&lt;li&gt;Enhance Anthropic&#39;s employer brand within the research and science community to showcase our mission, culture, and values to candidates&lt;/li&gt;\n&lt;li&gt;Stay up-to-date on recruiting best practices, emerging sourcing techniques, interview innovations, and workplace trends&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 5+ years of experience in full life cycle recruiting supporting technical research teams&lt;/li&gt;\n&lt;li&gt;Have a passion for AI&#39;s potential to positively impact the world and realistic assessment of its risks and limitations&lt;/li&gt;\n&lt;li&gt;Are experimental and are open to new, creative recruiting ideas, or have experience working with hiring managers who are open to non-traditional talent strategies&lt;/li&gt;\n&lt;li&gt;Thrive in fast-paced, dynamic environments and enjoy juggling multiple priorities&lt;/li&gt;\n&lt;li&gt;Possess strong technical aptitude with the ability to understand and evaluate technical qualifications&lt;/li&gt;\n&lt;li&gt;Have enthusiasm for deeply understanding the needs of researchers and innovating on recruiting processes to make them more tailored to the world of research&lt;/li&gt;\n&lt;li&gt;Have excellent organizational skills and attention to detail, as well as a proactive mindset and ability to operate with autonomy&lt;/li&gt;\n&lt;li&gt;Have experience partnering with researchers and hiring talent that work on GenAI and LLMs&lt;/li&gt;\n&lt;li&gt;Have a proven track record of scaling and building diverse and high-performing teams in a fast-paced, high-growth startup environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Bring a deep interest in AI safety research&lt;/li&gt;\n&lt;li&gt;Have experience partnering with researchers and hiring talent that work on GenAI and LLMs&lt;/li&gt;\n&lt;li&gt;Have experience with academic recruitment and research communities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;None. Applications will be reviewed on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$170,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$295,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4604015008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Recruiter, Sales",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4961118008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Anthropic is seeking an exceptional Sales Recruiter to join our GTM recruiting team. In this pivotal role, you will be at the forefront of building our Sales organization, sourcing and hiring exceptional talent across Enterprise Sales, Commercial Sales, Strategic Accounts, Account Management, and Sales Leadership. As we scale our commercial efforts and bring Claude to enterprises worldwide, we need a passionate recruiter who understands the nuances of quota-carrying roles and can identify the sales talent that will drive our mission forward. You'll partner closely with our Sales leadership to build teams that combine commercial excellence with deep commitment to responsible AI deployment. This role requires someone who can assess not just sales acumen and track records, but also alignment with our mission of building safe and beneficial AI systems. Responsibilities: Lead full-cycle recruiting for all Sales roles, from individual contributors to senior sales leaders, across Enterprise, Commercial, and Strategic Account segments Develop and execute strategic recruiting plans tailored to sales hiring, including competitive mapping, territory-based sourcing, and revenue leader networking strategies Partner closely with Sales leadership to understand revenue goals, territory plans, ideal candidate profiles, and required competencies for different sales segments Build robust pipelines of quota-carrying sales talent with proven track records in enterprise software, SaaS, or emerging technology markets Create exceptional candidate experiences that showcase Anthropic's mission, market opportunity, and unique value proposition for sales professionals Design and implement sales-specific recruiting processes that effectively assess consultative selling skills, technical acumen, deal execution, and cultural alignment Leverage industry relationships, sales communities, and creative sourcing strategies to identify passive candidates and build long-term talent pipelines Partner with Recruiting Operations to analyze sales recruiting metrics (time-to-fill, pipeline velocity, offer acceptance rates) and optimize processes accordingly Collaborate with GTM recruiting colleagues to share market insights, candidate leads, and best practices across the broader Go-To-Market organization You may be a good fit if you: Have 7+ years of full-cycle recruiting experience with deep specialization in Sales hiring across enterprise software, SaaS, or technology companies Possess a proven track record of building sales teams from the ground up, with experience hiring across different sales segments (Enterprise, Mid-Market, Commercial, Strategic Accounts) Can effectively assess sales talent by evaluating deal experience, pipeline management, quota attainment, territory building, and consultative selling capabilities Have established relationships with sales leaders and understand how to source both active and passive sales candidates through industry networks Excel at partnering with Revenue leaders and have experience navigating the unique dynamics of sales hiring (compensation negotiations, competitive offer situations, quota expectations) Demonstrate expertise in building diverse, high-performing sales teams while maintaining a high talent bar and inclusive hiring practices Thrive in fast-paced, high-growth environments where sales hiring velocity and quality are critical to business success Are passionate about AI technology and can articulate Anthropic's mission and market opportunity in ways that resonate with commercial talent Have a proactive, autonomous mindset with ability to manage multiple executive-level searches simultaneously while delivering exceptional candidate and stakeholder experiences Strong candidates may also have: Experience recruiting for sales roles in AI/ML, emerging technology, or platform businesses where technical acumen is required alongside sales skills Track record of hiring sales talent for companies selling into highly regulated industries (healthcare, financial services, government) Deep understanding of sales compensation structures, quota models, and how to position offers competitively in the market Experience building sales enablement partnerships between recruiting and revenue operations teams Demonstrated success recruiting diverse sales talent and implementing strategies to build inclusive, high-performing commercial teams Background in sales or revenue operations that informs recruiting approach and stakeholder credibility The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$170,000 - $230,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4961118008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4961118008",
    "title": "Recruiter, Sales",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4961118008",
    "departments": [
      "People"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Anthropic is seeking an exceptional Sales Recruiter to join our GTM recruiting team. In this pivotal role, you will be at the forefront of building our Sales organization, sourcing and hiring exceptional talent across Enterprise Sales, Commercial Sales, Strategic Accounts, Account Management, and Sales Leadership. As we scale our commercial efforts and bring Claude to enterprises worldwide, we need a passionate recruiter who understands the nuances of quota-carrying roles and can identify the sales talent that will drive our mission forward.&lt;/p&gt;\n&lt;p&gt;You&#39;ll partner closely with our Sales leadership to build teams that combine commercial excellence with deep commitment to responsible AI deployment. This role requires someone who can assess not just sales acumen and track records, but also alignment with our mission of building safe and beneficial AI systems.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead full-cycle recruiting for all Sales roles, from individual contributors to senior sales leaders, across Enterprise, Commercial, and Strategic Account segments&lt;/li&gt;\n&lt;li&gt;Develop and execute strategic recruiting plans tailored to sales hiring, including competitive mapping, territory-based sourcing, and revenue leader networking strategies&lt;/li&gt;\n&lt;li&gt;Partner closely with Sales leadership to understand revenue goals, territory plans, ideal candidate profiles, and required competencies for different sales segments&lt;/li&gt;\n&lt;li&gt;Build robust pipelines of quota-carrying sales talent with proven track records in enterprise software, SaaS, or emerging technology markets&lt;/li&gt;\n&lt;li&gt;Create exceptional candidate experiences that showcase Anthropic&#39;s mission, market opportunity, and unique value proposition for sales professionals&lt;/li&gt;\n&lt;li&gt;Design and implement sales-specific recruiting processes that effectively assess consultative selling skills, technical acumen, deal execution, and cultural alignment&lt;/li&gt;\n&lt;li&gt;Leverage industry relationships, sales communities, and creative sourcing strategies to identify passive candidates and build long-term talent pipelines&lt;/li&gt;\n&lt;li&gt;Partner with Recruiting Operations to analyze sales recruiting metrics (time-to-fill, pipeline velocity, offer acceptance rates) and optimize processes accordingly&lt;/li&gt;\n&lt;li&gt;Collaborate with GTM recruiting colleagues to share market insights, candidate leads, and best practices across the broader Go-To-Market organization&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 7+ years of full-cycle recruiting experience with deep specialization in Sales hiring across enterprise software, SaaS, or technology companies&lt;/li&gt;\n&lt;li&gt;Possess a proven track record of building sales teams from the ground up, with experience hiring across different sales segments (Enterprise, Mid-Market, Commercial, Strategic Accounts)&lt;/li&gt;\n&lt;li&gt;Can effectively assess sales talent by evaluating deal experience, pipeline management, quota attainment, territory building, and consultative selling capabilities&lt;/li&gt;\n&lt;li&gt;Have established relationships with sales leaders and understand how to source both active and passive sales candidates through industry networks&lt;/li&gt;\n&lt;li&gt;Excel at partnering with Revenue leaders and have experience navigating the unique dynamics of sales hiring (compensation negotiations, competitive offer situations, quota expectations)&lt;/li&gt;\n&lt;li&gt;Demonstrate expertise in building diverse, high-performing sales teams while maintaining a high talent bar and inclusive hiring practices&lt;/li&gt;\n&lt;li&gt;Thrive in fast-paced, high-growth environments where sales hiring velocity and quality are critical to business success&lt;/li&gt;\n&lt;li&gt;Are passionate about AI technology and can articulate Anthropic&#39;s mission and market opportunity in ways that resonate with commercial talent&lt;/li&gt;\n&lt;li&gt;Have a proactive, autonomous mindset with ability to manage multiple executive-level searches simultaneously while delivering exceptional candidate and stakeholder experiences&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience recruiting for sales roles in AI/ML, emerging technology, or platform businesses where technical acumen is required alongside sales skills&lt;/li&gt;\n&lt;li&gt;Track record of hiring sales talent for companies selling into highly regulated industries (healthcare, financial services, government)&lt;/li&gt;\n&lt;li&gt;Deep understanding of sales compensation structures, quota models, and how to position offers competitively in the market&lt;/li&gt;\n&lt;li&gt;Experience building sales enablement partnerships between recruiting and revenue operations teams&lt;/li&gt;\n&lt;li&gt;Demonstrated success recruiting diverse sales talent and implementing strategies to build inclusive, high-performing commercial teams&lt;/li&gt;\n&lt;li&gt;Background in sales or revenue operations that informs recruiting approach and stakeholder credibility&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$170,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$230,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4961118008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Interpretability",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4980430008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: When you see what modern language models are capable of, do you wonder, \"How do these things work? How can we trust them?\" The Interpretability team at Anthropic is working to reverse-engineer how trained models work because we believe that a mechanistic understanding is the most robust way to make advanced systems safe. We’re looking for researchers and engineers to join our efforts. People mean many different things by \"interpretability\". We're focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do \"biology\" or \"neuroscience\" of neural networks using “microscopes” we build, or as treating neural networks as binary computer programs we're trying to \"reverse engineer\". A few places to learn more about our work and team at a high level are this introduction to Interpretability from our research lead, Chris Olah; a discussion of our work on the Hard Fork podcast produced by the New York Times, and this blog post (and accompanying video) sharing more about some of the engineering challenges we’d had to solve to get these results. Some of our team's notable publications include A Mathematical Framework for Transformer Circuits, In-context Learning and Induction Heads, Toy Models of Superposition, Scaling Monosemanticity, and our Circuits’ Methods and Biology papers. This work builds on ideas from members' work prior to Anthropic such as the original circuits thread, Multimodal Neurons, Activation Atlases, and Building Blocks. We aim to create a solid foundation for mechanistically understanding neural networks and making them safe (see our vision post). In the short term, we have focused on resolving the issue of \"superposition\" (see Toy Models of Superposition, Superposition, Memorization, and Double Descent, and our May 2023 update), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our subsequent work found millions of features in Sonnet, one of our production language models, represents progress in this direction. In our most recent work, we develop methods that allow us to build circuits using features and use this circuits to understand the mechanisms associated with a model's computation and study specific examples of multi-hop reasoning, planning, and chain-of-thought faithfulness on Haiku 3.5, one of our production models.” This is a stepping stone towards our overall goal of mechanistically understanding neural networks. We often collaborate with teams across Anthropic, such as Alignment Science and Societal Impacts to use our work to make Anthropic’s models safer. We also have an Interpretability Architectures project that involves collaborating with Pretraining. Responsibilities: Implement and analyze research experiments, both quickly in toy scenarios and at scale in large models Set up and optimize research workflows to run efficiently and reliably at large scale Build tools and abstractions to support rapid pace of research experimentation Develop and improve tools and infrastructure to support other teams in using Interpretability’s work to improve model safety You may be a good fit if you: Have 5-10+ years of experience building software Are highly proficient in at least one programming language (e.g., Python, Rust, Go, Java) and productive with python Have some experience contributing to empirical AI research projects Have a strong ability to prioritize and direct effort toward the most impactful work and are comfortable operating with ambiguity and questioning assumptions. Prefer fast-moving collaborative projects to extensive solo efforts Want to learn more about machine learning research and its applications and collaborate closely with researchers Care about the societal impacts and ethics of your work Strong candidates may also have experience with: Designing a code base so that anyone can quickly code experiments, launch them, and analyze their results without hitting bugs Optimizing the performance of large-scale distributed systems Collaborating closely with researchers Language modeling with transformers GPUs or Pytorch Representative Projects: Building Garcon, a tool that allows researchers to easily access LLMs internals from a jupyter notebook Setting up and optimizing a pipeline to efficiently collect petabytes of transformer activations and shuffle them. Profiling and optimizing ML training, including parallelizing to many GPUs Make launching ML experiments and manipulating+analyzing the results fast and easy Creating an interactive visualization of attention between tokens in a language model Role Specific Location Policy: This role is based in San Francisco office; however, we are open to considering exceptional candidates for remote work on a case-by-case basis. The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$315,000 - $560,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4980430008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4980430008",
    "title": "Research Engineer, Interpretability",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4980430008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;p&gt;When you see what modern language models are capable of, do you wonder, &quot;How do these things work? How can we trust them?&quot;&lt;/p&gt;\n&lt;p&gt;The Interpretability team at Anthropic is working to reverse-engineer how trained models work because we believe that a mechanistic understanding is the most robust way to make advanced systems safe. We’re looking for researchers and engineers to join our efforts.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;People mean many different things by &quot;interpretability&quot;. We&#39;re focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do &quot;biology&quot; or &quot;neuroscience&quot; of neural networks using “microscopes” we build, or as treating neural networks as binary computer programs we&#39;re trying to &quot;reverse engineer&quot;.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;A few places to learn more about our work and team at a high level are &lt;a href=&quot;https://www.youtube.com/watch?v=TxhhMTOTMDg&quot;&gt;this introduction to Interpretability&lt;/a&gt; from our research lead, &lt;a href=&quot;https://colah.github.io/about.html&quot;&gt;Chris Olah&lt;/a&gt;; a &lt;a href=&quot;https://open.spotify.com/episode/5UF79Uu94ia0fwC32a89LU&quot;&gt;discussion of our work&lt;/a&gt; on the &lt;a href=&quot;https://www.nytimes.com/column/hard-fork&quot;&gt;Hard Fork podcast&lt;/a&gt; produced by the New York Times, and this &lt;a href=&quot;https://www.anthropic.com/research/engineering-challenges-interpretability&quot;&gt;blog post&lt;/a&gt; (and accompanying video) sharing more about some of the engineering challenges we’d had to solve to get these results. Some of our team&#39;s notable publications include &lt;a href=&quot;https://transformer-circuits.pub/2021/framework/index.html&quot;&gt;A Mathematical Framework for Transformer Circuits&lt;/a&gt;, &lt;a href=&quot;https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html&quot;&gt;In-context Learning and Induction Heads&lt;/a&gt;, &lt;a href=&quot;https://transformer-circuits.pub/2022/toy_model/index.html&quot;&gt;Toy Models of Superposition&lt;/a&gt;, &lt;a href=&quot;https://transformer-circuits.pub/2024/scaling-monosemanticity/&quot;&gt;Scaling Monosemanticity&lt;/a&gt;, and our Circuits’ &lt;a href=&quot;https://transformer-circuits.pub/2025/attribution-graphs/methods.html&quot;&gt;Methods&lt;/a&gt; and &lt;a href=&quot;https://transformer-circuits.pub/2025/attribution-graphs/biology.html&quot;&gt;Biology&lt;/a&gt; papers. This work builds on ideas from members&#39; work prior to Anthropic such as the &lt;a href=&quot;https://distill.pub/2020/circuits/&quot;&gt;original circuits thread&lt;/a&gt;, &lt;a href=&quot;https://distill.pub/2021/multimodal-neurons/&quot;&gt;Multimodal Neurons&lt;/a&gt;, &lt;a href=&quot;https://distill.pub/2019/activation-atlas/&quot;&gt;Activation Atlases&lt;/a&gt;, and &lt;a href=&quot;https://distill.pub/2018/building-blocks/&quot;&gt;Building Blocks&lt;/a&gt;.&lt;/p&gt;\n&lt;p&gt;We aim to create a solid foundation for mechanistically understanding neural networks and making them safe (see our &lt;a href=&quot;https://transformer-circuits.pub/2023/interpretability-dreams/index.html&quot;&gt;vision post&lt;/a&gt;). In the short term, we have focused on resolving the issue of &quot;superposition&quot; (see &lt;a href=&quot;https://transformer-circuits.pub/2022/toy_model/index.html&quot;&gt;Toy Models of Superposition&lt;/a&gt;, &lt;a href=&quot;https://transformer-circuits.pub/2023/toy-double-descent/index.html&quot;&gt;Superposition, Memorization, and Double Descent&lt;/a&gt;, and our &lt;a href=&quot;https://transformer-circuits.pub/2023/may-update/index.html&quot;&gt;May 2023 update&lt;/a&gt;), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our subsequent &lt;a href=&quot;https://www.anthropic.com/news/mapping-mind-language-model&quot;&gt;work&lt;/a&gt; found millions of features in Sonnet, one of our production language models, represents progress in this direction. In our most recent work, we develop methods that allow us to build circuits using features and use this circuits to understand the mechanisms associated with a model&#39;s computation and study specific examples of multi-hop reasoning, planning, and chain-of-thought faithfulness on Haiku 3.5, one of our production models.” This is a stepping stone towards our overall goal of mechanistically understanding neural networks.&lt;/p&gt;\n&lt;p&gt;We often collaborate with teams across Anthropic, such as Alignment Science and Societal Impacts to use our work to make Anthropic’s models safer. We also have an &lt;a href=&quot;https://transformer-circuits.pub/2024/april-update/index.html#interpretability-architecture&quot;&gt;Interpretability Architectures project&lt;/a&gt; that involves collaborating with Pretraining.&lt;/p&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Implement and analyze research experiments, both quickly in toy scenarios and at scale in large models&lt;/li&gt;\n&lt;li&gt;Set up and optimize research workflows to run efficiently and reliably at large scale&lt;/li&gt;\n&lt;li&gt;Build tools and abstractions to support rapid pace of research experimentation&lt;/li&gt;\n&lt;li&gt;Develop and improve tools and infrastructure to support other teams in using Interpretability’s work to improve model safety&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 5-10+ years of experience building software&lt;/li&gt;\n&lt;li&gt;Are highly proficient in at least one programming language (e.g., Python, Rust, Go, Java) and productive with python&lt;/li&gt;\n&lt;li&gt;Have some experience contributing to empirical AI research projects&lt;/li&gt;\n&lt;li&gt;Have a strong ability to prioritize and direct effort toward the most impactful work and are comfortable operating with ambiguity and questioning assumptions.&lt;/li&gt;\n&lt;li&gt;Prefer fast-moving collaborative projects to extensive solo efforts&lt;/li&gt;\n&lt;li&gt;Want to learn more about machine learning research and its applications and collaborate closely with researchers&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts and ethics of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Designing a code base so that anyone can quickly code experiments, launch them, and analyze their results without hitting bugs&lt;/li&gt;\n&lt;li&gt;Optimizing the performance of large-scale distributed systems&lt;/li&gt;\n&lt;li&gt;Collaborating closely with researchers&lt;/li&gt;\n&lt;li&gt;Language modeling with transformers&lt;/li&gt;\n&lt;li&gt;GPUs or Pytorch&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;h2&gt;Representative Projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Building &lt;a href=&quot;https://transformer-circuits.pub/2021/garcon/index.html&quot;&gt;Garcon&lt;/a&gt;, a tool that allows researchers to easily access LLMs internals from a jupyter notebook&lt;/li&gt;\n&lt;li&gt;Setting up and optimizing a pipeline to efficiently collect petabytes of transformer activations and shuffle them.&lt;/li&gt;\n&lt;li&gt;Profiling and optimizing ML training, including parallelizing to many GPUs&lt;/li&gt;\n&lt;li&gt;Make launching ML experiments and manipulating+analyzing the results fast and easy&lt;/li&gt;\n&lt;li&gt;Creating an interactive visualization of attention between tokens in a language model&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Role Specific Location Policy:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;This role is based in San Francisco office; however, we are open to considering exceptional candidates for remote work on a case-by-case basis.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$315,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$560,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4980430008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Machine Learning (Horizons) ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4613568008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About Horizons The Horizons team leads Anthropic's reinforcement learning research and development, playing a critical role in advancing our AI systems. We've contributed to all Claude models, with significant impacts on the autonomy and coding capabilities of Claude 3.5 and 3.7 Sonnet. Our work spans several key areas: Developing systems that enable models to use computers effectively Advancing code generation through reinforcement learning Pioneering fundamental RL research for large language models Building scalable RL infrastructure and training methodologies Enhancing model reasoning capabilities We collaborate closely with Anthropic's alignment and frontier red teams to ensure our systems are both capable and safe. We partner with the applied production training team to bring research innovations into deployed models, and work hand-in-hand with dedicated RL engineering teams to implement our research at scale. The Horizons team sits at the intersection of cutting-edge research and engineering excellence, with a deep commitment to building high-quality, scalable systems that push the boundaries of what AI can accomplish. About the Role As a Research Engineer on the Horizons team, you will collaborate with a diverse group of researchers and engineers to advance the capabilities and safety of large language models. This role blends research and engineering responsibilities, requiring you to both implement novel approaches and contribute to the research direction. You'll work on fundamental research in reinforcement learning, creating 'agentic' models via tool use for open-ended tasks such as computer use and autonomous software generation, improving reasoning abilities in areas such as mathematics, and developing prototypes for internal use, productivity, and evaluation. Representative projects: Architect and optimize core reinforcement learning infrastructure, from clean training abstractions to distributed experiment management across GPU clusters. Help scale our systems to handle increasingly complex research workflows. Design, implement, and test novel training environments, evaluations, and methodologies for reinforcement learning agents which push the state of the art for the next generation of models. Drive performance improvements across our stack through profiling, optimization, and benchmarking. Implement efficient caching solutions and debug distributed systems to accelerate both training and evaluation workflows. Collaborate across research and engineering teams to develop automated testing frameworks, design clean APIs, and build scalable infrastructure that accelerates AI research. You may be a good fit if you: Are proficient in Python and async/concurrent programming with frameworks like Trio Have experience with machine learning frameworks (PyTorch, TensorFlow, JAX) Have industry experience in machine learning research Can balance research exploration with engineering implementation Enjoy pair programming (we love to pair!) Care about code quality, testing, and performance Have strong systems design and communication skills Are passionate about the potential impact of AI and are committed to developing safe and beneficial systems Strong candidates may have: Familiarity with LLM architectures and training methodologies Experience with reinforcement learning techniques and environments Experience with virtualization and sandboxed code execution environments Experience with Kubernetes Experience with distributed systems or high-performance computing Experience with Rust and/or C++ Strong candidates need not have: Formal certifications or education credentials Academic research experience or publication history Deadline to apply: None. Applications will be reviewed on a rolling basis. The expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.Annual Salary:$280,000 - $425,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4613568008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4613568008",
    "title": "Research Engineer, Machine Learning (Horizons) ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4613568008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-03T04:44:24.618Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About Horizons&lt;/h2&gt;\n&lt;p&gt;The Horizons team leads Anthropic&#39;s reinforcement learning research and development, playing a critical role in advancing our AI systems. We&#39;ve contributed to all Claude models, with significant impacts on the autonomy and coding capabilities of Claude 3.5 and 3.7 Sonnet. Our work spans several key areas:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Developing systems that enable models to use computers effectively&lt;/li&gt;\n&lt;li&gt;Advancing code generation through reinforcement learning&lt;/li&gt;\n&lt;li&gt;Pioneering fundamental RL research for large language models&lt;/li&gt;\n&lt;li&gt;Building scalable RL infrastructure and training methodologies&lt;/li&gt;\n&lt;li&gt;Enhancing model reasoning capabilities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;We collaborate closely with Anthropic&#39;s alignment and frontier red teams to ensure our systems are both capable and safe. We partner with the applied production training team to bring research innovations into deployed models, and work hand-in-hand with dedicated RL engineering teams to implement our research at scale. The Horizons team sits at the intersection of cutting-edge research and engineering excellence, with a deep commitment to building high-quality, scalable systems that push the boundaries of what AI can accomplish.&lt;/p&gt;\n&lt;/div&gt;\n&lt;h2&gt;About the Role&lt;/h2&gt;\n&lt;div&gt;\n&lt;p&gt;As a Research Engineer on the Horizons team, you will collaborate with a diverse group of researchers and engineers to advance the capabilities and safety of large language models. This role blends research and engineering responsibilities, requiring you to both implement novel approaches and contribute to the research direction. You&#39;ll work on fundamental research in reinforcement learning, creating &#39;agentic&#39; models via tool use for open-ended tasks such as computer use and autonomous software generation, improving reasoning abilities in areas such as mathematics, and developing prototypes for internal use, productivity, and evaluation.&lt;/p&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Architect and optimize core reinforcement learning infrastructure, from clean training abstractions to distributed experiment management across GPU clusters. Help scale our systems to handle increasingly complex research workflows.&lt;/li&gt;\n&lt;li&gt;Design, implement, and test novel training environments, evaluations, and methodologies for reinforcement learning agents which push the state of the art for the next generation of models.&lt;/li&gt;\n&lt;li&gt;Drive performance improvements across our stack through profiling, optimization, and benchmarking. Implement efficient caching solutions and debug distributed systems to accelerate both training and evaluation workflows.&lt;/li&gt;\n&lt;li&gt;Collaborate across research and engineering teams to develop automated testing frameworks, design clean APIs, and build scalable infrastructure that accelerates AI research.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Are proficient in Python and async/concurrent programming with frameworks like Trio&lt;/li&gt;\n&lt;li&gt;Have experience with machine learning frameworks (PyTorch, TensorFlow, JAX)&lt;/li&gt;\n&lt;li&gt;Have industry experience in machine learning research&lt;/li&gt;\n&lt;li&gt;Can balance research exploration with engineering implementation&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Care about code quality, testing, and performance&lt;/li&gt;\n&lt;li&gt;Have strong systems design and communication skills&lt;/li&gt;\n&lt;li&gt;Are passionate about the potential impact of AI and are committed to developing safe and beneficial systems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may have:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;ul&gt;\n&lt;li&gt;Familiarity with LLM architectures and training methodologies&lt;/li&gt;\n&lt;li&gt;Experience with reinforcement learning techniques and environments&lt;/li&gt;\n&lt;li&gt;Experience with virtualization and sandboxed code execution environments&lt;/li&gt;\n&lt;li&gt;Experience with Kubernetes&lt;/li&gt;\n&lt;li&gt;Experience with distributed systems or high-performance computing&lt;/li&gt;\n&lt;li&gt;Experience with Rust and/or C++&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates need not have:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;ul&gt;\n&lt;li&gt;Formal certifications or education credentials&lt;/li&gt;\n&lt;li&gt;Academic research experience or publication history&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The expected&amp;nbsp;base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$280,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$425,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4613568008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]