[
  {
    "job_title": "Privacy Counsel",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4980527008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role Anthropic is seeking a Privacy Counsel to join our Legal team. The ideal candidate will have a strong background in counseling complex privacy issues, with a proven track record of building robust processes and programs to address complex privacy and data protection issues in a global context. This is a unique opportunity to join a dynamic and growing team, where you will have the chance to shape the company's privacy and data protection strategy and compliance program. If you are a collaborative, results-driven professional with a passion for privacy and a desire to make a real impact, we would love to hear from you. Responsibilities: Develop and implement comprehensive privacy strategies that align with the technology, product, and services Anthropic is building and our overall company goals Provide expert legal advice and guidance on privacy and data protection law (including state and federal privacy and consumer protection laws, GDPR and other international privacy laws) Work with cross-functional teams to design and implement privacy-by-design principles in product development, particularly in the realm of general purpose AI models and systems Collaborate with frontier counsel and product counsel to integrate privacy considerations into model development and product planning Maintain relationships with key regulators and stay abreast of emerging legal and regulatory developments in the global privacy landscape Collaborate closely with our privacy program team on the maintenance and maturation of our global privacy compliance program, governance framework, accountability documentation, internal and external policies and related training You may be a good fit if you have: A JD and active membership in at least one U.S. state bar (California preferred) At least 8 years of global privacy and data protection legal experience, preferably in hyper-growth global technology environments Deep subject matter expertise in privacy and data protection law and its practical application in a global context Extensive experience advising on privacy, data protection, and direct marketing laws, regulations, and guidance Strong understanding of the interplay between privacy, security, and AI, and the ability to provide strategic guidance in these areas Excellent leadership skills and the ability to drive projects forward in a fast-paced, hands-on environment Exceptional communication and stakeholder management skills, with the ability to build strong relationships with regulators, internal teams, and external partners A proven ability to think strategically and translate complex legal concepts into practical business solutions Strong candidates may have: Experience with privacy regulations in other international jurisdictions, enabling them to support the organization's global data protection compliance efforts Experience with privacy-enhancing technologies and their implementation in a business setting Knowledge and experience with AI-specific regulations and their interplay with privacy frameworks A network of contacts within the data protection community, allowing them to stay informed about best practices and share knowledge with peers Role-specific policy: For this role, we expect all staff to be able to work from our San Francisco office at least 3 days a week, though we encourage you to apply even if you might need some flexibility for an interim period of timeThe annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$265,000 - $320,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4980527008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4980527008",
    "title": "Privacy Counsel",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4980527008",
    "departments": [
      "Legal"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is seeking a Privacy Counsel to join our Legal team. The ideal candidate will have a strong background in counseling complex privacy issues, with a proven track record of building robust processes and programs to address complex privacy and data protection issues in a global context. This is a unique opportunity to join a dynamic and growing team, where you will have the chance to shape the company&#39;s privacy and data protection strategy and compliance program. If you are a collaborative, results-driven professional with a passion for privacy and a desire to make a real impact, we would love to hear from you.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and implement comprehensive privacy strategies that align with the technology, product, and services Anthropic is building and our overall company goals&lt;/li&gt;\n&lt;li&gt;Provide expert legal advice and guidance on privacy and data protection law (including state and federal privacy and consumer protection laws, GDPR and other international privacy laws)&lt;/li&gt;\n&lt;li&gt;Work with cross-functional teams to design and implement privacy-by-design principles in product development, particularly in the realm of general purpose AI models and systems&lt;/li&gt;\n&lt;li&gt;Collaborate with frontier counsel and product counsel to integrate privacy considerations into model development and product planning&lt;/li&gt;\n&lt;li&gt;Maintain relationships with key regulators and stay abreast of emerging legal and regulatory developments in the global privacy landscape&lt;/li&gt;\n&lt;li&gt;Collaborate closely with our privacy program team on the maintenance and maturation of our global privacy compliance program, governance framework, accountability documentation, internal and external policies and related training&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;A JD and active membership in at least one U.S. state bar (California preferred)&lt;/li&gt;\n&lt;li&gt;At least 8 years of global privacy and data protection legal experience, preferably in hyper-growth global technology environments&lt;/li&gt;\n&lt;li&gt;Deep subject matter expertise in privacy and data protection law and its practical application in a global context&lt;/li&gt;\n&lt;li&gt;Extensive experience advising on privacy, data protection, and direct marketing laws, regulations, and guidance&lt;/li&gt;\n&lt;li&gt;Strong understanding of the interplay between privacy, security, and AI, and the ability to provide strategic guidance in these areas&lt;/li&gt;\n&lt;li&gt;Excellent leadership skills and the ability to drive projects forward in a fast-paced, hands-on environment&lt;/li&gt;\n&lt;li&gt;Exceptional communication and stakeholder management skills, with the ability to build strong relationships with regulators, internal teams, and external partners&lt;/li&gt;\n&lt;li&gt;A proven ability to think strategically and translate complex legal concepts into practical business solutions&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with privacy regulations in other international jurisdictions, enabling them to support the organization&#39;s global data protection compliance efforts&lt;/li&gt;\n&lt;li&gt;Experience with privacy-enhancing technologies and their implementation in a business setting&lt;/li&gt;\n&lt;li&gt;Knowledge and experience with AI-specific regulations and their interplay with privacy frameworks&lt;/li&gt;\n&lt;li&gt;A network of contacts within the data protection community, allowing them to stay informed about best practices and share knowledge with peers&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Role-specific policy:&amp;nbsp;&lt;/strong&gt;For this role, we expect all staff to be able to work from our San Francisco office at least 3 days a week, though we encourage you to apply even if you might need some flexibility for an interim period of time&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$265,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$320,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4980527008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Privacy Research Engineer, Safeguards",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4949108008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role We are looking for researchers to help mitigate the risks that come with building AI systems. One of these risks is the potential for models to interact with private user data. In this role, you'll design and implement privacy-preserving techniques, audit our current techniques, and set the direction for how Anthropic handles privacy more broadly. Responsibilities: Lead our privacy analysis of frontier models, carefully auditing the use of data and ensuring safety throughout the process Develop privacy-first training algorithms and techniques Develop evaluation and auditing techniques to measure the privacy of training algorithms Work with a small, senior team of engineers and researchers to enact a forward-looking privacy policy Advocate on behalf of our users to ensure responsible handling of all data You may be a good fit if you have: Experience working on privacy-preserving machine learning A track record of shipping products and features inside a fast-moving environment Strong coding skills in Python and familiarity with ML frameworks like PyTorch or JAX. Deep familiarity with large language models, how they work, and how they are trained Have experience working with privacy-preserving techniques (e.g., differential privacy and how it is different from k-anonymity, l-diversity, and t-closeness) Experience supporting fast-paced startup engineering teams Demonstrated success in bringing clarity and ownership to ambiguous technical problems Proven ability to lead cross-functional security initiatives and navigate complex organizational dynamics Strong candidates may also: Have published papers on the topic of privacy-preserving ML at top academic venues Prior experience training large language models (e.g., collecting training datasets, pre-training models, post-training models via fine-tuning and RL, running evaluations on trained models) Prior experience developing tooling to support privacy-preserving ML (e.g., differential privacy in TF-Privacy or Opacus) The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$320,000 - $485,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4949108008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4949108008",
    "title": "Privacy Research Engineer, Safeguards",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4949108008",
    "departments": [
      "Safeguards (Trust & Safety) "
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We are looking for researchers to help mitigate the risks that come with building AI systems. One of these risks is the potential for models to interact with private user data. In this role, you&#39;ll design and implement privacy-preserving techniques, audit our current techniques, and set the direction for how Anthropic handles privacy more broadly.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead our privacy analysis of frontier models, carefully auditing the use of data and ensuring safety throughout the process&lt;/li&gt;\n&lt;li&gt;Develop privacy-first training algorithms and techniques&lt;/li&gt;\n&lt;li&gt;Develop evaluation and auditing techniques to measure the privacy of training algorithms&lt;/li&gt;\n&lt;li&gt;Work with a small, senior team of engineers and researchers to enact a forward-looking privacy policy&lt;/li&gt;\n&lt;li&gt;Advocate on behalf of our users to ensure responsible handling of all data&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience working on privacy-preserving machine learning&lt;/li&gt;\n&lt;li&gt;A track record of shipping products and features inside a fast-moving environment&lt;/li&gt;\n&lt;li&gt;Strong coding skills in Python and familiarity with ML frameworks like PyTorch or JAX.&lt;/li&gt;\n&lt;li&gt;Deep familiarity with large language models, how they work, and how they are trained&lt;/li&gt;\n&lt;li&gt;Have experience working with privacy-preserving techniques (e.g., differential privacy and how it is different from k-anonymity, l-diversity, and t-closeness)&lt;/li&gt;\n&lt;li&gt;Experience supporting fast-paced startup engineering teams&lt;/li&gt;\n&lt;li&gt;Demonstrated success in bringing clarity and ownership to ambiguous technical problems&lt;/li&gt;\n&lt;li&gt;Proven ability to lead cross-functional security initiatives and navigate complex organizational dynamics&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have published papers on the topic of privacy-preserving ML at top academic venues&lt;/li&gt;\n&lt;li&gt;Prior experience training large language models (e.g., collecting training datasets, pre-training models, post-training models via fine-tuning and RL, running evaluations on trained models)&lt;/li&gt;\n&lt;li&gt;Prior experience developing tooling to support privacy-preserving ML (e.g., differential privacy in TF-Privacy or Opacus)&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$320,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$485,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4949108008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Designer, Claude Experiences",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4929512008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator:&amp;nbsp;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs.&lt;/li&gt;\n&lt;li&gt;Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy.&lt;/li&gt;\n&lt;li&gt;Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility.&lt;/li&gt;\n&lt;li&gt;We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Read more &lt;a href=&quot;https://www.anthropic.com/news&quot;&gt;here&lt;/a&gt; for the type of features we build.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&amp;nbsp;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;This is a lead role whose work will range from late breaking features for model launches to shaping first in industry experiences powered by our emerging capabilities.&lt;/li&gt;\n&lt;li&gt;Craft coherent Claude experiences that delight at every touchpoint, making AI collab feel effortless, pro-human, and essential to how work gets done.&lt;/li&gt;\n&lt;li&gt;Work with cross functional partners to establish a vision that transforms Claude from a chatbot to a work platform.&lt;/li&gt;\n&lt;li&gt;Pioneer new ways for Claude to be a true partner in people’s day to day lives that can access your tools, ask for feedback, help you prep for your day, and more.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred)&lt;/li&gt;\n&lt;li&gt;Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms&lt;/li&gt;\n&lt;li&gt;Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments&lt;/li&gt;\n&lt;li&gt;Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority&lt;/li&gt;\n&lt;li&gt;Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities&lt;/li&gt;\n&lt;li&gt;Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ship opinionated products and make things customers want.&lt;/li&gt;\n&lt;li&gt;Model a builder mindset to explore and communicate through prototyping and design.&lt;/li&gt;\n&lt;li&gt;Build trust with users through craft and connection.&lt;/li&gt;\n&lt;li&gt;Be proactive and make things happen in a startup environment&lt;/li&gt;\n&lt;li&gt;Have a technical understanding of LLMs and can build on top of them.&lt;/li&gt;\n&lt;li&gt;Design new, functional and easy to use interaction design conventions that are on the frontier.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$260,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4929512008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4929512008",
    "title": "Product Designer, Claude Experiences",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4929512008",
    "departments": [
      "Engineering & Design - Product"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator:&amp;nbsp;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs.&lt;/li&gt;\n&lt;li&gt;Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy.&lt;/li&gt;\n&lt;li&gt;Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility.&lt;/li&gt;\n&lt;li&gt;We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Read more &lt;a href=&quot;https://www.anthropic.com/news&quot;&gt;here&lt;/a&gt; for the type of features we build.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&amp;nbsp;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;This is a lead role whose work will range from late breaking features for model launches to shaping first in industry experiences powered by our emerging capabilities.&lt;/li&gt;\n&lt;li&gt;Craft coherent Claude experiences that delight at every touchpoint, making AI collab feel effortless, pro-human, and essential to how work gets done.&lt;/li&gt;\n&lt;li&gt;Work with cross functional partners to establish a vision that transforms Claude from a chatbot to a work platform.&lt;/li&gt;\n&lt;li&gt;Pioneer new ways for Claude to be a true partner in people’s day to day lives that can access your tools, ask for feedback, help you prep for your day, and more.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred)&lt;/li&gt;\n&lt;li&gt;Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms&lt;/li&gt;\n&lt;li&gt;Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments&lt;/li&gt;\n&lt;li&gt;Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority&lt;/li&gt;\n&lt;li&gt;Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities&lt;/li&gt;\n&lt;li&gt;Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ship opinionated products and make things customers want.&lt;/li&gt;\n&lt;li&gt;Model a builder mindset to explore and communicate through prototyping and design.&lt;/li&gt;\n&lt;li&gt;Build trust with users through craft and connection.&lt;/li&gt;\n&lt;li&gt;Be proactive and make things happen in a startup environment&lt;/li&gt;\n&lt;li&gt;Have a technical understanding of LLMs and can build on top of them.&lt;/li&gt;\n&lt;li&gt;Design new, functional and easy to use interaction design conventions that are on the frontier.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$260,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4929512008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": false
  },
  {
    "job_title": "Product Designer, Growth ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4963443008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator: We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs. Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy. Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility. We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement. Read more here for the type of features we build. Responsibilities: Design intuitive onboarding flows that help new users get started quickly, understand Claude's capabilities, and achieve their goals in the first session. Create scalable education systems that help people deepen their understanding of Claude over time and seamlessly integrate it into their workflows Design clear, trust-building upgrade experiences that help users understand the right plan for their needs. Uncover barriers that prevent users from getting the most out of Claude and create experiences that empower them to make it a trusted part of their routine. Contribute to the strategic direction of our tools, rooted in deep user empathy Define feature areas with exceptional attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps Rapidly prototype ideas using code and other methods to communicate concepts and build excitement Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment You may be a good fit if you have: 8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred) Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred Strong candidates may: Ship opinionated products and make things customers want. Model a builder mindset to explore and communicate through prototyping and design. Build trust with users through craft and connection. Be proactive and make things happen in a startup environment Have a technical understanding of LLMs and can build on top of them. Design new, functional and easy to use interaction design conventions that are on the frontier. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$260,000 - $305,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4963443008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4963443008",
    "title": "Product Designer, Growth ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4963443008",
    "departments": [
      "Engineering & Design - Product"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator:&amp;nbsp;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs.&lt;/li&gt;\n&lt;li&gt;Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy.&lt;/li&gt;\n&lt;li&gt;Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility.&lt;/li&gt;\n&lt;li&gt;We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Read more&amp;nbsp;&lt;a href=&quot;https://www.anthropic.com/news&quot;&gt;here&lt;/a&gt; for the type of features we build.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design intuitive onboarding flows that help new users get started quickly, understand Claude&#39;s capabilities, and achieve their goals in the first session.&lt;/li&gt;\n&lt;li&gt;Create scalable education systems that help people deepen their understanding of Claude over time and seamlessly integrate it into their workflows&lt;/li&gt;\n&lt;li&gt;Design clear, trust-building upgrade experiences that help users understand the right plan for their needs.&lt;/li&gt;\n&lt;li&gt;Uncover barriers that prevent users from getting the most out of Claude and create experiences that empower them to make it a trusted part of their routine.&lt;/li&gt;\n&lt;li&gt;Contribute to the strategic direction of our tools, rooted in deep user empathy&lt;/li&gt;\n&lt;li&gt;Define feature areas with exceptional attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows&lt;/li&gt;\n&lt;li&gt;Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology&lt;/li&gt;\n&lt;li&gt;Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps&lt;/li&gt;\n&lt;li&gt;Rapidly prototype ideas using code and other methods to communicate concepts and build excitement&lt;/li&gt;\n&lt;li&gt;Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred)&lt;/li&gt;\n&lt;li&gt;Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms&lt;/li&gt;\n&lt;li&gt;Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments&lt;/li&gt;\n&lt;li&gt;Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority&lt;/li&gt;\n&lt;li&gt;Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities&lt;/li&gt;\n&lt;li&gt;Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ship opinionated products and make things customers want.&lt;/li&gt;\n&lt;li&gt;Model a builder mindset to explore and communicate through prototyping and design.&lt;/li&gt;\n&lt;li&gt;Build trust with users through craft and connection.&lt;/li&gt;\n&lt;li&gt;Be proactive and make things happen in a startup environment&lt;/li&gt;\n&lt;li&gt;Have a technical understanding of LLMs and can build on top of them.&lt;/li&gt;\n&lt;li&gt;Design new, functional and easy to use interaction design conventions that are on the frontier.&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$260,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4963443008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Manager, API ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4936029008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Product Manager for our API team at Anthropic, you will drive the development and adoption of our API platform across enterprise organizations. You'll own the end-to-end enterprise API experience, focusing on building scalable, secure, and compliant solutions that enable organizations to confidently integrate Claude into their systems and workflows. Working at the intersection of developer experience and enterprise needs, you'll transform our API into a trusted enterprise solution that delivers measurable value across teams and functions. Responsibilities: Customer Understanding & Advocacy Deeply engage with enterprise developers and technical leaders to understand their integration needs and pain points Run regular feedback sessions and technical reviews with key enterprise customers Build strong relationships with enterprise development teams to understand their workflows and challenges Transform customer insights into actionable product requirements and priorities Product Strategy & Vision Define and execute the enterprise API strategy, balancing security requirements with developer experience Develop a clear roadmap for enterprise API features including authentication, rate limiting, and compliance capabilities Identify and prioritize key enterprise integration patterns that drive organizational value Enterprise API Development Partner with engineering to build enterprise-grade API features, security controls, and deployment tools Design and implement enterprise integration frameworks and SDKs for common enterprise systems Drive development of industry-specific API features and compliance capabilities Cross-functional Leadership Partner with sales and customer success to understand enterprise requirements and support technical evaluations Work closely with security and compliance teams to meet enterprise standards Collaborate with platform teams on API architecture and scalability Engage with marketing to develop enterprise API positioning and technical materials You may be a good fit if you have: 5+ years of product management experience, with significant experience in API and enterprise software Strong technical background with understanding of API architecture and integration patterns Track record of successfully launching and scaling enterprise API products Demonstrated ability to build strong relationships with technical customers and translate their needs into product features Strong understanding of enterprise security, compliance, and deployment requirements Proficiency in with business analytics and experience with data-driven decision making Excellence in cross-functional collaboration and stakeholder management Clear communication skills with ability to engage with both technical and business stakeholders The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$305,000 - $385,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4936029008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4936029008",
    "title": "Product Manager, API ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4936029008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&amp;nbsp;&lt;/h2&gt;\n&lt;p&gt;As a Product Manager for our API team at Anthropic, you will drive the development and adoption of our API platform across enterprise organizations. You&#39;ll own the end-to-end enterprise API experience, focusing on building scalable, secure, and compliant solutions that enable organizations to confidently integrate Claude into their systems and workflows. Working at the intersection of developer experience and enterprise needs, you&#39;ll transform our API into a trusted enterprise solution that delivers measurable value across teams and functions.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Customer Understanding &amp;amp; Advocacy&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Deeply engage with enterprise developers and technical leaders to understand their integration needs and pain points&lt;/li&gt;\n&lt;li&gt;Run regular feedback sessions and technical reviews with key enterprise customers&lt;/li&gt;\n&lt;li&gt;Build strong relationships with enterprise development teams to understand their workflows and challenges&lt;/li&gt;\n&lt;li&gt;Transform customer insights into actionable product requirements and priorities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Product Strategy &amp;amp; Vision&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Define and execute the enterprise API strategy, balancing security requirements with developer experience&lt;/li&gt;\n&lt;li&gt;Develop a clear roadmap for enterprise API features including authentication, rate limiting, and compliance capabilities&lt;/li&gt;\n&lt;li&gt;Identify and prioritize key enterprise integration patterns that drive organizational value&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Enterprise API Development&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Partner with engineering to build enterprise-grade API features, security controls, and deployment tools&lt;/li&gt;\n&lt;li&gt;Design and implement enterprise integration frameworks and SDKs for common enterprise systems&lt;/li&gt;\n&lt;li&gt;Drive development of industry-specific API features and compliance capabilities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Cross-functional Leadership&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Partner with sales and customer success to understand enterprise requirements and support technical evaluations&lt;/li&gt;\n&lt;li&gt;Work closely with security and compliance teams to meet enterprise standards&lt;/li&gt;\n&lt;li&gt;Collaborate with platform teams on API architecture and scalability&lt;/li&gt;\n&lt;li&gt;Engage with marketing to develop enterprise API positioning and technical materials&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of product management experience, with significant experience in API and enterprise software&lt;/li&gt;\n&lt;li&gt;Strong technical background with understanding of API architecture and integration patterns&lt;/li&gt;\n&lt;li&gt;Track record of successfully launching and scaling enterprise API products&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to build strong relationships with technical customers and translate their needs into product features&lt;/li&gt;\n&lt;li&gt;Strong understanding of enterprise security, compliance, and deployment requirements&lt;/li&gt;\n&lt;li&gt;Proficiency in with business analytics and experience with data-driven decision making&lt;/li&gt;\n&lt;li&gt;Excellence in cross-functional collaboration and stakeholder management&lt;/li&gt;\n&lt;li&gt;Clear communication skills with ability to engage with both technical and business stakeholders&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$305,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$385,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4936029008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Manager, Claude Code",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4985920008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Product Manager for Claude Code, you will drive the evolution of the Claude Code product suite and help shape how developers work with AI. You will work closely with internal users and customers to prioritize their requirements and ship improvements to Claude Code. You will work closely with the engineering team, research team, and XFN teams to ensure Claude Code remains ahead of model capabilities and is seen as the best way to experience the most intelligent Claude models. In just a few months since launch, Claude Code has already redefined how developers interact with AI. Yet we are only scratching the surface. As model intelligence accelerates, the ultimate form factor of agentic software development remains unwritten. We seek a product manager who combines deep technical understanding, genuine love for developers, and strong product intuition. You should be equally comfortable discussing customer feedback with world-class researchers, debugging user workflows with engineers, and presenting product strategy to executives. Responsibilities: Define the roadmap for an area of the Claude Code product suite Translate cutting-edge AI advances into practical developer features Build an ecosystem around the CLI and other products so that developers can easily share best practices You might be a good fit if you: Have a combined 5+ years in product management and engineering, including at least 1 year as a professional engineer. Have a deep technical background with experience working cross-functionally with engineering teams to ship technical products. Track record of launching ambitious products that have achieved distribution or commercial success. Experience in dev tools is preferred. Stay up-to-date and hands-on with AI coding tools, model capabilities, and industry trends Have a creative, hacker spirit and love solving puzzles The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$285,000 - $305,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4985920008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4985920008",
    "title": "Product Manager, Claude Code",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | Seattle, WA",
    "locations": [
      "San Francisco, CA | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4985920008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a Product Manager for Claude Code, you will drive the evolution of the Claude Code product suite and help shape how developers work with AI. You will work closely with internal users and customers to prioritize their requirements and ship improvements to Claude Code. You will work closely with the engineering team, research team, and XFN teams to ensure Claude Code remains ahead of model capabilities and is seen as the best way to experience the most intelligent Claude models.&lt;/p&gt;\n&lt;p&gt;In just a few months since launch, Claude Code has already redefined how developers interact with AI. Yet we are only scratching the surface. As model intelligence accelerates, the ultimate form factor of agentic software development remains unwritten. We seek a product manager who combines deep technical understanding, genuine love for developers, and strong product intuition. You should be equally comfortable discussing customer feedback with world-class researchers, debugging user workflows with engineers, and presenting product strategy to executives.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Define the roadmap for an area of the Claude Code product suite&lt;/li&gt;\n&lt;li&gt;Translate cutting-edge AI advances into practical developer features&lt;/li&gt;\n&lt;li&gt;Build an ecosystem around the CLI and other products so that developers can easily share best practices&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You might be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have a combined 5+ years in product management and engineering, including at least 1 year as a professional engineer.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Have a deep technical background with experience working cross-functionally with engineering teams to ship technical products.&lt;/li&gt;\n&lt;li&gt;Track record of launching ambitious products that have achieved distribution or commercial success. Experience in dev tools is preferred.&lt;/li&gt;\n&lt;li&gt;Stay up-to-date and hands-on with AI coding tools, model capabilities, and industry trends&lt;/li&gt;\n&lt;li&gt;Have a creative, hacker spirit and love solving puzzles&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$285,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4985920008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Manager, Research",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4933792008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Product Manager for the Research and Frontiers teams at Anthropic, you will own the ideation and deployment of new products as we advance transformative, safe AI. The Research Product Management team works closely with our researchers to productize credible applied research and identify high-potential use cases grounded in customer needs. This role will partner closely with Frontiers, which pushes the boundaries of our research capabilities into new experiences for end users and builders. Frontiers focuses on 0-to-1 product development, taking our most advanced research and transforming it into innovative applications like Claude Code. We seek experienced founders and product managers who can bridge pure research and ambitious product experimentation, with the ability to identify and ultimately define entirely new product categories enabled by AI. Responsibilities: Lead 0-to-1 product development from research to internal prototypes to shipped products Identify nascent research capabilities that could become transformative products Define product strategy for experimental initiatives that push beyond our current offerings Creatively build MVPs and prototypes to validate product-market fit with the lowest cost possible Lead vision, strategy, roadmap, and execution of frontier technologies that leverage the latest AI capabilities to solve real-world problems You might be a good fit if you: Have 5+ years in product management, with experience launching new products and scaling existing products. Founder background is a plus. Possess a deep technical background with experience working cross-functionally with engineering teams to ship technical products. A data-driven mindset with Python and SQL working proficiency is a must. Have the ability to navigate and execute amidst ambiguity, and to flex into different domains based on the business problem at hand, finding simple, easy-to-understand solutions Have a track record of launching ambitious products that have found distribution or commercial success Think creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks Stay up-to-date and hands-on with emerging research and industry trends Have a creative, hacker spirit and love solving puzzles The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$275,000 - $375,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4933792008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4933792008",
    "title": "Product Manager, Research",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4933792008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Product Manager for the Research and Frontiers teams at Anthropic, you will own the ideation and deployment of new products as we advance transformative, safe AI. The Research Product Management team works closely with our researchers to productize credible applied research and identify high-potential use cases grounded in customer needs. This role will partner closely with Frontiers, which pushes the boundaries of our research capabilities into new experiences for end users and builders. Frontiers focuses on 0-to-1 product development, taking our most advanced research and transforming it into innovative applications like Claude Code.&lt;/p&gt;\n&lt;p&gt;We seek experienced founders and product managers who can bridge pure research and ambitious product experimentation, with the ability to identify and ultimately define entirely new product categories enabled by AI.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead 0-to-1 product development from research to internal prototypes to shipped products&lt;/li&gt;\n&lt;li&gt;Identify nascent research capabilities that could become transformative products&lt;/li&gt;\n&lt;li&gt;Define product strategy for experimental initiatives that push beyond our current offerings&lt;/li&gt;\n&lt;li&gt;Creatively build MVPs and prototypes to validate product-market fit with the lowest cost possible&lt;/li&gt;\n&lt;li&gt;Lead vision, strategy, roadmap, and execution of frontier technologies that leverage the latest AI capabilities to solve real-world problems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You might be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 5+ years in product management, with experience launching new products and scaling existing products. Founder background is a plus.&lt;/li&gt;\n&lt;li&gt;Possess a deep technical background with experience working cross-functionally with engineering teams to ship technical products. A data-driven mindset with Python and SQL working proficiency is a must.&lt;/li&gt;\n&lt;li&gt;Have the ability to navigate and execute amidst ambiguity, and to flex into different domains based on the business problem at hand, finding simple, easy-to-understand solutions&lt;/li&gt;\n&lt;li&gt;Have a track record of launching ambitious products that have found distribution or commercial success&lt;/li&gt;\n&lt;li&gt;Think creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks&lt;/li&gt;\n&lt;li&gt;Stay up-to-date and hands-on with emerging research and industry trends&lt;/li&gt;\n&lt;li&gt;Have a creative, hacker spirit and love solving puzzles&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$275,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$375,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4933792008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Manager, Safeguards",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4932942008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role Anthropic is dedicated to developing AI assistants that are helpful, harmless, and honest. As usage of our AI services grows, we need to ensure they are not misused. The Safeguards team is at the forefront of protecting our users from the risks of powerful AIs as well as ethical, technical, and social risks from the use of generative AI. The Safeguards team at Anthropic builds protections for new AI features enabled by the research teams and protects new products and surfaces developed by our product teams. As a Product Manager for the Safeguards team at Anthropic, you will own the ideation, design, development and deployment of Safeguards systems and relevant product UX to ensure we are advancing frontier models safely to users across various cloud platforms. You will work closely with our research and product teams to develop detections, evals, interventions, and tools to measure and mitigate deployment and user risks. We are looking for a product manager who is deeply committed to making AI safe and beneficial for humanity. You are aware of the risks and are committed to working with experts and coming up with ideas for Anthropic to implement. You have deep technical expertise in development, deployment and measurement of Safeguards systems. You thrive in rapidly moving and ambiguous environments. Responsibilities: Determine how to build in safety by design upstream and leverage downstream defenses for Anthropic’s frontier models, AI products, customers on different surfaces - Claude.ai, 1P API, external Cloud providers. Ability to write safety evals and communicate externally about safety. Drive impact via ruthless prioritization by clearly defining problems, solution options forward, clarity on both business & technical tradeoffs and accordingly clear requirements toward MVP vs. ideal state. Align & collaborate with policy, enforcement, research, engineering and cross functional stakeholders. Understand the AI landscape and ecosystem to plan for mitigation of deployment risks of increasingly powerful models and determined adversaries. Lead the development of metrics to understand the area, performance, blindspots to help inform future project planning. You may be a good fit if you have: 5+ years in product management with a focus on fast problem understanding, building roadmaps with tractable progress, ability to get into the details on data, detection & interventions, infrastructure & tools, and/or evals. Ability to make technical tradeoff decisions; ideally with experience working across policy experts, AI/ML research engineers and software engineering teams to design and build state of the art safety systems. Strong user understanding of how our products are used, their Safeguards concerns and how we provide the best solutions. Demonstrated ability to build product and engineering strategy across multiple cross-functional teams for a rapidly changing space. Demonstrated experience in designing and building metrics to evaluate risks, system performance, user impact and making crisp tradeoffs Very strong ability to navigate, and prioritize amidst rapidly changing product specs, and to flex into different domains to bring clarity and execute. Evidence of exercising judgment and decision making in ambiguous situations. Planning, building, launching and measuring new products / systems in a zero to one environment. Ability to clearly articulate complex technical concepts to non-technical audiences in written and verbal communication. Think creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$305,000 - $385,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4932942008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4932942008",
    "title": "Product Manager, Safeguards",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4932942008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;Anthropic is dedicated to developing AI assistants that are helpful, harmless, and honest. As usage of our AI services grows, we need to ensure they are not misused. The Safeguards team is at the forefront of protecting our users from the risks of powerful AIs as well as ethical, technical, and social risks from the use of generative AI. The Safeguards team at Anthropic builds protections for new AI features enabled by the research teams and protects new products and surfaces developed by our product teams. As a Product Manager for the Safeguards team at Anthropic, you will own the ideation, design, development and deployment of Safeguards systems and relevant product UX to ensure we are advancing frontier models safely to users across various cloud platforms. You will work closely with our research and product teams to develop detections, evals, interventions, and tools to measure and mitigate deployment and user risks.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;We are looking for a product manager who is deeply committed to making AI safe and beneficial for humanity.&amp;nbsp; You are aware of the risks and are committed to working with experts and coming up with ideas for Anthropic to implement. You have deep technical expertise in development, deployment and measurement of Safeguards systems. You thrive in rapidly moving and ambiguous environments.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Determine how to build in safety by design upstream and leverage downstream defenses for Anthropic’s frontier models, AI products, customers on different surfaces - Claude.ai, 1P API, external Cloud providers.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Ability to write safety evals and communicate externally about safety.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Drive impact via ruthless prioritization by clearly defining problems, solution options forward, clarity on both business &amp;amp; technical tradeoffs and accordingly clear requirements toward MVP vs. ideal state.&lt;/li&gt;\n&lt;li&gt;Align &amp;amp; collaborate with policy, enforcement, research, engineering and cross functional stakeholders.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Understand the AI landscape and ecosystem to plan for mitigation of deployment risks of increasingly powerful models and determined adversaries.&lt;/li&gt;\n&lt;li&gt;Lead the development of metrics to understand the area, performance, blindspots to help inform future project planning.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years in product management with a focus on fast problem understanding, building roadmaps with tractable progress, ability to get into the details on data, detection &amp;amp; interventions, infrastructure &amp;amp; tools, and/or evals.&lt;/li&gt;\n&lt;li&gt;Ability to make technical tradeoff decisions; ideally with experience working across policy experts, AI/ML research engineers and software engineering teams to design and build state of the art safety systems.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Strong user understanding of how our products are used, their Safeguards concerns and how we provide the best solutions.&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to build product and engineering strategy across multiple cross-functional teams for a rapidly changing space.&lt;/li&gt;\n&lt;li&gt;Demonstrated experience in designing and building metrics to evaluate risks, system performance, user impact and making crisp tradeoffs&lt;/li&gt;\n&lt;li&gt;Very strong ability to navigate, and prioritize amidst rapidly changing product specs, and to flex into different domains to bring clarity and execute.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Evidence of exercising judgment and decision making in ambiguous situations.&lt;/li&gt;\n&lt;li&gt;Planning, building, launching and measuring new products / systems in a zero to one environment.&lt;/li&gt;\n&lt;li&gt;Ability to clearly articulate complex technical concepts to non-technical audiences in written and verbal communication.&lt;/li&gt;\n&lt;li&gt;Think creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks.&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$305,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$385,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4932942008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Operations Manager",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4971429008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: We're hiring several Product Operations Managers to work directly with our Product and Engineering teams to build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities. The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way. The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product processes. They should be passionate about creating scalable systems that help Product teams better understand users, make data-driven decisions, execute efficiently, and deliver exceptional products. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization's effectiveness. Responsibilities: Inputs to Product Teams – Ensuring product teams have the information they need to make great decisions Voice of customer synthesis and feedback routing from strategic to tactical Create high-leverage engagement points with partners throughout the product lifecycle Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems Streamline the most important decision points for teams and impacted partners Ops of the Product Org – Creating the operating systems that enable product teams to thrive Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc) Create reliable run-of-business systems across product Improve common product development processes and tooling Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams Outputs from Product Teams – Amplifying product impact by connecting what we build to those who need it Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products Maintain launch motions that allow us to ship with confidence and monitor impact Create cross-team roadmap visibility that drives cross-functional alignment Make clear to all of Anthropic what Product is working on and how it's going You may be a good fit if you have: 5+ years of experience in product operations, program management, or related operational roles in tech companies Track record of building processes and programs from 0 to 1 and scaling them thoughtfully Experience working deeply embedded with product teams, serving as an extension of product leadership Strong cross-functional partnership skills with ability to influence without authority Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments Experience with launch coordination, early access programs, or customer feedback loops A passion for iterative, user-driven product development Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists. Mission-aligned with building safe and beneficial AI systems The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$165,000 - $190,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4971429008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4971429008",
    "title": "Product Operations Manager",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4971429008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;We&#39;re hiring several Product Operations Managers to work directly with our Product and Engineering teams to build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will &amp;nbsp;work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way.&lt;/p&gt;\n&lt;p&gt;The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product processes. They should be passionate about creating scalable systems that help Product teams better understand users, make data-driven decisions, execute efficiently, and deliver exceptional products. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization&#39;s effectiveness.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Inputs to Product Teams&lt;/strong&gt; – Ensuring product teams have the information they need to make great decisions&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Voice of customer synthesis and feedback routing from strategic to tactical&lt;/li&gt;\n&lt;li&gt;Create high-leverage engagement points with partners throughout the product lifecycle&lt;/li&gt;\n&lt;li&gt;Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses&lt;/li&gt;\n&lt;li&gt;Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems&lt;/li&gt;\n&lt;li&gt;Streamline the most important decision points for teams and impacted partners&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Ops of the Product Org&lt;/strong&gt; – Creating the operating systems that enable product teams to thrive&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc)&lt;/li&gt;\n&lt;li&gt;Create reliable run-of-business systems across product&lt;/li&gt;\n&lt;li&gt;Improve common product development processes and tooling&lt;/li&gt;\n&lt;li&gt;Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Outputs from Product Teams&lt;/strong&gt; – Amplifying product impact by connecting what we build to those who need it&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products&lt;/li&gt;\n&lt;li&gt;Maintain launch motions that allow us to ship with confidence and monitor impact&lt;/li&gt;\n&lt;li&gt;Create cross-team roadmap visibility that drives cross-functional alignment&lt;/li&gt;\n&lt;li&gt;Make clear to all of Anthropic what Product is working on and how it&#39;s going&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in product operations, program management, or related operational roles in tech companies&lt;/li&gt;\n&lt;li&gt;Track record of building processes and programs from 0 to 1 and scaling them thoughtfully&lt;/li&gt;\n&lt;li&gt;Experience working deeply embedded with product teams, serving as an extension of product leadership&lt;/li&gt;\n&lt;li&gt;Strong cross-functional partnership skills with ability to influence without authority&lt;/li&gt;\n&lt;li&gt;Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations&lt;/li&gt;\n&lt;li&gt;Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments&lt;/li&gt;\n&lt;li&gt;Experience with launch coordination, early access programs, or customer feedback loops&lt;/li&gt;\n&lt;li&gt;A passion for iterative, user-driven product development&lt;/li&gt;\n&lt;li&gt;Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists.&lt;/li&gt;\n&lt;li&gt;Mission-aligned with building safe and beneficial AI systems&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$165,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$190,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4971429008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Operations Manager, Public Sector ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4992055008",
    "job_posted_at_datetime_utc": "2025-11-22T09:28:05-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role: We're hiring a Product Operations Manager to work directly with our Product and Engineering teams on our Growth, Enterprise, and Verticals team. They will build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities. The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way. The Public Sector (PubSec) Product Team is responsible for launching our new models into Public Sector organizations. They are obsessed with the specific use cases and impact our work can have within Public Sector organizations and are willing to get into the weeds to break down any barriers to adoption or engagement. The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product delivery. They are passionate about creating scalable systems that help Product teams better understand users. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization's effectiveness. Responsibilities: Inputs to Product Teams – Ensuring product teams have the information they need to make great decisions Voice of customer synthesis and feedback routing from strategic to tactical Create high-leverage engagement points with partners throughout the product lifecycle Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems Streamline the most important decision points for teams and impacted partners Ops of the Product Org – Creating the operating systems that enable product teams to thrive Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc) Create reliable run-of-business systems across product Improve common product development processes and tooling Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams Outputs from Product Teams – Amplifying product impact by connecting what we build to those who need it Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products Maintain launch motions that allow us to ship with confidence and monitor impact Create cross-team roadmap visibility that drives cross-functional alignment Make clear to all of Anthropic what Product is working on and how it's going You may be a good fit if you have: 5+ years of experience in product operations, program management, or related operational roles in hyper-scaling tech companies Mission-aligned with building safe and beneficial AI systems Experience working with Public Sector organizations Track record of building processes and programs from 0 to 1 and scaling them thoughtfully Experience working deeply with AI and frontier models Strong cross-functional partnership skills with ability to influence without authority Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments Experience with launch coordination, early access programs, or customer feedback loops A passion for iterative, user-driven product development Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists. This position requires verification of U.S. citizenship due to citizenship-based legal restrictions. Specifically, this position supports a United States federal, state, and/or local government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law. To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government clearance.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$210,000 - $240,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4992055008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4992055008",
    "title": "Product Operations Manager, Public Sector ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4992055008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2025-11-22T09:28:05-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the Role:&lt;/h2&gt;\n&lt;p&gt;We&#39;re hiring a Product Operations Manager to work directly with our Product and Engineering teams on our Growth, Enterprise, and Verticals team. They will build, launch, and improve bleeding edge products that make the most of our frontier models’ capabilities.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;The Product Operations team connects strategy to execution by creating alignment up, down, and across the company. They will&amp;nbsp; work closely with Product Managers and Engineers to identify bottlenecks, streamline workflows, enhance decision-making processes, and scale our Product’s impact. Working as an extension of the product leadership team, they will balance hands-on tactical execution with strategic initiatives, bringing a pragmatic eye for scale and operationalization in a fit-for-purpose way.&lt;/p&gt;\n&lt;p&gt;The Public Sector (PubSec) Product Team is responsible for launching our new models into Public Sector organizations. They are obsessed with the specific use cases and impact our work can have within Public Sector organizations and are willing to get into the weeds to break down any barriers to adoption or engagement.&lt;/p&gt;\n&lt;p&gt;The ideal candidate will be hands-on and have experience building and operationalizing end-to-end product delivery. They are passionate about creating scalable systems that help Product teams better understand users. This includes implementing feedback loops, developing planning frameworks, and designing launch playbooks that elevate our Product organization&#39;s effectiveness.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Inputs to Product Teams&lt;/strong&gt; – Ensuring product teams have the information they need to make great decisions&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Voice of customer synthesis and feedback routing from strategic to tactical&lt;/li&gt;\n&lt;li&gt;Create high-leverage engagement points with partners throughout the product lifecycle&lt;/li&gt;\n&lt;li&gt;Establish rigor in understanding users via reliable metrics, dashboards, and clear hypotheses&lt;/li&gt;\n&lt;li&gt;Establish mechanisms for measuring product success and impact, including analytics dashboards and reporting systems&lt;/li&gt;\n&lt;li&gt;Streamline the most important decision points for teams and impacted partners&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Ops of the Product Org&lt;/strong&gt; – Creating the operating systems that enable product teams to thrive&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Support team rhythms, rituals, and operational models (offsites, Monthly Business Reviews, Team town halls, etc)&lt;/li&gt;\n&lt;li&gt;Create reliable run-of-business systems across product&lt;/li&gt;\n&lt;li&gt;Improve common product development processes and tooling&lt;/li&gt;\n&lt;li&gt;Facilitate effective collaboration between Product, Engineering, Sales, Customer Success, and Marketing teams&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Outputs from Product Teams&lt;/strong&gt; – Amplifying product impact by connecting what we build to those who need it&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Run Early Access Programs (EAPs) and beta programs that validate hypotheses and improve products&lt;/li&gt;\n&lt;li&gt;Maintain launch motions that allow us to ship with confidence and monitor impact&lt;/li&gt;\n&lt;li&gt;Create cross-team roadmap visibility that drives cross-functional alignment&lt;/li&gt;\n&lt;li&gt;Make clear to all of Anthropic what Product is working on and how it&#39;s going&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in product operations, program management, or related operational roles in hyper-scaling tech companies&lt;/li&gt;\n&lt;li&gt;Mission-aligned with building safe and beneficial AI systems&lt;/li&gt;\n&lt;li&gt;Experience working with Public Sector organizations&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Track record of building processes and programs from 0 to 1 and scaling them thoughtfully&lt;/li&gt;\n&lt;li&gt;Experience working deeply with AI and frontier models&lt;/li&gt;\n&lt;li&gt;Strong cross-functional partnership skills with ability to influence without authority&lt;/li&gt;\n&lt;li&gt;Strong analytical skills with the ability to translate complex qualitative and quantitative data into actionable insights with clear recommendations&lt;/li&gt;\n&lt;li&gt;Success managing complex, multi-stakeholder initiatives in fast-paced, ambiguous environments&lt;/li&gt;\n&lt;li&gt;Experience with launch coordination, early access programs, or customer feedback loops&lt;/li&gt;\n&lt;li&gt;A passion for iterative, user-driven product development&lt;/li&gt;\n&lt;li&gt;Experience as a bridge builder who connects strategy to execution and creates alignment across teams. You are a problem seeker comfortable with ambiguity and skilled at creating structure where none exists.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;This position requires verification of U.S. citizenship due to citizenship-based legal restrictions. Specifically, this position supports a United States federal, state, and/or local government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law. To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government clearance.&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$210,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$240,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4992055008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]