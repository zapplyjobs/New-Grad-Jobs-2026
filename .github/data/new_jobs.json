[
  {
    "job_title": "Research Engineer, Pre-training",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4616971008",
    "job_posted_at_datetime_utc": "2026-01-15T19:27:35-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems. Key Responsibilities: Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development Independently lead small research projects while collaborating with team members on larger initiatives Design, run, and analyze scientific experiments to advance our understanding of large language models Optimize and scale our training infrastructure to improve efficiency and reliability Develop and improve dev tooling to enhance team productivity Contribute to the entire stack, from low-level optimizations to high-level model design Qualifications: Advanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field Strong software engineering skills with a proven track record of building complex systems Expertise in Python and experience with deep learning frameworks (PyTorch preferred) Familiarity with large-scale machine learning, particularly in the context of language models Ability to balance research goals with practical engineering constraints Strong problem-solving skills and a results-oriented mindset Excellent communication skills and ability to work in a collaborative environment Care about the societal impacts of your work Preferred Experience: Work on high-performance, large-scale ML systems Familiarity with GPUs, Kubernetes, and OS internals Experience with language modeling using transformer architectures Knowledge of reinforcement learning techniques Background in large-scale ETL processes You'll thrive in this role if you: Have significant software engineering experience Are results-oriented with a bias towards flexibility and impact Willingly take on tasks outside your job description to support the team Enjoy pair programming and collaborative work Are eager to learn more about machine learning research Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects Are working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research View research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights Have ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term. Sample Projects: Optimizing the throughput of novel attention mechanisms Comparing compute efficiency of different Transformer variants Preparing large-scale datasets for efficient model consumption Scaling distributed training jobs to thousands of GPUs Designing fault tolerance strategies for our training infrastructure Creating interactive visualizations of model internals, such as attention patterns At Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech. If you're excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4616971008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4616971008",
    "title": "Research Engineer, Pre-training",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4616971008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:27:35-05:00",
    "fetched_at": "2026-01-19T18:49:25.811Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Key Responsibilities:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development&lt;/li&gt;\n&lt;li&gt;Independently lead small research projects while collaborating with team members on larger initiatives&lt;/li&gt;\n&lt;li&gt;Design, run, and analyze scientific experiments to advance our understanding of large language models&lt;/li&gt;\n&lt;li&gt;Optimize and scale our training infrastructure to improve efficiency and reliability&lt;/li&gt;\n&lt;li&gt;Develop and improve dev tooling to enhance team productivity&lt;/li&gt;\n&lt;li&gt;Contribute to the entire stack, from low-level optimizations to high-level model design&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Qualifications:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Advanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field&lt;/li&gt;\n&lt;li&gt;Strong software engineering skills with a proven track record of building complex systems&lt;/li&gt;\n&lt;li&gt;Expertise in Python and experience with deep learning frameworks (PyTorch preferred)&lt;/li&gt;\n&lt;li&gt;Familiarity with large-scale machine learning, particularly in the context of language models&lt;/li&gt;\n&lt;li&gt;Ability to balance research goals with practical engineering constraints&lt;/li&gt;\n&lt;li&gt;Strong problem-solving skills and a results-oriented mindset&lt;/li&gt;\n&lt;li&gt;Excellent communication skills and ability to work in a collaborative environment&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Preferred Experience:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Work on high-performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;Familiarity with GPUs, Kubernetes, and OS internals&lt;/li&gt;\n&lt;li&gt;Experience with language modeling using transformer architectures&lt;/li&gt;\n&lt;li&gt;Knowledge of reinforcement learning techniques&lt;/li&gt;\n&lt;li&gt;Background in large-scale ETL processes&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;You&#39;ll thrive in this role if you:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant software engineering experience&lt;/li&gt;\n&lt;li&gt;Are results-oriented with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Willingly take on tasks outside your job description to support the team&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming and collaborative work&lt;/li&gt;\n&lt;li&gt;Are eager to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects&lt;/li&gt;\n&lt;li&gt;Are working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research&lt;/li&gt;\n&lt;li&gt;View research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights&lt;/li&gt;\n&lt;li&gt;Have ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Sample Projects:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Optimizing the throughput of novel attention mechanisms&lt;/li&gt;\n&lt;li&gt;Comparing compute efficiency of different Transformer variants&lt;/li&gt;\n&lt;li&gt;Preparing large-scale datasets for efficient model consumption&lt;/li&gt;\n&lt;li&gt;Scaling distributed training jobs to thousands of GPUs&lt;/li&gt;\n&lt;li&gt;Designing fault tolerance strategies for our training infrastructure&lt;/li&gt;\n&lt;li&gt;Creating interactive visualizations of model internals, such as attention patterns&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;At Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech.&lt;/p&gt;\n&lt;p&gt;If you&#39;re excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4616971008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Staff Research Engineer, Discovery Team",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4593216008",
    "job_posted_at_datetime_utc": "2026-01-15T19:24:50-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Team Our team is organized around the north star goal of building an AI scientist – a system capable of solving the long term reasoning challenges and basic capabilities necessary to push the scientific frontier. Our team likes to think across the whole model stack. Currently the team is focused on improving models' abilities to use computers – as a laboratory for long horizon tasks and a key blocker to many scientific workflows. About the role As a Research Engineer on our team you will work end to end, identifying and addressing key blockers on the path to scientific AGI. Strong candidates should have familiarity with language model training, evaluation, and inference, be comfortable triaging research ideas and diagnosing problems and enjoy working collaboratively. Familiarity with performance optimization, distributed systems, vm/sandboxing/container deployment, and large scale data pipelines is highly encouraged. Join us in our mission to develop advanced AI systems that are both powerful and beneficial for humanity. Responsibilities: Working across the full stack to identify and remove bottlenecks preventing progress toward scientific AGI Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery Scaling research ideas from prototype to production Create benchmarks and evaluation frameworks to measure model capabilities in scientific workflows and computer use Implement distributed training systems and performance optimizations to support large-scale model development You may be a good fit if you: Have 8+ years of ML research experience Are familiar with large scale language model training, evaluation, and inference pipelines Enjoy obsessively iterating on immediate blockers towards longterm goals Thrive working collaboratively to solve problems Have expertise in performance optimization and distributed computing systems Show strong problem-solving skills and ability to identify technical bottlenecks in complex systems Can translate research concepts into scalable engineering solutions Have a track record of shipping ML systems that tackle challenging multi-step reasoning problems Strong candidates may also have: Expertise with performance optimization for language model inference and training Experience with computer use automation and agentic AI systems A history working on reinforcement learning approaches for complex task completion Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing) Have experience with VM/sandboxing/container deployment and large-scale data processing Experience working with large scale data problem solving and infrastructure Published research or practical experience in scientific AI applications or long-horizon reasoning The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4593216008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4593216008",
    "title": "Staff Research Engineer, Discovery Team",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4593216008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:24:50-05:00",
    "fetched_at": "2026-01-19T18:49:25.811Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Team&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Our team is organized around the north star goal of building an AI scientist – a system capable of solving the long term reasoning challenges and basic capabilities necessary to push the scientific frontier. Our team likes to think across the whole model stack. Currently the team is focused on improving models&#39; abilities to use computers – as a laboratory for long horizon tasks and a key blocker to many scientific workflows.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Research Engineer on our team you will work end to end, identifying and addressing key blockers on the path to scientific AGI. Strong candidates should have familiarity with language model training, evaluation, and inference, be comfortable triaging research ideas and diagnosing problems and enjoy working collaboratively. Familiarity with performance optimization, distributed systems, vm/sandboxing/container deployment, and large scale data pipelines is highly encouraged.&lt;/p&gt;\n&lt;p&gt;Join us in our mission to develop advanced AI systems that are both powerful and beneficial for humanity.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Working across the full stack to identify and remove bottlenecks preventing progress toward scientific AGI&lt;/li&gt;\n&lt;li&gt;Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery&lt;/li&gt;\n&lt;li&gt;Scaling research ideas from prototype to production&lt;/li&gt;\n&lt;li&gt;Create benchmarks and evaluation frameworks to measure model capabilities in scientific workflows and computer use&lt;/li&gt;\n&lt;li&gt;Implement distributed training systems and performance optimizations to support large-scale model development&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 8+ years of ML research experience&lt;/li&gt;\n&lt;li&gt;Are familiar with large scale language model training, evaluation, and inference pipelines&lt;/li&gt;\n&lt;li&gt;Enjoy obsessively iterating on immediate blockers towards longterm goals&lt;/li&gt;\n&lt;li&gt;Thrive working collaboratively to solve problems&lt;/li&gt;\n&lt;li&gt;Have expertise in performance optimization and distributed computing systems&lt;/li&gt;\n&lt;li&gt;Show strong problem-solving skills and ability to identify technical bottlenecks in complex systems&lt;/li&gt;\n&lt;li&gt;Can translate research concepts into scalable engineering solutions&lt;/li&gt;\n&lt;li&gt;Have a track record of shipping ML systems that tackle challenging multi-step reasoning problems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Expertise with performance optimization for language model inference and training&lt;/li&gt;\n&lt;li&gt;Experience with computer use automation and agentic AI systems&lt;/li&gt;\n&lt;li&gt;A history working on reinforcement learning approaches for complex task completion&lt;/li&gt;\n&lt;li&gt;Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing)&lt;/li&gt;\n&lt;li&gt;Have experience with VM/sandboxing/container deployment and large-scale data processing&lt;/li&gt;\n&lt;li&gt;Experience working with large scale data problem solving and infrastructure&lt;/li&gt;\n&lt;li&gt;Published research or practical experience in scientific AI applications or long-horizon reasoning&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4593216008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Data Ingestion",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5025065008",
    "job_posted_at_datetime_utc": "2026-01-15T19:18:29-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role: We are looking for an experienced Research Engineer to join the Data Ingestion team, which owns the problem of acquiring all of the available data on the internet through a large scale web crawler. Most of Anthropic's research and product builds on top of the best pretrained models that we can produce, which in turn rely on having the best pretraining data. This role combines hands-on engineering with data research—you'll build and scale our crawler infrastructure while also conducting experiments to evaluate and improve data quality. Successfully scaling our data corpus is critical to our continued efforts at producing the best pretrained models. Responsibilities: Develop and maintain our large-scale web crawler Design and run experiments to evaluate data quality, extraction methods, and crawling strategies Analyze crawled data to identify patterns, gaps, and opportunities for improvement Build pipelines for data ingestion, analysis, and quality improvement Build specialized crawlers for high-value data sources Collaborate with Pretraining and Tokens teams to create feedback loops between crawled data and data evaluation results. Collaborate with team members on improving data acquisition processes Participate in code reviews and debugging sessions You may be a good fit if you: Believe in the transformative potential of advanced AI systems Are interested in building a large-scale system to acquire all openly accessible information on the internet Have experience with data research, including designing experiments and analyzing results Have worked on web crawlers or large-scale data acquisition systems Are comfortable operating in a hybrid research-engineering role, balancing system building with experimentation The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5025065008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5025065008",
    "title": "Research Engineer, Data Ingestion",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5025065008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:18:29-05:00",
    "fetched_at": "2026-01-19T18:49:25.811Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We are looking for an experienced Research Engineer to join the Data Ingestion team, which owns the problem of acquiring all of the available data on the internet through a large scale web crawler. Most of Anthropic&#39;s research and product builds on top of the best pretrained models that we can produce, which in turn rely on having the best pretraining data. This role combines hands-on engineering with data research—you&#39;ll build and scale our crawler infrastructure while also conducting experiments to evaluate and improve data quality. Successfully scaling our data corpus is critical to our continued efforts at producing the best pretrained models.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Develop and maintain our large-scale web crawler&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Design and run experiments to evaluate data quality, extraction methods, and crawling strategies&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Analyze crawled data to identify patterns, gaps, and opportunities for improvement&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Build pipelines for data ingestion, analysis, and quality improvement&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Build specialized crawlers for high-value data sources&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Collaborate with Pretraining and Tokens teams to create feedback loops between crawled data and data evaluation results.&amp;nbsp;&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Collaborate with team members on improving data acquisition processes&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Participate in code reviews and debugging sessions&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Believe in the transformative potential of advanced AI systems&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Are interested in building a large-scale system to acquire all openly accessible information on the internet&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Have experience with data research, including designing experiments and analyzing results&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Have worked on web crawlers or large-scale data acquisition systems&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Are comfortable operating in a hybrid research-engineering role, balancing system building with experimentation&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5025065008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Senior Research Scientist, Reward Models",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel Required) | San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5024835008",
    "job_posted_at_datetime_utc": "2026-01-15T19:15:02-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Senior Research Scientist on our Reward Models team, you'll lead research efforts to improve how we specify and learn human preferences at scale. Your work will directly shape how our models understand and optimize for what humans actually want — enabling Claude to be more useful, more reliable, and better aligned with human values. This role focuses on pushing the frontier of reward modeling for large language models. You'll develop novel architectures and training methodologies for RLHF, research new approaches to LLM-based evaluation and grading (including rubric-based methods), and investigate techniques to identify and mitigate reward hacking. You'll collaborate closely with teams across Anthropic, including Finetuning, Alignment Science, and our broader research organization, to ensure your work translates into concrete improvements in both model capabilities and safety. We're looking for someone who can drive ambitious research agendas while also shipping practical improvements to production systems. You'll have the opportunity to work on some of the most important open problems in AI alignment, with access to frontier models and significant computational resources. Your work will directly advance the science of how we train AI systems to be both highly capable and safe. Note: For this role, we conduct all interviews in Python. Responsibilities Lead research on novel reward model architectures and training approaches for RLHF Develop and evaluate LLM-based grading and evaluation methods, including rubric-driven approaches that improve consistency and interpretability Research techniques to detect, characterize, and mitigate reward hacking and specification gaming Design experiments to understand reward model generalization, robustness, and failure modes Collaborate with the Finetuning team to translate research insights into improvements for production training pipelines Contribute to research publications, blog posts, and internal documentation Mentor other researchers and help build institutional knowledge around reward modeling You may be a good fit if you Have a track record of research contributions in reward modeling, RLHF, or closely related areas of machine learning Have experience training and evaluating reward models for large language models Are comfortable designing and running large-scale experiments with significant computational resources Can work effectively across research and engineering, iterating quickly while maintaining scientific rigor Enjoy collaborative research and can communicate complex ideas clearly to diverse audiences Care deeply about building AI systems that are both highly capable and safe Strong candidates may also Have published research on reward modeling, preference learning, or RLHF Have experience with LLM-as-judge approaches, including calibration and reliability challenges Have worked on reward hacking, specification gaming, or related robustness problems Have experience with constitutional AI, debate, or other scalable oversight approaches Have contributed to production ML systems at scale Have familiarity with interpretability techniques as applied to understanding reward model behavior The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5024835008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5024835008",
    "title": "Senior Research Scientist, Reward Models",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel Required) | San Francisco, CA",
    "locations": [
      "Remote-Friendly (Travel Required) | San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5024835008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:15:02-05:00",
    "fetched_at": "2026-01-19T18:49:25.811Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Senior Research Scientist on our Reward Models team, you&#39;ll lead research efforts to improve how we specify and learn human preferences at scale. Your work will directly shape how our models understand and optimize for what humans actually want — enabling Claude to be more useful, more reliable, and better aligned with human values.&lt;/p&gt;\n&lt;p&gt;This role focuses on pushing the frontier of reward modeling for large language models. You&#39;ll develop novel architectures and training methodologies for RLHF, research new approaches to LLM-based evaluation and grading (including rubric-based methods), and investigate techniques to identify and mitigate reward hacking. You&#39;ll collaborate closely with teams across Anthropic, including Finetuning, Alignment Science, and our broader research organization, to ensure your work translates into concrete improvements in both model capabilities and safety.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;We&#39;re looking for someone who can drive ambitious research agendas while also shipping practical improvements to production systems. You&#39;ll have the opportunity to work on some of the most important open problems in AI alignment, with access to frontier models and significant computational resources. Your work will directly advance the science of how we train AI systems to be both highly capable and safe.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead research on novel reward model architectures and training approaches for RLHF&lt;/li&gt;\n&lt;li&gt;Develop and evaluate LLM-based grading and evaluation methods, including rubric-driven approaches that improve consistency and interpretability&lt;/li&gt;\n&lt;li&gt;Research techniques to detect, characterize, and mitigate reward hacking and specification gaming&lt;/li&gt;\n&lt;li&gt;Design experiments to understand reward model generalization, robustness, and failure modes&lt;/li&gt;\n&lt;li&gt;Collaborate with the Finetuning team to translate research insights into improvements for production training pipelines&lt;/li&gt;\n&lt;li&gt;Contribute to research publications, blog posts, and internal documentation&lt;/li&gt;\n&lt;li&gt;Mentor other researchers and help build institutional knowledge around reward modeling&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have a track record of research contributions in reward modeling, RLHF, or closely related areas of machine learning&lt;/li&gt;\n&lt;li&gt;Have experience training and evaluating reward models for large language models&lt;/li&gt;\n&lt;li&gt;Are comfortable designing and running large-scale experiments with significant computational resources&lt;/li&gt;\n&lt;li&gt;Can work effectively across research and engineering, iterating quickly while maintaining scientific rigor&lt;/li&gt;\n&lt;li&gt;Enjoy collaborative research and can communicate complex ideas clearly to diverse audiences&lt;/li&gt;\n&lt;li&gt;Care deeply about building AI systems that are both highly capable and safe&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have published research on reward modeling, preference learning, or RLHF&lt;/li&gt;\n&lt;li&gt;Have experience with LLM-as-judge approaches, including calibration and reliability challenges&lt;/li&gt;\n&lt;li&gt;Have worked on reward hacking, specification gaming, or related robustness problems&lt;/li&gt;\n&lt;li&gt;Have experience with constitutional AI, debate, or other scalable oversight approaches&lt;/li&gt;\n&lt;li&gt;Have contributed to production ML systems at scale&lt;/li&gt;\n&lt;li&gt;Have familiarity with interpretability techniques as applied to understanding reward model behavior&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5024835008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Reward Models Platform",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5024831008",
    "job_posted_at_datetime_utc": "2026-01-15T19:02:38-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role You will deeply understand the research workflows of our Finetuning teams and automate the high-friction parts – turning days of manual experimentation into hours. You’ll build the tools and infrastructure that enable researchers across the organization to develop, evaluate, and optimize reward signals for training our models. Your scalable platforms will make it easy to experiment with different reward methodologies, assess their robustness, and iterate rapidly on improvements to help the rest of Anthropic train our reward models. This is a role for someone who wants to stay close to the science while having outsized leverage. You'll partner directly with researchers on the Rewards team and across the broader Fine-Tuning organization to understand what slows them down: running human data experiments before adding to preference models, debugging reward hacks, comparing rubric methodologies across domains. Then you'll build the systems that make those workflows 10x faster. When you have bandwidth, you'll contribute directly to research projects yourself. Your work will directly impact our ability to scale reward development across domains, from crafting and evaluating rubrics to understanding the effects of human feedback data to detecting and mitigating reward hacks. We're looking for someone who combines strong engineering fundamentals with research experience – someone who can scope ambiguous problems, ship quickly, and cares as much about the science as the systems. Note: For this role, we conduct all interviews in Python. Responsibilities Design and build infrastructure that enables researchers to rapidly iterate on reward signals, including tools for rubric development, human feedback data analysis, and reward robustness evaluation Develop systems for automated quality assessment of rewards, including detection of reward hacks and other pathologies Create tooling that allows researchers to easily compare different reward methodologies (preference models, rubrics, programmatic rewards) and understand their effects Build pipelines and workflows that reduce toil in reward development, from dataset preparation to evaluation to deployment Implement monitoring and observability systems to track reward signal quality and surface issues during training runs Collaborate with researchers to translate science requirements into platform capabilities Optimize existing systems for performance, reliability, and ease of use Contribute to the development of best practices and documentation for reward development workflows You may be a good fit if you Have prior research experience Are excited to work closely with researchers and translate ambiguous requirements into well-scoped engineering projects Have strong Python skills Have experience with ML workflows and data pipelines, and building related infrastructure/tooling/platforms Are comfortable working across the stack, ranging from data pipelines to experiment tracking to user-facing tooling Can balance building robust, maintainable systems with the need to move quickly in a research environment Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Care about the societal impacts of your work and are motivated by Anthropic's mission to develop safe AI Strong candidates may also have experience with Experience with ML research Building internal tooling and platforms for ML researchers Data quality assessment and pipeline optimization Experiment tracking, evaluation frameworks, or MLOps tooling Large-scale data processing (e.g., Spark, Hive, or similar) Kubernetes, distributed systems, or cloud infrastructure Familiarity with reinforcement learning or fine-tuning workflows Representative projects Building infrastructure that allows researchers to rapidly test new rubric designs against small models before scaling up Developing automated systems to detect reward hacks and surface problematic behaviors during training Creating tooling for comparing different grading methodologies and understanding their effects on model behavior Building a data quality flywheel that helps researchers identify problematic transcripts and feed improvements back into the system Developing dashboards and monitoring systems that give researchers visibility into reward signal quality across training runs Streamlining dataset preparation workflows to reduce latency and operational overhead The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5024831008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5024831008",
    "title": "Research Engineer, Reward Models Platform",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5024831008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:02:38-05:00",
    "fetched_at": "2026-01-19T18:49:25.811Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;You will deeply understand the research workflows of our Finetuning teams and automate the high-friction parts – turning days of manual experimentation into hours. You’ll build the tools and infrastructure that enable researchers across the organization to develop, evaluate, and optimize reward signals for training our models. Your scalable platforms will make it easy to experiment with different reward methodologies, assess their robustness, and iterate rapidly on improvements to help the rest of Anthropic train our reward models.&lt;/p&gt;\n&lt;p&gt;This is a role for someone who wants to stay close to the science while having outsized leverage. You&#39;ll partner directly with researchers on the Rewards team and across the broader Fine-Tuning organization to understand what slows them down: running human data experiments before adding to preference models, debugging reward hacks, comparing rubric methodologies across domains. Then you&#39;ll build the systems that make those workflows 10x faster. When you have bandwidth, you&#39;ll contribute directly to research projects yourself. Your work will directly impact our ability to scale reward development across domains, from crafting and evaluating rubrics to understanding the effects of human feedback data to detecting and mitigating reward hacks.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;We&#39;re looking for someone who combines strong engineering fundamentals with research experience – someone who can scope ambiguous problems, ship quickly, and cares as much about the science as the systems.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and build infrastructure that enables researchers to rapidly iterate on reward signals, including tools for rubric development, human feedback data analysis, and reward robustness evaluation&lt;/li&gt;\n&lt;li&gt;Develop systems for automated quality assessment of rewards, including detection of reward hacks and other pathologies&lt;/li&gt;\n&lt;li&gt;Create tooling that allows researchers to easily compare different reward methodologies (preference models, rubrics, programmatic rewards) and understand their effects&lt;/li&gt;\n&lt;li&gt;Build pipelines and workflows that reduce toil in reward development, from dataset preparation to evaluation to deployment&lt;/li&gt;\n&lt;li&gt;Implement monitoring and observability systems to track reward signal quality and surface issues during training runs&lt;/li&gt;\n&lt;li&gt;Collaborate with researchers to translate science requirements into platform capabilities&lt;/li&gt;\n&lt;li&gt;Optimize existing systems for performance, reliability, and ease of use&lt;/li&gt;\n&lt;li&gt;Contribute to the development of best practices and documentation for reward development workflows&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have prior research experience&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Are excited to work closely with researchers and translate ambiguous requirements into well-scoped engineering projects&lt;/li&gt;\n&lt;li&gt;Have strong Python skills&lt;/li&gt;\n&lt;li&gt;Have experience with ML workflows and data pipelines, and building related infrastructure/tooling/platforms&lt;/li&gt;\n&lt;li&gt;Are comfortable working across the stack, ranging from data pipelines to experiment tracking to user-facing tooling&lt;/li&gt;\n&lt;li&gt;Can balance building robust, maintainable systems with the need to move quickly in a research environment&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work and are motivated by Anthropic&#39;s mission to develop safe AI&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have experience with&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with ML research&lt;/li&gt;\n&lt;li&gt;Building internal tooling and platforms for ML researchers&lt;/li&gt;\n&lt;li&gt;Data quality assessment and pipeline optimization&lt;/li&gt;\n&lt;li&gt;Experiment tracking, evaluation frameworks, or MLOps tooling&lt;/li&gt;\n&lt;li&gt;Large-scale data processing (e.g., Spark, Hive, or similar)&lt;/li&gt;\n&lt;li&gt;Kubernetes, distributed systems, or cloud infrastructure&lt;/li&gt;\n&lt;li&gt;Familiarity with reinforcement learning or fine-tuning workflows&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative projects&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Building infrastructure that allows researchers to rapidly test new rubric designs against small models before scaling up&lt;/li&gt;\n&lt;li&gt;Developing automated systems to detect reward hacks and surface problematic behaviors during training&lt;/li&gt;\n&lt;li&gt;Creating tooling for comparing different grading methodologies and understanding their effects on model behavior&lt;/li&gt;\n&lt;li&gt;Building a data quality flywheel that helps researchers identify problematic transcripts and feed improvements back into the system&lt;/li&gt;\n&lt;li&gt;Developing dashboards and monitoring systems that give researchers visibility into reward signal quality across training runs&lt;/li&gt;\n&lt;li&gt;Streamlining dataset preparation workflows to reduce latency and operational overhead&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5024831008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Software Engineer, Accelerator Build Infrastructure",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4943668008",
    "job_posted_at_datetime_utc": "2026-01-15T18:59:29-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role A systems-level engineer specializing in build infrastructure and low-level systems optimization, with expertise in maintaining and improving non-trivial C/C++ builds and other host level systems. This role requires deep technical knowledge of compilation processes, hardware-software interfaces, build systems, and the ability to debug and optimize at the system level. Responsibilities: Build Systems & Toolchains Expert-level proficiency with build/packaging systems (Nix, pip, uv, CMake, Bazel, Make, etc…) Nix experience in particular is a huge plus Experience managing complex builds and interacting in non-trivial ways with CI Skilled in diagnosing and resolving linking issues, symbol resolution problems, and toolchain/ABI incompatibilities Low-Level Systems/Embedded Programming Strong C/C++ debugging skills, especially nice if in embedded systems or in dealing with cross compiling/linking Comfortable with system calls, POSIX APIs, and kernel interfaces Experience with toolchain debugging tools like readelf, bloaty, c++filt, nm, etc… Compiler & Toolchain Experience Basic knowledge of compilers (understanding things like passes, having multiples levels of IR, what kinds of operations are done on it, etc…) Experience with cross-compilers (compiling code for target devices) Experience with detailed compiler flags optimization and custom toolchain configuration Understanding of linking processes, object file formats (ELF, DWARF), and ABI compatibility Strong candidates may have: Machine Learning Infrastructure Basic understanding of deep learning frameworks (PyTorch, Jax) from a systems perspective Understanding of tensor operations Experience with distributed training infrastructure is a plus You may be a good fit if you have: 5+ years of experience in systems programming or infrastructure roles Often comes from backgrounds in: HPC, game engine development, embedded systems, OS, or compiler teams Strong debugging mindset with patience for complex, multi-layered issues Self-directed problem solver who can navigate large, legacy codebases This profile would be ideal for roles in ML infrastructure teams, HPC environments, or any organization dealing with non-trivial C/C++ systems that need optimization at the build and runtime level. Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4943668008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4943668008",
    "title": "Software Engineer, Accelerator Build Infrastructure",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | Seattle, WA",
    "locations": [
      "San Francisco, CA | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4943668008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:59:29-05:00",
    "fetched_at": "2026-01-19T18:49:25.811Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;A systems-level engineer specializing in build infrastructure and low-level systems optimization, with expertise in maintaining and improving non-trivial C/C++ builds and other host level systems. This role requires deep technical knowledge of compilation processes, hardware-software interfaces, build systems, and the ability to debug and optimize at the system level.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Build Systems &amp;amp; Toolchains&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Expert-level proficiency with build/packaging systems (Nix, pip, uv, CMake, Bazel, Make, etc…)&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Nix experience in particular is a huge plus&lt;/li&gt;\n&lt;li&gt;Experience managing complex builds and interacting in non-trivial ways with CI&lt;/li&gt;\n&lt;li&gt;Skilled in diagnosing and resolving linking issues, symbol resolution problems, and toolchain/ABI incompatibilities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Low-Level Systems/Embedded Programming&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Strong C/C++ debugging skills, especially nice if in embedded systems or in dealing with cross compiling/linking&lt;/li&gt;\n&lt;li&gt;Comfortable with system calls, POSIX APIs, and kernel interfaces&lt;/li&gt;\n&lt;li&gt;Experience with toolchain debugging tools like readelf, bloaty, c++filt, nm, etc…&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Compiler &amp;amp; Toolchain Experience&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Basic knowledge of compilers (understanding things like passes, having multiples levels of IR, what kinds of operations are done on it, etc…)&lt;/li&gt;\n&lt;li&gt;Experience with cross-compilers (compiling code for target devices)&lt;/li&gt;\n&lt;li&gt;Experience with detailed compiler flags optimization and custom toolchain configuration&lt;/li&gt;\n&lt;li&gt;Understanding of linking processes, object file formats (ELF, DWARF), and ABI compatibility&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may have:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Machine Learning Infrastructure&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Basic understanding of deep learning frameworks (PyTorch, Jax) from a systems perspective&lt;/li&gt;\n&lt;li&gt;Understanding of tensor operations&lt;/li&gt;\n&lt;li&gt;Experience with distributed training infrastructure is a plus&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&amp;nbsp;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in systems programming or infrastructure roles&lt;/li&gt;\n&lt;li&gt;Often comes from backgrounds in: HPC, game engine development, embedded systems, OS, or compiler teams&lt;/li&gt;\n&lt;li&gt;Strong debugging mindset with patience for complex, multi-layered issues&lt;/li&gt;\n&lt;li&gt;Self-directed problem solver who can navigate large, legacy codebases&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;This profile would be ideal for roles in ML infrastructure teams, HPC environments, or any organization dealing with non-trivial C/C++ systems that need optimization at the build and runtime level.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4943668008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Senior Software Engineer, Machine Learning (Safety)",
    "employer_name": "discord",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/discord/jobs/8369339002",
    "job_posted_at_datetime_utc": "2026-01-14T16:30:07-05:00",
    "job_description": "Discord is used by over 200 million people every month for many different reasons, but there’s one thing that nearly everyone does on our platform: play video games. Over 90% of our users play games, spending a combined 1.5 billion hours playing thousands of unique titles on Discord each month. Discord plays a uniquely important role in the future of gaming. We are focused on making it easier and more fun for people to talk and hang out before, during, and after playing games.We are seeking an experienced Senior Machine Learning Engineer to join our Safety ML team. This role focuses on building and deploying machine learning models that help keep Discord users safe, including real-time and batch systems for content understanding, risk evaluation, and account integrity. You will work closely with partners across product, engineering, design, policy, legal, and Trust and Safety to design and deliver effective ML solutions. This role reports to the Senior Manager of Machine Learning, Safety. What You'll Be Doing Analyze data to identify risk patterns and inform the design of machine learning models Build, iterate on, and evaluate models that detect risk and anomalous behavior Work with product, engineering, legal, and Trust and Safety partners to deliver effective ML solutions Work with partner teams in Trust & Safety to curate golden label sets at scale and improve data labeling techniques for model training Deploy models into production systems, writing backend code as needed to ensure scalability and reliability, and monitor performance Document modeling approaches and systems, and apply current machine learning best practices What you should have 4+ years of experience in ML engineering or applied ML roles. Strong coding skills in Python and fluency in ML frameworks such as PyTorch, JAX, or TensorFlow. Experience building performant machine learning systems at scale and have driven the execution of projects from ideation to production. Ability to think from first principles, approaching complex problems with creativity, clear reasoning, and pragmatic solutions. A growth mindset: seeking feedback, reflecting on decisions, and continuously improving. Excellent communication and collaboration skills, with a history of partnering effectively across engineering, data science, legal, policy, and product teams. Bachelor’s or Master’s degree in Computer Science, Machine Learning, Statistics, or a related field (Physics, Math, Operations Research, etc. The US base salary range for this full-time position is $220,000 to $247,500 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.Why Discord? Discord plays a uniquely important role in the future of gaming. We're a multiplatform, multigenerational and multiplayer platform that helps people deepen their friendships around games and shared interests. We believe games give us a way to have fun with our favorite people, whether listening to music together or grinding in competitive matches for diamond rank. Join us in our mission! Your future is just a click away! Discord is committed to inclusion and providing reasonable accommodations during the interview process. We want you to feel set up for success, so if you are in need of reasonable accommodations, please let your recruiter know. Please see our Applicant and Candidate Privacy Policy for details regarding Discord’s collection and usage of personal information relating to the application and recruitment process by clicking HERE.",
    "id": "job-boards-greenhouse-io-discord-jobs-8369339002",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "8369339002",
    "title": "Senior Software Engineer, Machine Learning (Safety)",
    "company_name": "discord",
    "company_slug": "discord",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/discord/jobs/8369339002",
    "departments": [
      "Machine Learning"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T16:30:07-05:00",
    "fetched_at": "2026-01-19T18:49:26.370Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;p&gt;Discord is used by over 200 million people every month for many different reasons, but there’s one thing that nearly everyone does on our platform:&lt;strong&gt; play video games.&lt;/strong&gt; Over 90% of our users play games, spending a combined 1.5 billion hours playing thousands of unique titles on Discord each month. Discord plays a uniquely important role in the future of gaming. We are focused on making it easier and more fun for people to talk and hang out before, during, and after playing games.&lt;/p&gt;&lt;/div&gt;&lt;h4&gt;We are seeking an experienced Senior Machine Learning Engineer to join our Safety ML team. This role focuses on building and deploying machine learning models that help keep Discord users safe, including real-time and batch systems for content understanding, risk evaluation, and account integrity. You will work closely with partners across product, engineering, design, policy, legal, and Trust and Safety to design and deliver effective ML solutions. This role reports to the Senior Manager of Machine Learning, Safety.&lt;/h4&gt;\n&lt;p&gt;&lt;strong&gt;What You&#39;ll Be Doing&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Analyze data to identify risk patterns and inform the design of machine learning models&lt;/li&gt;\n&lt;li&gt;Build, iterate on, and evaluate models that detect risk and anomalous behavior&lt;/li&gt;\n&lt;li&gt;Work with product, engineering, legal, and Trust and Safety partners to deliver effective ML solutions&lt;/li&gt;\n&lt;li&gt;Work with partner teams in Trust &amp;amp; Safety to curate golden label sets at scale and improve data labeling techniques for model training&lt;/li&gt;\n&lt;li&gt;Deploy models into production systems, writing backend code as needed to ensure scalability and reliability, and monitor performance&lt;/li&gt;\n&lt;li&gt;Document modeling approaches and systems, and apply current machine learning best practices&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;What you should have&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;4+ years of experience in ML engineering or applied ML roles.&lt;/li&gt;\n&lt;li&gt;Strong coding skills in Python and fluency in ML frameworks such as PyTorch, JAX, or TensorFlow.&lt;/li&gt;\n&lt;li&gt;Experience building performant machine learning systems at scale and have driven the execution of projects from ideation to production.&lt;/li&gt;\n&lt;li&gt;Ability to think from first principles, approaching complex problems with creativity, clear reasoning, and pragmatic solutions.&lt;/li&gt;\n&lt;li&gt;A growth mindset: seeking feedback, reflecting on decisions, and continuously improving.&lt;/li&gt;\n&lt;li&gt;Excellent communication and collaboration skills, with a history of partnering effectively across engineering, data science, legal, policy, and product teams.&lt;/li&gt;\n&lt;li&gt;Bachelor’s or Master’s degree in Computer Science, Machine Learning, Statistics, or a related field (Physics, Math, Operations Research, etc.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;em&gt;&lt;br&gt;The US base salary range for this full-time position is $220,000 to $247,500 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.&lt;br&gt;&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;p&gt;&lt;strong&gt;Why Discord?&amp;nbsp;&lt;/strong&gt;&lt;br&gt;&lt;br&gt;Discord plays a uniquely important role in the future of gaming. We&#39;re a multiplatform, multigenerational and multiplayer platform that helps people deepen their friendships around games and shared interests. We believe games give us a way to have fun with our favorite people, whether listening to music together or grinding in competitive matches for diamond rank. &lt;strong&gt;Join us in our mission! Your future is just a click away!&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Discord is committed to inclusion and providing reasonable accommodations during the interview process. &lt;/strong&gt;We want you to feel set up for success, so if you are in need of reasonable accommodations, please let your recruiter know.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;&lt;strong&gt;Please see our Applicant and Candidate Privacy Policy for details regarding Discord’s collection and usage of personal information relating to the application and recruitment process by clicking&amp;nbsp;&lt;a href=&quot;https://discord.com/terms/applicant-candidate-privacy-policy&quot;&gt;HERE.&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 8369339002
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Security Software Engineer, D&R Platform",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4595463008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role We're seeking an exceptional engineer to join Anthropic's Detection Platform team to build and scale our next-generation security analytics infrastructure. In this role, you'll architect and implement data pipelines that process massive amounts of security telemetry, develop ML-powered detection systems, and create innovative solutions that leverage Claude to transform security operations. Responsibilities: Build AI-powered platform responsible for all aspects of D&R capabilities from detection development to incident response Design and implement scalable data pipelines for ingesting and processing security telemetry across our rapidly growing infrastructure Architect solutions for storing and efficiently querying large volumes of security-relevant data Create rapid prototypes and proof-of-concepts for new security tooling and analytics capabilities Work closely with security and infrastructure teams to understand requirements and deliver solutions Mentor engineers and contribute to hiring and growth of the Security team Participate in on-call shifts You may be a good fit if you: 7+ years of experience in software engineering with a focus on security, infrastructure and/or data pipelines Track record of building and maintaining internal developer tools or security platforms Strong understanding of data processing pipelines and experience working with large-scale logging systems Experience with: Test-driven software development and/or CI/CD (plus for direct experience with Detection-as-code workflows) Infrastructure-as-code (Terraform, CloudFormation) Query optimization for large datasets Experience with building stable and scalable services on cloud infrastructure and serverless architectures Ability to write maintainable and secure code in Python Experience working with security teams and translating requirements into technical solutions Ability to lead technical projects with minimal guidance Track record of driving engineering excellence through high standards, constructive code reviews, and mentorship Proven ability to lead cross-functional security initiatives and navigate complex organizational dynamics Outstanding communication skills, translating technical concepts effectively across all organizational levels Demonstrated success in bringing clarity and ownership to ambiguous technical problems Strong systems thinking with ability to identify and mitigate risks in complex environments Strong candidates may also have experience with: Experience building security tooling from the ground up Background in implementing security monitoring solutions (SIEM, log aggregation, EDR) Background in detection engineering or security operations Experience with: SOAR platform/automation development Data lake / Database architecture API design and internal platform creation Track record of applying ML/AI to security problems Experience scaling security operations in a high-growth environment Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$320,000 - $405,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4595463008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4595463008",
    "title": "Security Software Engineer, D&R Platform",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4595463008",
    "departments": [
      "Security"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-19T18:49:25.811Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;We&#39;re seeking an exceptional engineer to join Anthropic&#39;s Detection Platform team to build and scale our next-generation security analytics infrastructure. In this role, you&#39;ll architect and implement data pipelines that process massive amounts of security telemetry, develop ML-powered detection systems, and create innovative solutions that leverage Claude to transform security operations.&lt;/p&gt;\n&lt;/div&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;Build AI-powered platform responsible for all aspects of D&amp;amp;R capabilities from detection development to incident response&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;Design and implement scalable data pipelines for ingesting and processing security telemetry across our rapidly growing infrastructure&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;Architect solutions for storing and efficiently querying large volumes of security-relevant data&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;Create rapid prototypes and proof-of-concepts for new security tooling and analytics capabilities&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;Work closely with security and infrastructure teams to understand requirements and deliver solutions&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;Mentor engineers and contribute to hiring and growth of the Security team&lt;/li&gt;\n&lt;li&gt;Participate in on-call shifts&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;7+ years of experience in software engineering with a focus on security, infrastructure and/or data pipelines&lt;/li&gt;\n&lt;li&gt;Track record of building and maintaining internal developer tools or security platforms&lt;/li&gt;\n&lt;li&gt;Strong understanding of data processing pipelines and experience working with large-scale logging systems&lt;/li&gt;\n&lt;li&gt;Experience with:\n&lt;ul&gt;\n&lt;li&gt;Test-driven software development and/or CI/CD (plus for direct experience with Detection-as-code workflows)&lt;/li&gt;\n&lt;li&gt;Infrastructure-as-code (Terraform, CloudFormation)&lt;/li&gt;\n&lt;li&gt;Query optimization for large datasets&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;Experience with building stable and scalable services on cloud infrastructure and serverless architectures&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Ability to write maintainable and secure code in Python&lt;/li&gt;\n&lt;li&gt;Experience working with security teams and translating requirements into technical solutions&lt;/li&gt;\n&lt;li&gt;Ability to lead technical projects with minimal guidance&lt;/li&gt;\n&lt;li&gt;Track record of driving engineering excellence through high standards, constructive code reviews, and mentorship&lt;/li&gt;\n&lt;li&gt;Proven ability to lead cross-functional security initiatives and navigate complex organizational dynamics&lt;/li&gt;\n&lt;li&gt;Outstanding communication skills, translating technical concepts effectively across all organizational levels&lt;/li&gt;\n&lt;li&gt;Demonstrated success in bringing clarity and ownership to ambiguous technical problems&lt;/li&gt;\n&lt;li&gt;Strong systems thinking with ability to identify and mitigate risks in complex environments&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience building security tooling from the ground up&lt;/li&gt;\n&lt;li&gt;Background in implementing security monitoring solutions (SIEM, log aggregation, EDR)&lt;/li&gt;\n&lt;li&gt;Background in detection engineering or security operations&lt;/li&gt;\n&lt;li&gt;Experience with:\n&lt;ul&gt;\n&lt;li&gt;SOAR platform/automation development&lt;/li&gt;\n&lt;li&gt;Data lake / Database architecture&lt;/li&gt;\n&lt;li&gt;API design and internal platform creation&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;Track record of applying ML/AI to security problems&lt;/li&gt;\n&lt;li&gt;Experience scaling security operations in a high-growth environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$320,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$405,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4595463008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Solutions Architect, Enterprise Industries",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4461444008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As an Applied AI team member at Anthropic, you will be a Pre-Sales architect focused on becoming a trusted technical advisor helping large enterprises understand the value of Claude and paint the vision on how they can successfully integrate and deploy Claude into their technology stack. You'll combine your deep technical expertise with customer-facing skills to architect innovative LLM solutions that address complex business challenges while maintaining our high standards for safety and reliability. Working closely with our Sales, Product, and Engineering teams, you'll guide customers from initial technical discovery through successful deployment. You'll leverage your expertise to help customers understand Claude's capabilities, develop evals, and design scalable architectures that maximize the value of our AI systems. Responsibilities: Partner with account executives to deeply understand customer requirements and translate them into technical solutions, ensuring alignment between business objectives and technical implementation Serve as the primary technical advisor to enterprise customers throughout their Claude adoption journey, from discovery to initial evaluation through deployment. You will need to coordinate internally across multiple teams & stakeholders to drive customer success Support customers building with both the Claude API and Claude for Work Create and deliver compelling technical content tailored to different audiences. You will need to be able to spread the gamut from technical deep dives for engineering & development teams up to business value focused conversations with executives Guide technical architecture decisions and help customers integrate Claude effectively into their existing technology stack Help customers develop evaluation frameworks to measure Claude's performance for their specific use cases Identify common integration patterns and contribute insights back to our Product and Engineering teams Travel occasionally to customer sites for workshops, technical deep dives, and relationship building Maintain strong knowledge of the latest developments in LLM capabilities and implementation patterns You may be a good fit if you have: 5+ years of experience in technical customer-facing roles such as Solutions Architect, Sales Engineer, or Technical Account Manager Experience working with enterprise customers, navigating complex buying cycles involving multiple stakeholders Exceptional ability to build relationships with and communicate technical concepts to diverse stakeholders to include C-suite executives, engineering & IT teams, and more Strong technical communication skills with the ability to translate customer requirements between technical and business stakeholders Experience designing scalable cloud architectures and integrating with enterprise systems Comfortable with python Familiarity with common LLM frameworks and tools or a background in machine learning or data science Excitement for engaging in cross-organizational collaboration, working through trade-offs, and balancing competing priorities A love of teaching, mentoring, and helping others succeed Excellent communication and interpersonal skills, able to convey complicated topics in easily understandable terms to a diverse set of external and internal stakeholders. You enjoy engaging in cross-organizational collaboration, working through trade-offs, and balancing competing priorities Passion for thinking creatively about how to use technology in a way that is safe and beneficial, and ultimately furthers the goal of advancing safe AI systems Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$240,000 - $270,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4461444008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4461444008",
    "title": "Solutions Architect, Enterprise Industries",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "New York City, NY; San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4461444008",
    "departments": [
      "Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-19T18:49:25.811Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As an Applied AI team member at Anthropic, you will be a Pre-Sales architect focused on becoming a trusted technical advisor helping large enterprises understand the value of Claude and paint the vision on how they can successfully integrate and deploy Claude into their technology stack. You&#39;ll combine your deep technical expertise with customer-facing skills to architect innovative LLM solutions that address complex business challenges while maintaining our high standards for safety and reliability.&lt;/p&gt;\n&lt;p&gt;Working closely with our Sales, Product, and Engineering teams, you&#39;ll guide customers from initial technical discovery through successful deployment. You&#39;ll leverage your expertise to help customers understand Claude&#39;s capabilities, develop evals, and design scalable architectures that maximize the value of our AI systems.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Partner with account executives to deeply understand customer requirements and translate them into technical solutions, ensuring alignment between business objectives and technical implementation&lt;/li&gt;\n&lt;li&gt;Serve as the primary technical advisor to enterprise customers throughout their Claude adoption journey, from discovery to initial evaluation through deployment. You will need to coordinate internally across multiple teams &amp;amp; stakeholders to drive customer success&lt;/li&gt;\n&lt;li&gt;Support customers building with both the Claude API and Claude for Work&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Create and deliver compelling technical content tailored to different audiences. You will need to be able to spread the gamut from technical deep dives for engineering &amp;amp; development teams up to business value focused conversations with executives&lt;/li&gt;\n&lt;li&gt;Guide technical architecture decisions and help customers integrate Claude effectively into their existing technology stack&lt;/li&gt;\n&lt;li&gt;Help customers develop evaluation frameworks to measure Claude&#39;s performance for their specific use cases&lt;/li&gt;\n&lt;li&gt;Identify common integration patterns and contribute insights back to our Product and Engineering teams&lt;/li&gt;\n&lt;li&gt;Travel occasionally to customer sites for workshops, technical deep dives, and relationship building&lt;/li&gt;\n&lt;li&gt;Maintain strong knowledge of the latest developments in LLM capabilities and implementation patterns&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in technical customer-facing roles such as Solutions Architect, Sales Engineer, or Technical Account Manager&lt;/li&gt;\n&lt;li&gt;Experience working with enterprise customers, navigating complex buying cycles involving multiple stakeholders&lt;/li&gt;\n&lt;li&gt;Exceptional ability to build relationships with and communicate technical concepts to diverse stakeholders to include C-suite executives, engineering &amp;amp; IT teams, and more&lt;/li&gt;\n&lt;li&gt;Strong technical communication skills with the ability to translate customer requirements between technical and business stakeholders&lt;/li&gt;\n&lt;li&gt;Experience designing scalable cloud architectures and integrating with enterprise systems&lt;/li&gt;\n&lt;li&gt;Comfortable with python&lt;/li&gt;\n&lt;li&gt;Familiarity with common LLM frameworks and tools or a background in machine learning or data science&lt;/li&gt;\n&lt;li&gt;Excitement for engaging in cross-organizational collaboration, working through trade-offs, and balancing competing priorities&lt;/li&gt;\n&lt;li&gt;A love of teaching, mentoring, and helping others succeed&lt;/li&gt;\n&lt;li&gt;Excellent communication and interpersonal skills, able to convey complicated topics in easily understandable terms to a diverse set of external and internal stakeholders. You enjoy engaging in cross-organizational collaboration, working through trade-offs, and balancing competing priorities&lt;/li&gt;\n&lt;li&gt;Passion for thinking creatively about how to use technology in a way that is safe and beneficial, and ultimately furthers the goal of advancing safe AI systems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$240,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$270,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4461444008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Partner Marketing Manager (Public Sector)",
    "employer_name": "datadog",
    "job_city": "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote",
    "job_apply_link": "https://careers.datadoghq.com/detail/7476873/?gh_jid=7476873",
    "job_posted_at_datetime_utc": "2026-01-12T12:36:11-05:00",
    "job_description": "Datadog’s Public Sector Marketing team is seeking an experienced Partner Marketing Manager to build and scale co-marketing programs with our strategic public sector partners, including AWS, Carahsoft, systems integrators (SIs), and resellers to drive pipeline and brand impact. This individual will develop, execute, and optimize co-marketing campaigns and enablement programs that position Datadog as the observability and security platform of choice for U.S. Federal, State, Local, and Education (SLED) markets.This role requires knowledge of the public sector ecosystem, government procurement processes, and the unique compliance and security requirements (e.g., FedRAMP, GovRAMP). You will work cross-functionally with sales, product marketing, field marketing, alliances, and demand generation teams to ensure partner marketing efforts are aligned to Datadog’s growth goals in the public sector.At Datadog, we place value in our office culture - the relationships and collaboration it builds, and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.What You’ll DoLead partner go-to-market strategy by developing and executing joint marketing plans with key public sector partners (AWS, Carahsoft, systems integrators, resellers).Manage MDF through planning, approving, tracking, and optimizing partner marketing development fund investments for campaigns, events, and targeted digital programs.Own the end-to-end execution of partner-led and co-branded marketing activities, from planning to performance analysis.Create and maintain enablement resources including partner playbooks, battlecards, solution briefs, and co-branded partner collateral to position Datadog effectively with public sector audiences.Drive partner seller readiness through training sessions, workshops, and enablement programs that empower partners to articulate Datadog’s value in mission-critical environments.Develop customer success storytelling with partners by producing case studies and proof points that highlight government and education wins.Collaborate cross-functionally with Public Sector Sales, Field Marketing, Product Marketing, and Demand Generation teams to align campaigns, messaging, and market approach. Build relationships with partner marketing teams to maximize collaboration and program impact.Track and report performance using Salesforce, partner portals, and analytics to measure sourced / influenced pipeline, enablement adoption, and MDF ROI.Who You Are6+ years of experience in partner marketing, alliances marketing, or channel marketing, ideally with a SaaS or cloud technology company serving the public sector.Strong understanding of public sector sales cycles, procurement vehicles, and compliance requirements (FedRAMP, SEWP, GSA).Proven track record building co-marketing campaigns with hyperscalers (AWS, Azure, GCP) and/or leading distributors / SIs in the public sector.Skilled at navigating complex partner organizations and building trusted relationships across marketing, sales, and alliance teams.Excellent written and verbal communicator, adept at translating technical concepts into mission-relevant messaging for government audiences.You work fluidly across multiple internal teams and external partners.Strong communication skills with both technical and executive-level audiences.You understand the mechanics of SaaS / cloud partner ecosystems, especially managing MDF and enabling co‑marketing efforts.Self-starter who thrives in a fast-paced, collaborative environment. Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply. Why Join Datadog Public Sector MarketingYou’ll join a fast-moving, data-driven team executing high-impact campaigns that help government agencies secure critical systems, modernize faster, and operate more efficiently. This role offers the opportunity to shape Datadog’s public sector partner marketing engine at a time of rapid growth, with significant impact on pipeline and market positioning. Benefits and Growth: Generous and competitive benefits packageNew hire stock equity (RSUs) and employee stock purchase planContinuous career development and pathing opportunities Product training to develop an in-depth understanding of our product and spaceBest in breed onboardingInternal mentor and buddy program cross-departmentallyFriendly and inclusive workplace cultureBenefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate's skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.The reasonably estimated yearly salary for this role at Datadog is:$96,000—$128,000 USDAbout Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog Learning Center.Equal Opportunity at Datadog:Datadog is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our Candidate Legal Notices for your reference. Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete this form. This form is for accommodation requests only and cannot be used to inquire about the status of applications. Privacy and AI Guidelines:Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice. For information on our AI policy, please visit Interviewing at Datadog AI Guidelines.Requisition ID: R17071",
    "id": "careers-datadoghq-com-detail-7476873",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7476873",
    "title": "Partner Marketing Manager (Public Sector)",
    "company_name": "datadog",
    "company_slug": "datadog",
    "location": "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote",
    "locations": [
      "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote"
    ],
    "url": "https://careers.datadoghq.com/detail/7476873/?gh_jid=7476873",
    "departments": [
      "Field Marketing"
    ],
    "employment_type": null,
    "posted_at": "2026-01-12T12:36:11-05:00",
    "fetched_at": "2026-01-19T18:49:28.845Z",
    "description": "&lt;p&gt;Datadog’s Public Sector Marketing team is seeking an experienced Partner Marketing Manager to build and scale co-marketing programs with our strategic public sector partners, including AWS, Carahsoft, systems integrators (SIs), and resellers to drive pipeline and brand impact. This individual will develop, execute, and optimize co-marketing campaigns and enablement programs that position Datadog as the observability and security platform of choice for U.S. Federal, State, Local, and Education (SLED) markets.&lt;/p&gt;\n&lt;p&gt;This role requires knowledge of the public sector ecosystem, government procurement processes, and the unique compliance and security requirements (e.g., FedRAMP, GovRAMP). You will work cross-functionally with sales, product marketing, field marketing, alliances, and demand generation teams to ensure partner marketing efforts are aligned to Datadog’s growth goals in the public sector.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;At Datadog, we place value in our office culture - the relationships and collaboration it builds, and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.&lt;/em&gt;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;What You’ll Do&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead partner go-to-market strategy by developing and executing joint marketing plans with key public sector partners (AWS, Carahsoft, systems integrators, resellers).&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Manage MDF through planning, approving, tracking, and optimizing partner marketing development fund investments for campaigns, events, and targeted digital programs.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Own the end-to-end execution of partner-led and co-branded marketing activities, from planning to performance analysis.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Create and maintain enablement resources including partner playbooks, battlecards, solution briefs, and co-branded partner collateral to position Datadog effectively with public sector audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Drive partner seller readiness through training sessions, workshops, and enablement programs that empower partners to articulate Datadog’s value in mission-critical environments.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Develop customer success storytelling with partners by producing case studies and proof points that highlight government and education wins.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Collaborate cross-functionally with Public Sector Sales, Field Marketing, Product Marketing, and Demand Generation teams to align campaigns, messaging, and market approach. Build relationships with partner marketing teams to maximize collaboration and program impact.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Track and report performance using Salesforce, partner portals, and analytics to measure sourced / influenced pipeline, enablement adoption, and MDF ROI.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Who You Are&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;6+ years of experience in partner marketing, alliances marketing, or channel marketing, ideally with a SaaS or cloud technology company serving the public sector.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Strong understanding of public sector sales cycles, procurement vehicles, and compliance requirements (FedRAMP, SEWP, GSA).&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Proven track record building co-marketing campaigns with hyperscalers (AWS, Azure, GCP) and/or leading distributors / SIs in the public sector.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Skilled at navigating complex partner organizations and building trusted relationships across marketing, sales, and alliance teams.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Excellent written and verbal communicator, adept at translating technical concepts into mission-relevant messaging for government audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;You work fluidly across multiple internal teams and external partners.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Strong communication skills with both technical and executive-level audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;You understand the mechanics of SaaS / cloud partner ecosystems, especially managing MDF and enabling co‑marketing efforts.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Self-starter who thrives in a fast-paced, collaborative environment.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That&#39;s okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply.&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;Why Join Datadog Public Sector Marketing&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;You’ll join a fast-moving, data-driven team executing high-impact campaigns that help government agencies secure critical systems, modernize faster, and operate more efficiently. This role offers the opportunity to shape Datadog’s public sector partner marketing engine at a time of rapid growth, with significant impact on pipeline and market positioning.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Benefits and Growth:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Generous and competitive benefits package&lt;/li&gt;\n&lt;li&gt;New hire stock equity (RSUs) and employee stock purchase plan&lt;/li&gt;\n&lt;li&gt;Continuous career development and pathing opportunities&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Product training to develop an in-depth understanding of our product and space&lt;/li&gt;\n&lt;li&gt;Best in breed onboarding&lt;/li&gt;\n&lt;li&gt;Internal mentor and buddy program cross-departmentally&lt;/li&gt;\n&lt;li&gt;Friendly and inclusive workplace culture&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate&#39;s skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;The reasonably estimated yearly salary for this role at Datadog is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$96,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$128,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;hr&gt;\n&lt;p&gt;&lt;strong&gt;About Datadog:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on &lt;a href=&quot;https://www.instagram.com/datadoghq/?hl=en&quot; target=&quot;_blank&quot;&gt;Instagram&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/company/datadog&quot; target=&quot;_blank&quot;&gt;LinkedIn,&lt;/a&gt; and &lt;a href=&quot;https://learn.datadoghq.com/&quot; target=&quot;_blank&quot;&gt;Datadog Learning Center. &lt;/a&gt;&lt;/p&gt;\n&lt;hr&gt;\n&lt;p data-renderer-start-pos=&quot;215&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Equal Opportunity at Datadog:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog is proud to offer &lt;a href=&quot;https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf&quot; target=&quot;_blank&quot;&gt;equal employment opportunity&lt;/a&gt; to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our &lt;a href=&quot;https://www.datadoghq.com/legal/candidate-legal-notices/&quot; target=&quot;_blank&quot;&gt;Candidate Legal Notices&lt;/a&gt; for your reference.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSeoJeduEZ2NdZF_65uZmWUrCM-zee7yADXX1s6Xr9zAGq8iKA/viewform&quot; target=&quot;_blank&quot;&gt;this form&lt;/a&gt;. This form is for accommodation requests only and cannot be used to inquire about the status of applications.&amp;nbsp;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Privacy and AI Guidelines:&lt;/strong&gt;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; data-sk=&quot;tooltip_parent&quot;&gt;Applicant and Candidate Privacy Notice&lt;/a&gt;. For information on our AI policy, please visit &lt;a href=&quot;https://www.datadoghq.com/legal/interviewing-at-datadog-ai-guidelines/&quot; target=&quot;_blank&quot;&gt;Interviewing at Datadog AI Guidelines&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7476873
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  }
]