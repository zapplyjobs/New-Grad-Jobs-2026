[
  {
    "job_title": "Developer Campaign Marketer, Claude Code",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5026189008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role Anthropic is seeking an experienced Developer Campaign Marketer to lead marketing efforts for Startups and Claude Code, our command line tool that enables developers to delegate coding tasks directly from their terminal. In this pivotal role, you will develop and execute comprehensive marketing campaigns that drive awareness, adoption, and engagement with Claude Code among startups, developers, technical teams, and engineering organizations. You will work at the intersection of developer relations, product marketing, and community building, executing on integrated campaigns that bring together compelling technical content and programs that resonate with developers. As a key member of the marketing team, you will be responsible for driving pipeline and active usage of Claude Code by working with Product Marketing to design campaigns that communicate our value propositions through the right channels and create scalable programs that drive measurable growth. The ideal candidate combines technical understanding with strong marketing instincts and can orchestrate campaigns that developers want to engage with. Responsibilities Develop and execute comprehensive marketing campaigns for Claude Code to generate pipeline by driving awareness and adoption among startups, developers, technical teams, and engineering organizations Develop deep understanding of the AI developer and startups audience, including behaviors, communication preferences, and communities, to inform channel strategy and adapt campaign messaging that resonates with how developers discover, evaluate, and adopt AI tools Partner with Product Marketing to translate product positioning and go-to-market strategy into executable campaign plans for developer audiences Execute on integrated marketing campaigns by working with centers of excellence across channels including content, media, developer-focused platforms (GitHub, Stack Overflow, Hacker News, Reddit), events, and partnerships Own campaign performance reporting and optimization iteration; provide feedback loop on campaign performance back to Product Marketing leadership Partner closely with product marketing and engineering teams to ensure marketing campaign strategies align with product development and user needs Track and analyze key metrics including Claude Code pipeline in target accounts, developer adoption, engagement, retention, and satisfaction, using data to continuously optimize marketing strategies Collaborate with the broader marketing team to ensure Claude Code messaging is integrated into Anthropic's overall marketing campaign and serve as execution lead on campaigns focused on our developer and startups audiences You have: 5+ years of experience in developer or campaign marketing with ownership of pipeline target, technical product marketing or developer relations experience is a plus Experience building and scaling demand gen programs targeted to developer communities, whether through online platforms, events, or advocacy programs Deep understanding of developer workflows, tools, and communities Demonstrated success launching and marketing developer tools, CLI tools, APIs, or infrastructure products Excellent collaboration skills and experience working cross-functionally with product, engineering, and sales teams Analytical mindset with experience tracking developer metrics and using data to inform marketing decisions and optimize campaign tactics Genuine passion for developer experience and a track record of earning trust and credibility in developer communities Nice to haves: Experience marketing AI/ML tools or emerging technology categories to technical audiences Background in software engineering or technical roles with professional coding experience Experience with open source community building and contribution Familiarity with command line tools, terminal workflows, and developer productivity tools Experience in high-growth startup environments or launching new developer products from scratch The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$255,000 - $255,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5026189008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5026189008",
    "title": "Developer Campaign Marketer, Claude Code",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5026189008",
    "departments": [
      "Marketing & Brand"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Anthropic is seeking an experienced Developer Campaign Marketer to lead marketing efforts for Startups and Claude Code, our command line tool that enables developers to delegate coding tasks directly from their terminal. In this pivotal role, you will develop and execute comprehensive marketing campaigns that drive awareness, adoption, and engagement with Claude Code among startups, developers, technical teams, and engineering organizations.&lt;/p&gt;\n&lt;p&gt;You will work at the intersection of developer relations, product marketing, and community building, executing on integrated campaigns that bring together compelling technical content and programs that resonate with developers. As a key member of the marketing team, you will be responsible for driving pipeline and active usage of Claude Code by working with Product Marketing to design campaigns that communicate our value propositions through the right channels and create scalable programs that drive measurable growth. The ideal candidate combines technical understanding with strong marketing instincts and can orchestrate campaigns that developers want to engage with.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Develop and execute comprehensive marketing campaigns for Claude Code to generate pipeline by driving awareness and adoption among startups, developers, technical teams, and engineering organizations&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Develop deep understanding of the AI developer and startups audience, including behaviors, communication preferences, and communities, to inform channel strategy and adapt campaign messaging that resonates with how developers discover, evaluate, and adopt AI tools&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Partner with Product Marketing to translate product positioning and go-to-market strategy into executable campaign plans for developer audiences&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Execute on integrated marketing campaigns by working with centers of excellence across channels including content, media, developer-focused platforms (GitHub, Stack Overflow, Hacker News, Reddit), events, and partnerships&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Own campaign performance reporting and optimization iteration; provide feedback loop on campaign performance back to Product Marketing leadership&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Partner closely with product marketing and engineering teams to ensure marketing campaign strategies align with product development and user needs&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Track and analyze key metrics including Claude Code pipeline in target accounts, developer adoption, engagement, retention, and satisfaction, using data to continuously optimize marketing strategies&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Collaborate with the broader marketing team to ensure Claude Code messaging is integrated into Anthropic&#39;s overall marketing campaign and serve as execution lead on campaigns focused on our developer and startups audiences&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;You have:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;5+ years of experience in developer or campaign marketing with ownership of pipeline target, technical product marketing or developer relations experience is a plus&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience building and scaling demand gen programs targeted to developer communities, whether through online platforms, events, or advocacy programs&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Deep understanding of developer workflows, tools, and communities&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Demonstrated success launching and marketing developer tools, CLI tools, APIs, or infrastructure products&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Excellent collaboration skills and experience working cross-functionally with product, engineering, and sales teams&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Analytical mindset with experience tracking developer metrics and using data to inform marketing decisions and optimize campaign tactics&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Genuine passion for developer experience and a track record of earning trust and credibility in developer communities&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Nice to haves:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Experience marketing AI/ML tools or emerging technology categories to technical audiences&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Background in software engineering or technical roles with professional coding experience&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience with open source community building and contribution&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Familiarity with command line tools, terminal workflows, and developer productivity tools&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience in high-growth startup environments or launching new developer products from scratch&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$255,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$255,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5026189008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Head of Azure Partnership",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5082397008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role Anthropic recently announced a transformative strategic partnership with Microsoft, positioning Claude as the only frontier AI model available across all three major cloud platforms. This partnership includes a $30 billion Azure compute commitment and represents one of the most significant AI-cloud partnerships in the industry. We're looking for a leader to build this partnership from the ground up into a multi-billion-dollar business. As Head of Azure Partnership, you will define and execute the strategy for Anthropic's Microsoft relationship — spanning Azure AI Foundry, GitHub Copilot, Microsoft 365 Copilot, and Copilot Studio. You'll build a team, establish executive relationships across Microsoft's global organization, and create the co-sell and go-to-market motions that drive Claude adoption at enterprise scale. This is a greenfield opportunity to shape how a landmark AI-cloud partnership is commercialized. Responsibilities: Define the strategic vision for Anthropic's Microsoft partnership, including annual business planning, multi-year revenue targets, joint roadmap development, and executive-level operational cadences (MBRs, QBRs) Build and lead a high-performing team, scaling to 6-8 people in the first year with international coverage across EMEA and APAC — with potential to grow significantly as the partnership matures Establish and own executive relationships across Microsoft's field organization, Azure leadership, and product teams at the most senior levels Drive partner-sourced and partner-influenced revenue from inception toward a multi-billion-dollar annual run rate, building forecasting models and pipeline management across Strategic, Major, and Enterprise accounts Develop and track field activation metrics — driving measurable engagement from Microsoft sellers and solutions architects on Claude opportunities Partner cross-functionally with Product, Engineering, Trust & Safety, and Legal to ensure successful integration and deployment of Claude across Microsoft's ecosystem Create scalable co-selling motions, enablement programs, and joint customer engagement frameworks Represent Anthropic in high-stakes executive meetings and strategic negotiations with Microsoft leadership Collaborate with GSI/SI partnerships (Accenture, Deloitte, etc.) on cloud-influenced enterprise deals You may be a good fit if you have: 15+ years of experience in partnerships, business development, or GTM leadership at technology companies, with deep experience managing strategic cloud provider relationships at scale Experience building hyperscaler partnerships to billions of dollars in revenue — ideally having transformed competitive dynamics into strategic alignment Proven track record building and scaling teams in high-growth environments, from early stages through significant organizational growth Deep understanding of enterprise cloud services, AI/ML market dynamics, and the Microsoft ecosystem specifically Exceptional executive presence and the ability to build trusted relationships with the most senior leaders across complex, matrixed organizations Strong business acumen paired with technical credibility — you can engage with solutions architects and hold your own in discussions about AI capabilities and enterprise deployment Comfort with ambiguity and rapid iteration; you can build an organization and its processes from scratch while delivering results in parallel Comfort with rigorous pipeline management, partner activation metrics, and data-driven operating rhythms Strong candidates may also have: Direct experience at Microsoft in senior BD, partnership, or GTM leadership roles Track record scaling cloud or AI partnerships at a major ISV (Snowflake, Databricks, MongoDB, Confluent, or similar) Experience navigating multi-cloud partnership dynamics where partners are simultaneously competitors Established relationships within Microsoft's senior field organization and partner ecosystem International GTM experience, particularly in APAC or EMEA markets Board-level or executive advisory experience in technology or growth-stage companies The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$248,500 - $297,500 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5082397008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5082397008",
    "title": "Head of Azure Partnership",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | Seattle, WA",
    "locations": [
      "San Francisco, CA | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5082397008",
    "departments": [
      "Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;About the role&lt;/h2&gt;\n&lt;p&gt;Anthropic recently announced a transformative strategic partnership with Microsoft, positioning Claude as the only frontier AI model available across all three major cloud platforms. This partnership includes a $30 billion Azure compute commitment and represents one of the most significant AI-cloud partnerships in the industry. &lt;br&gt;&lt;br&gt;We&#39;re looking for a leader to build this partnership from the ground up into a multi-billion-dollar business.&lt;/p&gt;\n&lt;p&gt;As Head of Azure Partnership, you will define and execute the strategy for Anthropic&#39;s Microsoft relationship — spanning Azure AI Foundry, GitHub Copilot, Microsoft 365 Copilot, and Copilot Studio. You&#39;ll build a team, establish executive relationships across Microsoft&#39;s global organization, and create the co-sell and go-to-market motions that drive Claude adoption at enterprise scale. This is a greenfield opportunity to shape how a landmark AI-cloud partnership is commercialized.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Define the strategic vision for Anthropic&#39;s Microsoft partnership, including annual business planning, multi-year revenue targets, joint roadmap development, and executive-level operational cadences (MBRs, QBRs)&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Build and lead a high-performing team, scaling to 6-8 people in the first year with international coverage across EMEA and APAC — with potential to grow significantly as the partnership matures&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Establish and own executive relationships across Microsoft&#39;s field organization, Azure leadership, and product teams at the most senior levels&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Drive partner-sourced and partner-influenced revenue from inception toward a multi-billion-dollar annual run rate, building forecasting models and pipeline management across Strategic, Major, and Enterprise accounts&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Develop and track field activation metrics — driving measurable engagement from Microsoft sellers and solutions architects on Claude opportunities&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Partner cross-functionally with Product, Engineering, Trust &amp;amp; Safety, and Legal to ensure successful integration and deployment of Claude across Microsoft&#39;s ecosystem&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Create scalable co-selling motions, enablement programs, and joint customer engagement frameworks&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Represent Anthropic in high-stakes executive meetings and strategic negotiations with Microsoft leadership&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Collaborate with GSI/SI partnerships (Accenture, Deloitte, etc.) on cloud-influenced enterprise deals&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;15+ years of experience in partnerships, business development, or GTM leadership at technology companies, with deep experience managing strategic cloud provider relationships at scale&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience building hyperscaler partnerships to billions of dollars in revenue — ideally having transformed competitive dynamics into strategic alignment&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Proven track record building and scaling teams in high-growth environments, from early stages through significant organizational growth&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Deep understanding of enterprise cloud services, AI/ML market dynamics, and the Microsoft ecosystem specifically&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Exceptional executive presence and the ability to build trusted relationships with the most senior leaders across complex, matrixed organizations&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Strong business acumen paired with technical credibility — you can engage with solutions architects and hold your own in discussions about AI capabilities and enterprise deployment&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Comfort with ambiguity and rapid iteration; you can build an organization and its processes from scratch while delivering results in parallel&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Comfort with rigorous pipeline management, partner activation metrics, and data-driven operating rhythms&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Strong candidates may also have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Direct experience at Microsoft in senior BD, partnership, or GTM leadership roles&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Track record scaling cloud or AI partnerships at a major ISV (Snowflake, Databricks, MongoDB, Confluent, or similar)&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience navigating multi-cloud partnership dynamics where partners are simultaneously competitors&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Established relationships within Microsoft&#39;s senior field organization and partner ecosystem&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;International GTM experience, particularly in APAC or EMEA markets&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Board-level or executive advisory experience in technology or growth-stage companies&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$248,500&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$297,500 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5082397008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Pre-training",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4616971008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems. Key Responsibilities: Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development Independently lead small research projects while collaborating with team members on larger initiatives Design, run, and analyze scientific experiments to advance our understanding of large language models Optimize and scale our training infrastructure to improve efficiency and reliability Develop and improve dev tooling to enhance team productivity Contribute to the entire stack, from low-level optimizations to high-level model design Qualifications: Advanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field Strong software engineering skills with a proven track record of building complex systems Expertise in Python and experience with deep learning frameworks (PyTorch preferred) Familiarity with large-scale machine learning, particularly in the context of language models Ability to balance research goals with practical engineering constraints Strong problem-solving skills and a results-oriented mindset Excellent communication skills and ability to work in a collaborative environment Care about the societal impacts of your work Preferred Experience: Work on high-performance, large-scale ML systems Familiarity with GPUs, Kubernetes, and OS internals Experience with language modeling using transformer architectures Knowledge of reinforcement learning techniques Background in large-scale ETL processes You'll thrive in this role if you: Have significant software engineering experience Are results-oriented with a bias towards flexibility and impact Willingly take on tasks outside your job description to support the team Enjoy pair programming and collaborative work Are eager to learn more about machine learning research Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects Are working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research View research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights Have ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term. Sample Projects: Optimizing the throughput of novel attention mechanisms Comparing compute efficiency of different Transformer variants Preparing large-scale datasets for efficient model consumption Scaling distributed training jobs to thousands of GPUs Designing fault tolerance strategies for our training infrastructure Creating interactive visualizations of model internals, such as attention patterns At Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech. If you're excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4616971008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4616971008",
    "title": "Research Engineer, Pre-training",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4616971008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Key Responsibilities:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development&lt;/li&gt;\n&lt;li&gt;Independently lead small research projects while collaborating with team members on larger initiatives&lt;/li&gt;\n&lt;li&gt;Design, run, and analyze scientific experiments to advance our understanding of large language models&lt;/li&gt;\n&lt;li&gt;Optimize and scale our training infrastructure to improve efficiency and reliability&lt;/li&gt;\n&lt;li&gt;Develop and improve dev tooling to enhance team productivity&lt;/li&gt;\n&lt;li&gt;Contribute to the entire stack, from low-level optimizations to high-level model design&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Qualifications:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Advanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field&lt;/li&gt;\n&lt;li&gt;Strong software engineering skills with a proven track record of building complex systems&lt;/li&gt;\n&lt;li&gt;Expertise in Python and experience with deep learning frameworks (PyTorch preferred)&lt;/li&gt;\n&lt;li&gt;Familiarity with large-scale machine learning, particularly in the context of language models&lt;/li&gt;\n&lt;li&gt;Ability to balance research goals with practical engineering constraints&lt;/li&gt;\n&lt;li&gt;Strong problem-solving skills and a results-oriented mindset&lt;/li&gt;\n&lt;li&gt;Excellent communication skills and ability to work in a collaborative environment&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Preferred Experience:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Work on high-performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;Familiarity with GPUs, Kubernetes, and OS internals&lt;/li&gt;\n&lt;li&gt;Experience with language modeling using transformer architectures&lt;/li&gt;\n&lt;li&gt;Knowledge of reinforcement learning techniques&lt;/li&gt;\n&lt;li&gt;Background in large-scale ETL processes&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;You&#39;ll thrive in this role if you:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant software engineering experience&lt;/li&gt;\n&lt;li&gt;Are results-oriented with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Willingly take on tasks outside your job description to support the team&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming and collaborative work&lt;/li&gt;\n&lt;li&gt;Are eager to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects&lt;/li&gt;\n&lt;li&gt;Are working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research&lt;/li&gt;\n&lt;li&gt;View research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights&lt;/li&gt;\n&lt;li&gt;Have ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Sample Projects:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Optimizing the throughput of novel attention mechanisms&lt;/li&gt;\n&lt;li&gt;Comparing compute efficiency of different Transformer variants&lt;/li&gt;\n&lt;li&gt;Preparing large-scale datasets for efficient model consumption&lt;/li&gt;\n&lt;li&gt;Scaling distributed training jobs to thousands of GPUs&lt;/li&gt;\n&lt;li&gt;Designing fault tolerance strategies for our training infrastructure&lt;/li&gt;\n&lt;li&gt;Creating interactive visualizations of model internals, such as attention patterns&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;At Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech.&lt;/p&gt;\n&lt;p&gt;If you&#39;re excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4616971008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Pretraining Scaling",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4938432008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role: Anthropic's ML Performance and Scaling team trains our production pretrained models, work that directly shapes the company's future and our mission to build safe, beneficial AI systems. As a Research Engineer on this team, you'll ensure our frontier models train reliably, efficiently, and at scale. This is demanding, high-impact work that requires both deep technical expertise and a genuine passion for the craft of large-scale ML systems. This role lives at the boundary between research and engineering. You'll work across our entire production training stack: performance optimization, hardware debugging, experimental design, and launch coordination. During launches, the team works in tight lockstep, responding to production issues that can't wait for tomorrow. Responsibilities: Own critical aspects of our production pretraining pipeline, including model operations, performance optimization, observability, and reliability Debug and resolve complex issues across the full stack—from hardware errors and networking to training dynamics and evaluation infrastructure Design and run experiments to improve training efficiency, reduce step time, increase uptime, and enhance model performance Respond to on-call incidents during model launches, diagnosing problems quickly and coordinating solutions across teams Build and maintain production logging, monitoring dashboards, and evaluation infrastructure Add new capabilities to the training codebase, such as long context support or novel architectures Collaborate closely with teammates across SF and London, as well as with Tokens, Architectures, and Systems teams Contribute to the team's institutional knowledge by documenting systems, debugging approaches, and lessons learned You May Be a Good Fit If You: Have hands-on experience training large language models, or deep expertise with JAX, TPU, PyTorch, or large-scale distributed systems Genuinely enjoy both research and engineering work—you'd describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other Are excited about being on-call for production systems, working long days during launches, and solving hard problems under pressure Thrive when working on whatever is most impactful, even if that changes day-to-day based on what the production model needs Excel at debugging complex, ambiguous problems across multiple layers of the stack Communicate clearly and collaborate effectively, especially when coordinating across time zones or during high-stress incidents Are passionate about the work itself and want to refine your craft as a research engineer Care about the societal impacts of AI and responsible scaling Strong Candidates May Also Have: Previous experience training LLM’s or working extensively with JAX/TPU, PyTorch, or other ML frameworks at scale Contributed to open-source LLM frameworks (e.g., open_lm, llm-foundry, mesh-transformer-jax) Published research on model training, scaling laws, or ML systems Experience with production ML systems, observability tools, or evaluation infrastructure Background as a systems engineer, quant, or in other roles requiring both technical depth and operational excellence What Makes This Role Unique: This is not a typical research engineering role. The work is highly operational—you'll be deeply involved in keeping our production models training smoothly, which means being responsive to incidents, flexible about priorities, and comfortable with uncertainty. During launches, the team often works extended hours and may need to respond to issues on evenings and weekends. However, this operational intensity comes with extraordinary learning opportunities. You'll gain hands-on experience with some of the largest, most sophisticated training runs in the industry. You'll work alongside world-class researchers and engineers, and the institutional knowledge you build will compound in ways that can't be easily transferred. For people who thrive on this type of work, it's uniquely rewarding. We're building a close-knit team of people who genuinely care about doing excellent work together. If you're someone who wants to be part of training the models that will define the future of AI—and you're excited about the full reality of what that entails—we'd love to hear from you. Location:This role requires working in-office 5 days per week in San Francisco. Deadline to apply: None. Applications will be reviewed on a rolling basis.The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4938432008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4938432008",
    "title": "Research Engineer, Pretraining Scaling",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4938432008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic&#39;s ML Performance and Scaling team trains our production pretrained models, work that directly shapes the company&#39;s future and our mission to build safe, beneficial AI systems. As a Research Engineer on this team, you&#39;ll ensure our frontier models train reliably, efficiently, and at scale. This is demanding, high-impact work that requires both deep technical expertise and a genuine passion for the craft of large-scale ML systems.&lt;/p&gt;\n&lt;p&gt;This role lives at the boundary between research and engineering. You&#39;ll work across our entire production training stack: performance optimization, hardware debugging, experimental design, and launch coordination. During launches, the team works in tight lockstep, responding to production issues that can&#39;t wait for tomorrow.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Own critical aspects of our production pretraining pipeline, including model operations, performance optimization, observability, and reliability&lt;/li&gt;\n&lt;li&gt;Debug and resolve complex issues across the full stack—from hardware errors and networking to training dynamics and evaluation infrastructure&lt;/li&gt;\n&lt;li&gt;Design and run experiments to improve training efficiency, reduce step time, increase uptime, and enhance model performance&lt;/li&gt;\n&lt;li&gt;Respond to on-call incidents during model launches, diagnosing problems quickly and coordinating solutions across teams&lt;/li&gt;\n&lt;li&gt;Build and maintain production logging, monitoring dashboards, and evaluation infrastructure&lt;/li&gt;\n&lt;li&gt;Add new capabilities to the training codebase, such as long context support or novel architectures&lt;/li&gt;\n&lt;li&gt;Collaborate closely with teammates across SF and London, as well as with Tokens, Architectures, and Systems teams&lt;/li&gt;\n&lt;li&gt;Contribute to the team&#39;s institutional knowledge by documenting systems, debugging approaches, and lessons learned&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You May Be a Good Fit If You:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have hands-on experience training large language models, or deep expertise with JAX, TPU, PyTorch, or large-scale distributed systems&lt;/li&gt;\n&lt;li&gt;Genuinely enjoy both research and engineering work—you&#39;d describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other&lt;/li&gt;\n&lt;li&gt;Are excited about being on-call for production systems, working long days during launches, and solving hard problems under pressure&lt;/li&gt;\n&lt;li&gt;Thrive when working on whatever is most impactful, even if that changes day-to-day based on what the production model needs&lt;/li&gt;\n&lt;li&gt;Excel at debugging complex, ambiguous problems across multiple layers of the stack&lt;/li&gt;\n&lt;li&gt;Communicate clearly and collaborate effectively, especially when coordinating across time zones or during high-stress incidents&lt;/li&gt;\n&lt;li&gt;Are passionate about the work itself and want to refine your craft as a research engineer&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of AI and responsible scaling&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong Candidates May Also Have:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Previous experience training LLM’s or working extensively with JAX/TPU, PyTorch, or other ML frameworks at scale&lt;/li&gt;\n&lt;li&gt;Contributed to open-source LLM frameworks (e.g., open_lm, llm-foundry, mesh-transformer-jax)&lt;/li&gt;\n&lt;li&gt;Published research on model training, scaling laws, or ML systems&lt;/li&gt;\n&lt;li&gt;Experience with production ML systems, observability tools, or evaluation infrastructure&lt;/li&gt;\n&lt;li&gt;Background as a systems engineer, quant, or in other roles requiring both technical depth and operational excellence&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;What Makes This Role Unique:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;This is not a typical research engineering role. The work is highly operational—you&#39;ll be deeply involved in keeping our production models training smoothly, which means being responsive to incidents, flexible about priorities, and comfortable with uncertainty. During launches, the team often works extended hours and may need to respond to issues on evenings and weekends.&lt;/p&gt;\n&lt;p&gt;However, this operational intensity comes with extraordinary learning opportunities. You&#39;ll gain hands-on experience with some of the largest, most sophisticated training runs in the industry. You&#39;ll work alongside world-class researchers and engineers, and the institutional knowledge you build will compound in ways that can&#39;t be easily transferred. For people who thrive on this type of work, it&#39;s uniquely rewarding.&lt;/p&gt;\n&lt;p&gt;We&#39;re building a close-knit team of people who genuinely care about doing excellent work together. If you&#39;re someone who wants to be part of training the models that will define the future of AI—and you&#39;re excited about the full reality of what that entails—we&#39;d love to hear from you.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Location:&lt;/strong&gt;This role requires working in-office 5 days per week in San Francisco.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None. Applications will be reviewed on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4938432008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Production Model Post Training",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4613592008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role Anthropic's production models undergo sophisticated post-training processes to enhance their capabilities, alignment, and safety. As a Research Engineer on our Post-Training team, you'll train our base models through the complete post-training stack to deliver the production Claude models that users interact with. You'll work at the intersection of cutting-edge research and production engineering, implementing, scaling, and improving post-training techniques like Constitutional AI, RLHF, and other alignment methodologies. Your work will directly impact the quality, safety, and capabilities of our production models. Note: For this role, we conduct all interviews in Python. This role may require responding to incidents on short-notice, including on weekends. Responsibilities: Implement and optimize post-training techniques at scale on frontier models Conduct research to develop and optimize post-training recipes that directly improve production model quality Design, build, and run robust, efficient pipelines for model fine-tuning and evaluation Develop tools to measure and improve model performance across various dimensions Collaborate with research teams to translate emerging techniques into production-ready implementations Debug complex issues in training pipelines and model behavior Help establish best practices for reliable, reproducible model post-training You may be a good fit if you: Thrive in controlled chaos and are energised, rather than overwhelmed, when juggling multiple urgent priorities Adapt quickly to changing priorities Maintain clarity when debugging complex, time-sensitive issues Have strong software engineering skills with experience building complex ML systems Are comfortable working with large-scale distributed systems and high-performance computing Have experience with training, fine-tuning, or evaluating large language models Can balance research exploration with engineering rigor and operational reliability Are adept at analyzing and debugging model training processes Enjoy collaborating across research and engineering disciplines Can navigate ambiguity and make progress in fast-moving research environments Strong candidates may also: Have experience with LLMs Have a keen interest in AI safety and responsible deployment We welcome candidates at various experience levels, with a preference for senior engineers who have hands-on experience with frontier AI systems. However, proficiency in Python, deep learning frameworks, and distributed computing is required for this role.The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4613592008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4613592008",
    "title": "Research Engineer, Production Model Post Training",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4613592008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;Anthropic&#39;s production models undergo sophisticated post-training processes to enhance their capabilities, alignment, and safety. As a Research Engineer on our Post-Training team, you&#39;ll train our base models through the complete post-training stack to deliver the production Claude models that users interact with.&lt;/p&gt;\n&lt;p&gt;You&#39;ll work at the intersection of cutting-edge research and production engineering, implementing, scaling, and improving post-training techniques like Constitutional AI, RLHF, and other alignment methodologies. Your work will directly impact the quality, safety, and capabilities of our production models.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python. This role may require responding to incidents on short-notice, including on weekends.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Implement and optimize post-training techniques at scale on frontier models&lt;/li&gt;\n&lt;li&gt;Conduct research to develop and optimize post-training recipes that directly improve production model quality&lt;/li&gt;\n&lt;li&gt;Design, build, and run robust, efficient pipelines for model fine-tuning and evaluation&lt;/li&gt;\n&lt;li&gt;Develop tools to measure and improve model performance across various dimensions&lt;/li&gt;\n&lt;li&gt;Collaborate with research teams to translate emerging techniques into production-ready implementations&lt;/li&gt;\n&lt;li&gt;Debug complex issues in training pipelines and model behavior&lt;/li&gt;\n&lt;li&gt;Help establish best practices for reliable, reproducible model post-training&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Thrive in controlled chaos and&amp;nbsp;are energised, rather than overwhelmed, when juggling multiple urgent priorities&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Adapt quickly to changing priorities&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Maintain clarity when debugging complex, time-sensitive issues&lt;/li&gt;\n&lt;li&gt;Have strong software engineering skills with experience building complex ML systems&lt;/li&gt;\n&lt;li&gt;Are comfortable working with large-scale distributed systems and high-performance computing&lt;/li&gt;\n&lt;li&gt;Have experience with training, fine-tuning, or evaluating large language models&lt;/li&gt;\n&lt;li&gt;Can balance research exploration with engineering rigor and operational reliability&lt;/li&gt;\n&lt;li&gt;Are adept at analyzing and debugging model training processes&lt;/li&gt;\n&lt;li&gt;Enjoy collaborating across research and engineering disciplines&lt;/li&gt;\n&lt;li&gt;Can navigate ambiguity and make progress in fast-moving research environments&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have experience with LLMs&lt;/li&gt;\n&lt;li&gt;Have a keen interest in AI safety and responsible deployment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;We welcome candidates at various experience levels, with a preference for senior engineers who have hands-on experience with frontier AI systems. However, proficiency in Python, deep learning frameworks, and distributed computing is required for this role.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4613592008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer/Research Scientist, Audio",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5074815008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Anthropic’s Audio team pushes the boundaries of what's possible with audio with large language models. We care about making safe, steerable, reliable systems that can understand and generate speech and audio, prioritizing not only naturalness but also steerability and robustness. As a researcher on the Audio team, you'll work across the full stack of audio ML, developing audio codecs and representations, sourcing and synthesizing high quality audio data, training large-scale speech language models and large audio diffusion models, and developing novel architectures for incorporating continuous signals into LLMs. Our team focuses primarily but not exclusively on speech, building advanced steerable systems spanning end-to-end conversational systems, speech and audio understanding models, and speech synthesis capabilities. The team works closely with many collaborators across pretraining, finetuning, reinforcement learning, production inference, and product to get advanced audio technologies from early research to high impact real-world deployments. You may be a good fit if you: Have hands-on experience with training audio models, whether that's conversational speech-to-speech, speech translation, speech recognition, text-to-speech, diarization, codecs, or generative audio models Genuinely enjoy both research and engineering work, and you'd describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other Are comfortable working across abstraction levels, from signal processing fundamentals to large-scale model training and inference optimization Have deep expertise with JAX, PyTorch, or large-scale distributed training, and can debug performance issues across the full stack Thrive in fast-moving environments where the most important problem might shift as we learn more about what works Communicate clearly and collaborate effectively; audio touches many parts of our systems, so you'll work closely with teams across the company Are passionate about building conversational AI that feels natural, steerable, and safe Care about the societal impacts of voice AI and want to help shape how these systems are developed responsibly Strong candidates may also have experience with: Large language model pretraining and finetuning Training diffusion models for image and audio generation Reinforcement learning for large language models and diffusion models End-to-end system optimization, from performance benchmarking to kernel optimization GPUs, Kubernetes, PyTorch, or distributed training infrastructure Representative projects: Training state-of-the art neural audio codecs for 48 kHz stereo audio Developing novel algorithms for diffusion pretraining and reinforcement learning Scaling audio datasets to millions of hours of high quality audio Creating robust evaluation methodologies for hard-to-measure qualities such as naturalness or expressiveness Studying training dynamics of mixed audio-text language models Optimizing latency and inference throughput for deployed streaming audio systems The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5074815008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5074815008",
    "title": "Research Engineer/Research Scientist, Audio",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5074815008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Anthropic’s Audio team pushes the boundaries of what&#39;s possible with audio with large language models. We care about making safe, steerable, reliable systems that can understand and generate speech and audio, prioritizing not only naturalness but also steerability and robustness. As a researcher on the Audio team, you&#39;ll work across the full stack of audio ML, developing audio codecs and representations, sourcing and synthesizing high quality audio data, training large-scale speech language models and large audio diffusion models, and developing novel architectures for incorporating continuous signals into LLMs.&lt;/p&gt;\n&lt;p&gt;Our team focuses primarily but not exclusively on speech, building advanced steerable systems spanning end-to-end conversational systems, speech and audio understanding models, and speech synthesis capabilities. The team works closely with many collaborators across pretraining, finetuning, reinforcement learning, production inference, and product to get advanced audio technologies from early research to high impact real-world deployments.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have hands-on experience with training audio models, whether that&#39;s conversational speech-to-speech, speech translation, speech recognition, text-to-speech, diarization, codecs, or generative audio models&lt;/li&gt;\n&lt;li&gt;Genuinely enjoy both research and engineering work, and you&#39;d describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other&lt;/li&gt;\n&lt;li&gt;Are comfortable working across abstraction levels, from signal processing fundamentals to large-scale model training and inference optimization&lt;/li&gt;\n&lt;li&gt;Have deep expertise with JAX, PyTorch, or large-scale distributed training, and can debug performance issues across the full stack&lt;/li&gt;\n&lt;li&gt;Thrive in fast-moving environments where the most important problem might shift as we learn more about what works&lt;/li&gt;\n&lt;li&gt;Communicate clearly and collaborate effectively; audio touches many parts of our systems, so you&#39;ll work closely with teams across the company&lt;/li&gt;\n&lt;li&gt;Are passionate about building conversational AI that feels natural, steerable, and safe&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of voice AI and want to help shape how these systems are developed responsibly&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Strong candidates may also have experience with:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Large language model pretraining and finetuning&lt;/li&gt;\n&lt;li&gt;Training diffusion models for image and audio generation&lt;/li&gt;\n&lt;li&gt;Reinforcement learning for large language models and diffusion models&lt;/li&gt;\n&lt;li&gt;End-to-end system optimization, from performance benchmarking to kernel optimization&lt;/li&gt;\n&lt;li&gt;GPUs, Kubernetes, PyTorch, or distributed training infrastructure&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Representative projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Training state-of-the art neural audio codecs for 48 kHz stereo audio&lt;/li&gt;\n&lt;li&gt;Developing novel algorithms for diffusion pretraining and reinforcement learning&lt;/li&gt;\n&lt;li&gt;Scaling audio datasets to millions of hours of high quality audio&lt;/li&gt;\n&lt;li&gt;Creating robust evaluation methodologies for hard-to-measure qualities such as naturalness or expressiveness&lt;/li&gt;\n&lt;li&gt;Studying training dynamics of mixed audio-text language models&lt;/li&gt;\n&lt;li&gt;Optimizing latency and inference throughput for deployed streaming audio systems&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5074815008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer / Research Scientist, Biology & Life Sciences",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4924308008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role We're seeking an exceptional Research Engineer / Research Scientist to join our Life Science team at Anthropic. Our team is organized around the north star goal of accelerating progress in the life sciences, from early discovery through translation, by an order of magnitude. Our team likes to think across the whole model stack. In this role, you'll combine your deep expertise in biology with machine learning engineering to develop novel evaluation frameworks and training strategies that push the frontier of what AI can achieve in biology. As a founding member of our team, you'll work at the intersection of cutting-edge AI and the biological sciences, developing rigorous methods to measure and improve model performance on complex scientific tasks. You'll collaborate closely with world-class researchers and engineers to build AI systems that can engage in all phases of research and development, while maintaining our commitment to safety and beneficial impact. Responsibilities: Design and implement evaluation methodologies for assessing AI model capabilities relevant to biological research and applications Develop and execute strategies to systematically improve model performance on scientific tasks Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery Collaborate with domain experts and partners to establish benchmarks and gather high-quality data Translate between biological domain knowledge and machine learning objectives You may be a good fit if you: Have 8+ years of machine learning experience, with demonstrated ability to train and evaluate large language models Have 5+ years of hands-on experience in life sciences R&D, with deep expertise in areas such as molecular biology, drug discovery, or computational biology Have a track record of bridging biological domain knowledge with computational approaches to solve real scientific problems Are proficient in Python and familiar with modern ML development practices Are comfortable navigating ambiguity and developing solutions in rapidly evolving research environments Can work independently while maintaining strong collaboration with cross-functional teams Are results-oriented, with a bias towards flexibility and impact Thrive in a fast-paced research environment where you balance rigorous scientific standards with rapid iteration Are passionate about using AI to accelerate scientific discovery while maintaining high ethical standards Have experience managing data pipelines and working with large-scale biological datasets Strong candidates may have: Ph.D. in a biological science (molecular biology, biochemistry, computational biology), in Machine Learning, or in a related field, or equivalent industry experience Published research or practical experience in scientific AI applications or long-horizon reasoning A history working on Reinforcement Learning and/or Pretraining Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing) Experience with modern machine learning techniques and model training methodologies Familiarity with biological databases (UniProt, GenBank, PDB) and computational biology tools Experience in drug discovery, including computational chemistry or structure-based design Knowledge of regulatory requirements for therapeutic development or clinical research Contributions to open-source scientific software or databases This role offers a unique opportunity to shape how AI transforms biological research. You'll work with some of the world's best AI researchers while tackling problems that matter deeply for human health and scientific understanding. If you're excited about using your expertise to guide the development of transformative AI systems, we want to hear from you. Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$280,000 - $350,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4924308008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4924308008",
    "title": "Research Engineer / Research Scientist, Biology & Life Sciences",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4924308008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We&#39;re seeking an exceptional Research Engineer / Research Scientist to join our Life Science team at Anthropic. Our team is organized around the north star goal of accelerating progress in the life sciences, from early discovery through translation, by an order of magnitude. Our team likes to think across the whole model stack. In this role, you&#39;ll combine your deep expertise in biology with machine learning engineering to develop novel evaluation frameworks and training strategies that push the frontier of what AI can achieve in biology.&lt;/p&gt;\n&lt;p&gt;As a founding member of our team, you&#39;ll work at the intersection of cutting-edge AI and the biological sciences, developing rigorous methods to measure and improve model performance on complex scientific tasks. You&#39;ll collaborate closely with world-class researchers and engineers to build AI systems that can engage in all phases of research and development, while maintaining our commitment to safety and beneficial impact.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement evaluation methodologies for assessing AI model capabilities relevant to biological research and applications&lt;/li&gt;\n&lt;li&gt;Develop and execute strategies to systematically improve model performance on scientific tasks&lt;/li&gt;\n&lt;li&gt;Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery&lt;/li&gt;\n&lt;li&gt;Collaborate with domain experts and partners to establish benchmarks and gather high-quality data&lt;/li&gt;\n&lt;li&gt;Translate between biological domain knowledge and machine learning objectives&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 8+ years of machine learning experience, with demonstrated ability to train and evaluate large language models&lt;/li&gt;\n&lt;li&gt;Have 5+ years of hands-on experience in life sciences R&amp;amp;D, with deep expertise in areas such as molecular biology, drug discovery, or computational biology&lt;/li&gt;\n&lt;li&gt;Have a track record of bridging biological domain knowledge with computational approaches to solve real scientific problems&lt;/li&gt;\n&lt;li&gt;Are proficient in Python and familiar with modern ML development practices&lt;/li&gt;\n&lt;li&gt;Are comfortable navigating ambiguity and developing solutions in rapidly evolving research environments&lt;/li&gt;\n&lt;li&gt;Can work independently while maintaining strong collaboration with cross-functional teams&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Thrive in a fast-paced research environment where you balance rigorous scientific standards with rapid iteration&lt;/li&gt;\n&lt;li&gt;Are passionate about using AI to accelerate scientific discovery while maintaining high ethical standards&lt;/li&gt;\n&lt;li&gt;Have experience managing data pipelines and working with large-scale biological datasets&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ph.D. in a biological science (molecular biology, biochemistry, computational biology), in Machine Learning, or in a related field, or equivalent industry experience&lt;/li&gt;\n&lt;li&gt;Published research or practical experience in scientific AI applications or long-horizon reasoning&lt;/li&gt;\n&lt;li&gt;A history working on Reinforcement Learning and/or Pretraining&lt;/li&gt;\n&lt;li&gt;Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing)&lt;/li&gt;\n&lt;li&gt;Experience with modern machine learning techniques and model training methodologies&lt;/li&gt;\n&lt;li&gt;Familiarity with biological databases (UniProt, GenBank, PDB) and computational biology tools&lt;/li&gt;\n&lt;li&gt;Experience in drug discovery, including computational chemistry or structure-based design&lt;/li&gt;\n&lt;li&gt;Knowledge of regulatory requirements for therapeutic development or clinical research&lt;/li&gt;\n&lt;li&gt;Contributions to open-source scientific software or databases&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;This role offers a unique opportunity to shape how AI transforms biological research. You&#39;ll work with some of the world&#39;s best AI researchers while tackling problems that matter deeply for human health and scientific understanding. If you&#39;re excited about using your expertise to guide the development of transformative AI systems, we want to hear from you.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$280,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$350,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4924308008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer / Research Scientist, Vision",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA; Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5074217008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role We’re looking for research engineers with a strong computer vision background who believe that visual and spatial reasoning are core to fully unlocking the capabilities of LLMs. In this role, you'll work on research, development, and evaluation for state-of-the-art Claude models, with a focus on visual and spatial capabilities. This role is highly collaborative and will touch many aspects of our broader research efforts, taking a full-stack approach across pretraining, RL, and runtime techniques like agentic harnesses. Additionally, you’ll partner with the product org to ensure that the vision improvements you deliver impact Claude’s performance on real-world tasks. What you'll do: Run experiments to evaluate architectural variants, data strategies, and SL and RL techniques to improve Claude’s vision Develop and test tools, skills, and agentic infrastructure that enable Claude to reason over visual inputs Create evaluations and benchmarks that measure progress on multimodal capabilities across training and deployment Work with our product org to find solutions to our most vexing API customer challenges related to vision and spatial reasoning You may be a good fit if you: Have 7+ years of ML, computer vision, and software engineering experience through industry, academia, or other projects Are familiar with the architecture, training, and operation of large vision language models Have experience creating and evaluating large synthetic and real-world visual training datasets Have experience engaging in systematic prompting, finetuning, or evaluation Are results-oriented, with a bias towards flexibility and impact Enjoy pair programming and cross-team collaboration Care about the societal impacts of your work Strong candidates may also have experience with: Large-scale pretraining, SL, and RL on language models Deep learning research on images, video, or other modalities Developing complex agentic systems using LLMs High-performance ML systems (GPUs, TPUs, JAX, PyTorch) Large-scale ETL and data pipeline development Representative projects: Running experiments to determine ideal training datamixes and parameters for a synthetically generated vision dataset Finetuning Claude to maximize its performance using a particular set of agent tools/skills Building a pipeline to ingest and process a novel source of visual training data Designing and running experiments to evaluate the scalability of two architectural variants The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5074217008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5074217008",
    "title": "Research Engineer / Research Scientist, Vision",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA; Seattle, WA",
    "locations": [
      "New York City, NY; San Francisco, CA; Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5074217008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We’re looking for research engineers with a strong computer vision background who believe that visual and spatial reasoning are core to fully unlocking the capabilities of LLMs. In this role, you&#39;ll work on research, development, and evaluation for state-of-the-art Claude models, with a focus on visual and spatial capabilities. This role is highly collaborative and will touch many aspects of our broader research efforts, taking a full-stack approach across pretraining, RL, and runtime techniques like agentic harnesses. Additionally, you’ll partner with the product org to ensure that the vision improvements you deliver impact Claude’s performance on real-world tasks.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;What you&#39;ll do:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Run experiments to evaluate architectural variants, data strategies, and SL and RL techniques to improve Claude’s vision&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Develop and test tools, skills, and agentic infrastructure that enable Claude to reason over visual inputs&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Create evaluations and benchmarks that measure progress on multimodal capabilities across training and deployment&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Work with our product org to find solutions to our most vexing API customer challenges related to vision and spatial reasoning&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Have 7+ years of ML, computer vision, and software engineering experience through industry, academia, or other projects&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Are familiar with the architecture, training, and operation of large vision language models&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Have experience creating and evaluating large synthetic and real-world visual training datasets&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Have experience engaging in systematic prompting, finetuning, or evaluation&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Enjoy pair programming and cross-team collaboration&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Care about the societal impacts of your work&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have experience with:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Large-scale pretraining, SL, and RL on language models&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Deep learning research on images, video, or other modalities&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Developing complex agentic systems using LLMs&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;High-performance ML systems (GPUs, TPUs, JAX, PyTorch)&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Large-scale ETL and data pipeline development&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Running experiments to determine ideal training datamixes and parameters for a synthetically generated vision dataset&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Finetuning Claude to maximize its performance using a particular set of agent tools/skills&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Building a pipeline to ingest and process a novel source of visual training data&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Designing and running experiments to evaluate the scalability of two architectural variants&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5074217008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Reward Models Platform",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5024831008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role You will deeply understand the research workflows of our Finetuning teams and automate the high-friction parts – turning days of manual experimentation into hours. You’ll build the tools and infrastructure that enable researchers across the organization to develop, evaluate, and optimize reward signals for training our models. Your scalable platforms will make it easy to experiment with different reward methodologies, assess their robustness, and iterate rapidly on improvements to help the rest of Anthropic train our reward models. This is a role for someone who wants to stay close to the science while having outsized leverage. You'll partner directly with researchers on the Rewards team and across the broader Fine-Tuning organization to understand what slows them down: running human data experiments before adding to preference models, debugging reward hacks, comparing rubric methodologies across domains. Then you'll build the systems that make those workflows 10x faster. When you have bandwidth, you'll contribute directly to research projects yourself. Your work will directly impact our ability to scale reward development across domains, from crafting and evaluating rubrics to understanding the effects of human feedback data to detecting and mitigating reward hacks. We're looking for someone who combines strong engineering fundamentals with research experience – someone who can scope ambiguous problems, ship quickly, and cares as much about the science as the systems. Note: For this role, we conduct all interviews in Python. Responsibilities Design and build infrastructure that enables researchers to rapidly iterate on reward signals, including tools for rubric development, human feedback data analysis, and reward robustness evaluation Develop systems for automated quality assessment of rewards, including detection of reward hacks and other pathologies Create tooling that allows researchers to easily compare different reward methodologies (preference models, rubrics, programmatic rewards) and understand their effects Build pipelines and workflows that reduce toil in reward development, from dataset preparation to evaluation to deployment Implement monitoring and observability systems to track reward signal quality and surface issues during training runs Collaborate with researchers to translate science requirements into platform capabilities Optimize existing systems for performance, reliability, and ease of use Contribute to the development of best practices and documentation for reward development workflows You may be a good fit if you Have prior research experience Are excited to work closely with researchers and translate ambiguous requirements into well-scoped engineering projects Have strong Python skills Have experience with ML workflows and data pipelines, and building related infrastructure/tooling/platforms Are comfortable working across the stack, ranging from data pipelines to experiment tracking to user-facing tooling Can balance building robust, maintainable systems with the need to move quickly in a research environment Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Care about the societal impacts of your work and are motivated by Anthropic's mission to develop safe AI Strong candidates may also have experience with Experience with ML research Building internal tooling and platforms for ML researchers Data quality assessment and pipeline optimization Experiment tracking, evaluation frameworks, or MLOps tooling Large-scale data processing (e.g., Spark, Hive, or similar) Kubernetes, distributed systems, or cloud infrastructure Familiarity with reinforcement learning or fine-tuning workflows Representative projects Building infrastructure that allows researchers to rapidly test new rubric designs against small models before scaling up Developing automated systems to detect reward hacks and surface problematic behaviors during training Creating tooling for comparing different grading methodologies and understanding their effects on model behavior Building a data quality flywheel that helps researchers identify problematic transcripts and feed improvements back into the system Developing dashboards and monitoring systems that give researchers visibility into reward signal quality across training runs Streamlining dataset preparation workflows to reduce latency and operational overhead The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5024831008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5024831008",
    "title": "Research Engineer, Reward Models Platform",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5024831008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;You will deeply understand the research workflows of our Finetuning teams and automate the high-friction parts – turning days of manual experimentation into hours. You’ll build the tools and infrastructure that enable researchers across the organization to develop, evaluate, and optimize reward signals for training our models. Your scalable platforms will make it easy to experiment with different reward methodologies, assess their robustness, and iterate rapidly on improvements to help the rest of Anthropic train our reward models.&lt;/p&gt;\n&lt;p&gt;This is a role for someone who wants to stay close to the science while having outsized leverage. You&#39;ll partner directly with researchers on the Rewards team and across the broader Fine-Tuning organization to understand what slows them down: running human data experiments before adding to preference models, debugging reward hacks, comparing rubric methodologies across domains. Then you&#39;ll build the systems that make those workflows 10x faster. When you have bandwidth, you&#39;ll contribute directly to research projects yourself. Your work will directly impact our ability to scale reward development across domains, from crafting and evaluating rubrics to understanding the effects of human feedback data to detecting and mitigating reward hacks.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;We&#39;re looking for someone who combines strong engineering fundamentals with research experience – someone who can scope ambiguous problems, ship quickly, and cares as much about the science as the systems.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and build infrastructure that enables researchers to rapidly iterate on reward signals, including tools for rubric development, human feedback data analysis, and reward robustness evaluation&lt;/li&gt;\n&lt;li&gt;Develop systems for automated quality assessment of rewards, including detection of reward hacks and other pathologies&lt;/li&gt;\n&lt;li&gt;Create tooling that allows researchers to easily compare different reward methodologies (preference models, rubrics, programmatic rewards) and understand their effects&lt;/li&gt;\n&lt;li&gt;Build pipelines and workflows that reduce toil in reward development, from dataset preparation to evaluation to deployment&lt;/li&gt;\n&lt;li&gt;Implement monitoring and observability systems to track reward signal quality and surface issues during training runs&lt;/li&gt;\n&lt;li&gt;Collaborate with researchers to translate science requirements into platform capabilities&lt;/li&gt;\n&lt;li&gt;Optimize existing systems for performance, reliability, and ease of use&lt;/li&gt;\n&lt;li&gt;Contribute to the development of best practices and documentation for reward development workflows&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have prior research experience&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Are excited to work closely with researchers and translate ambiguous requirements into well-scoped engineering projects&lt;/li&gt;\n&lt;li&gt;Have strong Python skills&lt;/li&gt;\n&lt;li&gt;Have experience with ML workflows and data pipelines, and building related infrastructure/tooling/platforms&lt;/li&gt;\n&lt;li&gt;Are comfortable working across the stack, ranging from data pipelines to experiment tracking to user-facing tooling&lt;/li&gt;\n&lt;li&gt;Can balance building robust, maintainable systems with the need to move quickly in a research environment&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work and are motivated by Anthropic&#39;s mission to develop safe AI&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have experience with&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with ML research&lt;/li&gt;\n&lt;li&gt;Building internal tooling and platforms for ML researchers&lt;/li&gt;\n&lt;li&gt;Data quality assessment and pipeline optimization&lt;/li&gt;\n&lt;li&gt;Experiment tracking, evaluation frameworks, or MLOps tooling&lt;/li&gt;\n&lt;li&gt;Large-scale data processing (e.g., Spark, Hive, or similar)&lt;/li&gt;\n&lt;li&gt;Kubernetes, distributed systems, or cloud infrastructure&lt;/li&gt;\n&lt;li&gt;Familiarity with reinforcement learning or fine-tuning workflows&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative projects&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Building infrastructure that allows researchers to rapidly test new rubric designs against small models before scaling up&lt;/li&gt;\n&lt;li&gt;Developing automated systems to detect reward hacks and surface problematic behaviors during training&lt;/li&gt;\n&lt;li&gt;Creating tooling for comparing different grading methodologies and understanding their effects on model behavior&lt;/li&gt;\n&lt;li&gt;Building a data quality flywheel that helps researchers identify problematic transcripts and feed improvements back into the system&lt;/li&gt;\n&lt;li&gt;Developing dashboards and monitoring systems that give researchers visibility into reward signal quality across training runs&lt;/li&gt;\n&lt;li&gt;Streamlining dataset preparation workflows to reduce latency and operational overhead&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5024831008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Reward Models Training",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4613599008",
    "job_posted_at_datetime_utc": "2026-01-26T15:24:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the Role Reward models are a critical component of how we align our AI systems with human values and preferences, serving as the bridge between human feedback and model behavior. In this role, you'll build the infrastructure that enables us to train reward models efficiently and reliably, scale to increasingly large model sizes, and incorporate diverse forms of human feedback across multiple domains and modalities. You will own the end-to-end engineering of reward model training at Anthropic. You'll work at the intersection of machine learning systems and alignment research, partnering closely with researchers to translate novel techniques into production-grade training pipelines. This is a high-impact role where your work directly contributes to making Claude more helpful, harmless, and honest. Note: For this role, we conduct all interviews in Python. Responsibilities: Own the end-to-end engineering of reward model training, from data ingestion through model evaluation and deployment Design and implement efficient, reliable training pipelines that can scale to increasingly large model sizes Build robust data pipelines for collecting, processing, and incorporating human feedback into reward model training Optimize training infrastructure for throughput, efficiency, and fault tolerance across distributed systems Extend reward model capabilities to support new domains and additional data modalities Collaborate with researchers to implement and iterate on novel reward modeling techniques Develop tooling and monitoring systems to ensure training quality and identify issues early Contribute to the design and improvement of our overall model training infrastructure You may be a good fit if you: Have significant experience building and maintaining large-scale ML systems Are proficient in Python and have experience with ML frameworks such as PyTorch Have experience with distributed training systems and optimizing ML workloads for efficiency Are comfortable working with large datasets and building data pipelines at scale Can balance research exploration with engineering rigor and operational reliability Enjoy collaborating closely with researchers and translating research ideas into reliable engineering systems Are results-oriented with a bias towards flexibility and impact Can navigate ambiguity and make progress in fast-moving research environments Adapt quickly to changing priorities, while juggling multiple urgent issues Maintain clarity when debugging complex, time-sensitive issues Pick up slack, even if it goes outside your job description Care about the societal impacts of your work and are motivated by Anthropic's mission Strong candidates may also have experience with Training or fine-tuning large language models Reinforcement learning from human feedback (RLHF) or related techniques GPUs, Kubernetes, and cloud infrastructure (AWS, GCP) Building systems for human-in-the-loop machine learning Working with multimodal data (text, images, audio, etc.) Large-scale ETL and data processing frameworks (Spark, Airflow) Representative projects Scaling reward model training to handle models with significantly more parameters while maintaining training stability Building a unified data pipeline that ingests human feedback from multiple sources and formats for reward model training Implementing fault-tolerant training infrastructure that gracefully handles hardware failures during long training runs Developing evaluation frameworks to measure reward model quality across diverse domains Optimizing training throughput to reduce iteration time on reward modeling experiments The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4613599008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4613599008",
    "title": "Research Engineer, Reward Models Training",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4613599008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-26T15:24:22-05:00",
    "fetched_at": "2026-01-29T18:15:07.390Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About the Role&lt;/h2&gt;\n&lt;p&gt;Reward models are a critical component of how we align our AI systems with human values and preferences, serving as the bridge between human feedback and model behavior. In this role, you&#39;ll build the infrastructure that enables us to train reward models efficiently and reliably, scale to increasingly large model sizes, and incorporate diverse forms of human feedback across multiple domains and modalities. You will own the end-to-end engineering of reward model training at Anthropic.&lt;/p&gt;\n&lt;p&gt;You&#39;ll work at the intersection of machine learning systems and alignment research, partnering closely with researchers to translate novel techniques into production-grade training pipelines. This is a high-impact role where your work directly contributes to making Claude more helpful, harmless, and honest.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;ul&gt;\n&lt;li&gt;Own the end-to-end engineering of reward model training, from data ingestion through model evaluation and deployment&lt;/li&gt;\n&lt;li&gt;Design and implement efficient, reliable training pipelines that can scale to increasingly large model sizes&lt;/li&gt;\n&lt;li&gt;Build robust data pipelines for collecting, processing, and incorporating human feedback into reward model training&lt;/li&gt;\n&lt;li&gt;Optimize training infrastructure for throughput, efficiency, and fault tolerance across distributed systems&lt;/li&gt;\n&lt;li&gt;Extend reward model capabilities to support new domains and additional data modalities&lt;/li&gt;\n&lt;li&gt;Collaborate with researchers to implement and iterate on novel reward modeling techniques&lt;/li&gt;\n&lt;li&gt;Develop tooling and monitoring systems to ensure training quality and identify issues early&lt;/li&gt;\n&lt;li&gt;Contribute to the design and improvement of our overall model training infrastructure&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant experience building and maintaining large-scale ML systems&lt;/li&gt;\n&lt;li&gt;Are proficient in Python and have experience with ML frameworks such as PyTorch&lt;/li&gt;\n&lt;li&gt;Have experience with distributed training systems and optimizing ML workloads for efficiency&lt;/li&gt;\n&lt;li&gt;Are comfortable working with large datasets and building data pipelines at scale&lt;/li&gt;\n&lt;li&gt;Can balance research exploration with engineering rigor and operational reliability&lt;/li&gt;\n&lt;li&gt;Enjoy collaborating closely with researchers and translating research ideas into reliable engineering systems&lt;/li&gt;\n&lt;li&gt;Are results-oriented with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Can navigate ambiguity and make progress in fast-moving research environments&lt;/li&gt;\n&lt;li&gt;Adapt quickly to changing priorities, while juggling multiple urgent issues&lt;/li&gt;\n&lt;li&gt;Maintain clarity when debugging complex, time-sensitive issues&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work and are motivated by Anthropic&#39;s mission&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have experience with&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Training or fine-tuning large language models&lt;/li&gt;\n&lt;li&gt;Reinforcement learning from human feedback (RLHF) or related techniques&lt;/li&gt;\n&lt;li&gt;GPUs, Kubernetes, and cloud infrastructure (AWS, GCP)&lt;/li&gt;\n&lt;li&gt;Building systems for human-in-the-loop machine learning&lt;/li&gt;\n&lt;li&gt;Working with multimodal data (text, images, audio, etc.)&lt;/li&gt;\n&lt;li&gt;Large-scale ETL and data processing frameworks (Spark, Airflow)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Representative projects&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Scaling reward model training to handle models with significantly more parameters while maintaining training stability&lt;/li&gt;\n&lt;li&gt;Building a unified data pipeline that ingests human feedback from multiple sources and formats for reward model training&lt;/li&gt;\n&lt;li&gt;Implementing fault-tolerant training infrastructure that gracefully handles hardware failures during long training runs&lt;/li&gt;\n&lt;li&gt;Developing evaluation frameworks to measure reward model quality across diverse domains&lt;/li&gt;\n&lt;li&gt;Optimizing training throughput to reduce iteration time on reward modeling experiments&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4613599008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]