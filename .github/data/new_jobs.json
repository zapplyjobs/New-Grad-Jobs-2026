[
  {
    "job_title": "Partner Marketing Manager (Public Sector)",
    "employer_name": "datadog",
    "job_city": "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote",
    "job_apply_link": "https://careers.datadoghq.com/detail/7476873/?gh_jid=7476873",
    "job_posted_at_datetime_utc": "2026-01-12T12:36:11-05:00",
    "job_description": "Datadog’s Public Sector Marketing team is seeking an experienced Partner Marketing Manager to build and scale co-marketing programs with our strategic public sector partners, including AWS, Carahsoft, systems integrators (SIs), and resellers to drive pipeline and brand impact. This individual will develop, execute, and optimize co-marketing campaigns and enablement programs that position Datadog as the observability and security platform of choice for U.S. Federal, State, Local, and Education (SLED) markets.This role requires knowledge of the public sector ecosystem, government procurement processes, and the unique compliance and security requirements (e.g., FedRAMP, GovRAMP). You will work cross-functionally with sales, product marketing, field marketing, alliances, and demand generation teams to ensure partner marketing efforts are aligned to Datadog’s growth goals in the public sector.At Datadog, we place value in our office culture - the relationships and collaboration it builds, and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.What You’ll DoLead partner go-to-market strategy by developing and executing joint marketing plans with key public sector partners (AWS, Carahsoft, systems integrators, resellers).Manage MDF through planning, approving, tracking, and optimizing partner marketing development fund investments for campaigns, events, and targeted digital programs.Own the end-to-end execution of partner-led and co-branded marketing activities, from planning to performance analysis.Create and maintain enablement resources including partner playbooks, battlecards, solution briefs, and co-branded partner collateral to position Datadog effectively with public sector audiences.Drive partner seller readiness through training sessions, workshops, and enablement programs that empower partners to articulate Datadog’s value in mission-critical environments.Develop customer success storytelling with partners by producing case studies and proof points that highlight government and education wins.Collaborate cross-functionally with Public Sector Sales, Field Marketing, Product Marketing, and Demand Generation teams to align campaigns, messaging, and market approach. Build relationships with partner marketing teams to maximize collaboration and program impact.Track and report performance using Salesforce, partner portals, and analytics to measure sourced / influenced pipeline, enablement adoption, and MDF ROI.Who You Are6+ years of experience in partner marketing, alliances marketing, or channel marketing, ideally with a SaaS or cloud technology company serving the public sector.Strong understanding of public sector sales cycles, procurement vehicles, and compliance requirements (FedRAMP, SEWP, GSA).Proven track record building co-marketing campaigns with hyperscalers (AWS, Azure, GCP) and/or leading distributors / SIs in the public sector.Skilled at navigating complex partner organizations and building trusted relationships across marketing, sales, and alliance teams.Excellent written and verbal communicator, adept at translating technical concepts into mission-relevant messaging for government audiences.You work fluidly across multiple internal teams and external partners.Strong communication skills with both technical and executive-level audiences.You understand the mechanics of SaaS / cloud partner ecosystems, especially managing MDF and enabling co‑marketing efforts.Self-starter who thrives in a fast-paced, collaborative environment. Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply. Why Join Datadog Public Sector MarketingYou’ll join a fast-moving, data-driven team executing high-impact campaigns that help government agencies secure critical systems, modernize faster, and operate more efficiently. This role offers the opportunity to shape Datadog’s public sector partner marketing engine at a time of rapid growth, with significant impact on pipeline and market positioning. Benefits and Growth: Generous and competitive benefits packageNew hire stock equity (RSUs) and employee stock purchase planContinuous career development and pathing opportunities Product training to develop an in-depth understanding of our product and spaceBest in breed onboardingInternal mentor and buddy program cross-departmentallyFriendly and inclusive workplace cultureBenefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate's skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.The reasonably estimated yearly salary for this role at Datadog is:$96,000—$128,000 USDAbout Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog Learning Center.Equal Opportunity at Datadog:Datadog is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our Candidate Legal Notices for your reference. Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete this form. This form is for accommodation requests only and cannot be used to inquire about the status of applications. Privacy and AI Guidelines:Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice. For information on our AI policy, please visit Interviewing at Datadog AI Guidelines.Requisition ID: R17071",
    "id": "careers-datadoghq-com-detail-7476873",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7476873",
    "title": "Partner Marketing Manager (Public Sector)",
    "company_name": "datadog",
    "company_slug": "datadog",
    "location": "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote",
    "locations": [
      "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote"
    ],
    "url": "https://careers.datadoghq.com/detail/7476873/?gh_jid=7476873",
    "departments": [
      "Field Marketing"
    ],
    "employment_type": null,
    "posted_at": "2026-01-12T12:36:11-05:00",
    "fetched_at": "2026-01-19T18:49:28.845Z",
    "description": "&lt;p&gt;Datadog’s Public Sector Marketing team is seeking an experienced Partner Marketing Manager to build and scale co-marketing programs with our strategic public sector partners, including AWS, Carahsoft, systems integrators (SIs), and resellers to drive pipeline and brand impact. This individual will develop, execute, and optimize co-marketing campaigns and enablement programs that position Datadog as the observability and security platform of choice for U.S. Federal, State, Local, and Education (SLED) markets.&lt;/p&gt;\n&lt;p&gt;This role requires knowledge of the public sector ecosystem, government procurement processes, and the unique compliance and security requirements (e.g., FedRAMP, GovRAMP). You will work cross-functionally with sales, product marketing, field marketing, alliances, and demand generation teams to ensure partner marketing efforts are aligned to Datadog’s growth goals in the public sector.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;At Datadog, we place value in our office culture - the relationships and collaboration it builds, and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.&lt;/em&gt;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;What You’ll Do&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead partner go-to-market strategy by developing and executing joint marketing plans with key public sector partners (AWS, Carahsoft, systems integrators, resellers).&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Manage MDF through planning, approving, tracking, and optimizing partner marketing development fund investments for campaigns, events, and targeted digital programs.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Own the end-to-end execution of partner-led and co-branded marketing activities, from planning to performance analysis.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Create and maintain enablement resources including partner playbooks, battlecards, solution briefs, and co-branded partner collateral to position Datadog effectively with public sector audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Drive partner seller readiness through training sessions, workshops, and enablement programs that empower partners to articulate Datadog’s value in mission-critical environments.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Develop customer success storytelling with partners by producing case studies and proof points that highlight government and education wins.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Collaborate cross-functionally with Public Sector Sales, Field Marketing, Product Marketing, and Demand Generation teams to align campaigns, messaging, and market approach. Build relationships with partner marketing teams to maximize collaboration and program impact.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Track and report performance using Salesforce, partner portals, and analytics to measure sourced / influenced pipeline, enablement adoption, and MDF ROI.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Who You Are&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;6+ years of experience in partner marketing, alliances marketing, or channel marketing, ideally with a SaaS or cloud technology company serving the public sector.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Strong understanding of public sector sales cycles, procurement vehicles, and compliance requirements (FedRAMP, SEWP, GSA).&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Proven track record building co-marketing campaigns with hyperscalers (AWS, Azure, GCP) and/or leading distributors / SIs in the public sector.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Skilled at navigating complex partner organizations and building trusted relationships across marketing, sales, and alliance teams.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Excellent written and verbal communicator, adept at translating technical concepts into mission-relevant messaging for government audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;You work fluidly across multiple internal teams and external partners.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Strong communication skills with both technical and executive-level audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;You understand the mechanics of SaaS / cloud partner ecosystems, especially managing MDF and enabling co‑marketing efforts.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Self-starter who thrives in a fast-paced, collaborative environment.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That&#39;s okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply.&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;Why Join Datadog Public Sector Marketing&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;You’ll join a fast-moving, data-driven team executing high-impact campaigns that help government agencies secure critical systems, modernize faster, and operate more efficiently. This role offers the opportunity to shape Datadog’s public sector partner marketing engine at a time of rapid growth, with significant impact on pipeline and market positioning.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Benefits and Growth:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Generous and competitive benefits package&lt;/li&gt;\n&lt;li&gt;New hire stock equity (RSUs) and employee stock purchase plan&lt;/li&gt;\n&lt;li&gt;Continuous career development and pathing opportunities&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Product training to develop an in-depth understanding of our product and space&lt;/li&gt;\n&lt;li&gt;Best in breed onboarding&lt;/li&gt;\n&lt;li&gt;Internal mentor and buddy program cross-departmentally&lt;/li&gt;\n&lt;li&gt;Friendly and inclusive workplace culture&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate&#39;s skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;The reasonably estimated yearly salary for this role at Datadog is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$96,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$128,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;hr&gt;\n&lt;p&gt;&lt;strong&gt;About Datadog:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on &lt;a href=&quot;https://www.instagram.com/datadoghq/?hl=en&quot; target=&quot;_blank&quot;&gt;Instagram&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/company/datadog&quot; target=&quot;_blank&quot;&gt;LinkedIn,&lt;/a&gt; and &lt;a href=&quot;https://learn.datadoghq.com/&quot; target=&quot;_blank&quot;&gt;Datadog Learning Center. &lt;/a&gt;&lt;/p&gt;\n&lt;hr&gt;\n&lt;p data-renderer-start-pos=&quot;215&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Equal Opportunity at Datadog:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog is proud to offer &lt;a href=&quot;https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf&quot; target=&quot;_blank&quot;&gt;equal employment opportunity&lt;/a&gt; to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our &lt;a href=&quot;https://www.datadoghq.com/legal/candidate-legal-notices/&quot; target=&quot;_blank&quot;&gt;Candidate Legal Notices&lt;/a&gt; for your reference.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSeoJeduEZ2NdZF_65uZmWUrCM-zee7yADXX1s6Xr9zAGq8iKA/viewform&quot; target=&quot;_blank&quot;&gt;this form&lt;/a&gt;. This form is for accommodation requests only and cannot be used to inquire about the status of applications.&amp;nbsp;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Privacy and AI Guidelines:&lt;/strong&gt;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; data-sk=&quot;tooltip_parent&quot;&gt;Applicant and Candidate Privacy Notice&lt;/a&gt;. For information on our AI policy, please visit &lt;a href=&quot;https://www.datadoghq.com/legal/interviewing-at-datadog-ai-guidelines/&quot; target=&quot;_blank&quot;&gt;Interviewing at Datadog AI Guidelines&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7476873
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Engineering Manager I - Cyber Threat Intelligence",
    "employer_name": "datadog",
    "job_city": "Boston, Massachusetts, USA; Denver, Colorado, USA; New York, New York, USA",
    "job_apply_link": "https://careers.datadoghq.com/detail/7181025/?gh_jid=7181025",
    "job_posted_at_datetime_utc": "2026-01-12T10:48:35-05:00",
    "job_description": "The Cyber Threat Intelligence team’s mission is to stay ahead of threat actors and their TTPs to help Datadog make intelligence-led-decisions to improve our security posture, inform detections in our security products, and publish research that elevates the Datadog security brand. As part of the Detection & Threat Intelligence group, you will get to work at the intersection of Datadog’s global information security and security product organizations.We are looking for an Engineering Manager to lead the Cyber Threat Intelligence team. This team focuses on tracking threat actors, malware, and vulnerabilities relevant to Datadog and our customers while also contributing to the Datadog Security Labs brand by publishing threat research blogs and speaking at conferences. This manager will report to the Engineering Manager II of the Detection & Intelligence Group and will partner closely with several teams to support their intelligence requirements, including Detection Engineering, Threat Hunting, Incident Response, Trust & Safety, Red team, Product Management, Product Detection Engineering, and Security Products Engineering.At Datadog, we place value in our office culture - the relationships and collaboration it builds and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.What You’ll Do:Develop and lead a team of security researchers who are responsible for ideating, planning and executing the cyber threat intelligence roadmap at Datadog which includes: threat hunting, threat intelligence, thought leadership and actor/malware tracking.Build a unified threat research and intelligence effort to track threat actors targeting Datadog & their customers.Work with leadership to set quarterly OKRs that address priority intelligence and research requirements.Build and support a RFI program for intelligence stakeholders.Build, and optimize the collection, processing and dissemination of strategic, tactical, and operational threat intelligence for intelligence stakeholders.Track, research and experiment with the latest tactics, techniques & procedures for attacking and defending integrated production environments with Datadog.Develop and maintain tools for automating the collection and analysis of intelligence.Create and collaborate with Engineering & Product Management on proof of concept products, services, tools and simulations to demonstrate new capabilities and protections in Datadog environments.Evangelize your team’s mission and regularly communicate with teams outside of your organizational structure.Work closely with our Community team to develop thought-leadership threat research content for blogs, webinars, and conferences.Build partnerships with external organizations dedicated to advancing cybersecurity for the world.Who You Are:A proven leader with experience leading threat research, cyber threat intelligence, security engineering or security research teams.A technical practitioner who has hands-on experience building, investigating and reporting on threat activity in highly complex environments.You have experience with collecting and anticipating intelligence requirements from your stakeholders and building out an operational model to support the production of intelligence products for them.Connected to threat intelligence sharing groups and can help navigate the complexities of intelligence sharing.You have led threat hunts to identify novel threat activity and turn that into new detections, new intelligence, and threat research publications.You are comfortable with helping build proof-of-concept services, which include writing and testing code (e.g. Go, Python, Ruby), deploying code to cloud environments and monitoring of these services.You have published blogs on threat intelligence topics, threat research, and spoken at security conferences on your findings.Motivating, kind and humble people leader who focuses on growth and happiness for your team. You have the ability to grow talent by providing a proper mentorship and performance management environment while prioritizing empathy.You value correctness and efficiency; you leave no stone unturned when reviewing documentation.Note: If you’re excited about this role and meet most of the qualifications, we encourage you to apply!Bonus Points:Experience leading a cyber threat intelligence group for a cloud native technology/security vendor.Experience setting up and managing a threat intelligence platform (TIP) to centralize intelligence collection, dissemination, and threat research activities.Experience responding to large scale emerging threats and vulnerabilities in a threat intelligence or incident response capacity.Experience working with Product Managers and Engineering teams on security products focused around threat detection and threat intelligence.Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate's skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.The reasonably estimated yearly salary for this role at Datadog is:$187,000—$240,000 USDAbout Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog Learning Center.Equal Opportunity at Datadog:Datadog is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our Candidate Legal Notices for your reference. Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete this form. This form is for accommodation requests only and cannot be used to inquire about the status of applications. Privacy and AI Guidelines:Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice. For information on our AI policy, please visit Interviewing at Datadog AI Guidelines.Requisition ID: R15312",
    "id": "careers-datadoghq-com-detail-7181025",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7181025",
    "title": "Engineering Manager I - Cyber Threat Intelligence",
    "company_name": "datadog",
    "company_slug": "datadog",
    "location": "Boston, Massachusetts, USA; Denver, Colorado, USA; New York, New York, USA",
    "locations": [
      "Boston, Massachusetts, USA; Denver, Colorado, USA; New York, New York, USA"
    ],
    "url": "https://careers.datadoghq.com/detail/7181025/?gh_jid=7181025",
    "departments": [
      "Security"
    ],
    "employment_type": null,
    "posted_at": "2026-01-12T10:48:35-05:00",
    "fetched_at": "2026-01-19T18:49:28.845Z",
    "description": "&lt;p&gt;The Cyber Threat Intelligence team’s mission is to stay ahead of threat actors and their TTPs to help Datadog make intelligence-led-decisions to improve our security posture, inform detections in our security products, and publish research that elevates the Datadog security brand. As part of the Detection &amp;amp; Threat Intelligence group, you will get to work at the intersection of Datadog’s global information security and security product organizations.&lt;/p&gt;\n&lt;p&gt;We are looking for an Engineering Manager to lead the Cyber Threat Intelligence team. This team focuses on tracking threat actors, malware, and vulnerabilities relevant to Datadog and our customers while also contributing to the &lt;a href=&quot;https://securitylabs.datadoghq.com/&quot;&gt;Datadog Security Labs&lt;/a&gt; brand by publishing threat research blogs and speaking at conferences. This manager will report to the Engineering Manager II of the Detection &amp;amp; Intelligence Group and will partner closely with several teams to support their intelligence requirements, including Detection Engineering, Threat Hunting, Incident Response, Trust &amp;amp; Safety, Red team, Product Management, Product Detection Engineering, and Security Products Engineering.&lt;/p&gt;\n&lt;p&gt;At Datadog, we place value in our office culture - the relationships and collaboration it builds and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;What You’ll Do:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and lead a team of security researchers who are responsible for ideating, planning and executing the cyber threat intelligence roadmap at Datadog which includes: threat hunting, threat intelligence, thought leadership and actor/malware tracking.&lt;/li&gt;\n&lt;li&gt;Build a unified threat research and intelligence effort to track threat actors targeting Datadog &amp;amp; their customers.&lt;/li&gt;\n&lt;li&gt;Work with leadership to set quarterly OKRs that address priority intelligence and research requirements.&lt;/li&gt;\n&lt;li&gt;Build and support a RFI program for intelligence stakeholders.&lt;/li&gt;\n&lt;li&gt;Build, and optimize the collection, processing and dissemination of strategic, tactical, and operational threat intelligence for intelligence stakeholders.&lt;/li&gt;\n&lt;li&gt;Track, research and experiment with the latest tactics, techniques &amp;amp; procedures for attacking and defending integrated production environments with Datadog.&lt;/li&gt;\n&lt;li&gt;Develop and maintain tools for automating the collection and analysis of intelligence.&lt;/li&gt;\n&lt;li&gt;Create and collaborate with Engineering &amp;amp; Product Management on proof of concept products, services, tools and simulations to demonstrate new capabilities and protections in Datadog environments.&lt;/li&gt;\n&lt;li&gt;Evangelize your team’s mission and regularly communicate with teams outside of your organizational structure.&lt;/li&gt;\n&lt;li&gt;Work closely with our Community team to develop thought-leadership threat research content for blogs, webinars, and conferences.&lt;/li&gt;\n&lt;li&gt;Build partnerships with external organizations dedicated to advancing cybersecurity for the world.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Who You Are:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;A proven leader with experience leading threat research, cyber threat intelligence, security engineering or security research teams.&lt;/li&gt;\n&lt;li&gt;A technical practitioner who has hands-on experience building, investigating and reporting on threat activity in highly complex environments.&lt;/li&gt;\n&lt;li&gt;You have experience with collecting and anticipating intelligence requirements from your stakeholders and building out an operational model to support the production of intelligence products for them.&lt;/li&gt;\n&lt;li&gt;Connected to threat intelligence sharing groups and can help navigate the complexities of intelligence sharing.&lt;/li&gt;\n&lt;li&gt;You have led threat hunts to identify novel threat activity and turn that into new detections, new intelligence, and threat research publications.&lt;/li&gt;\n&lt;li&gt;You are comfortable with helping build proof-of-concept services, which include writing and testing code (e.g. Go, Python, Ruby), deploying code to cloud environments and monitoring of these services.&lt;/li&gt;\n&lt;li&gt;You have published blogs on threat intelligence topics, threat research, and spoken at security conferences on your findings.&lt;/li&gt;\n&lt;li&gt;Motivating, kind and humble people leader who focuses on growth and happiness for your team. You have the ability to grow talent by providing a proper mentorship and performance management environment while prioritizing empathy.&lt;/li&gt;\n&lt;li&gt;You value correctness and efficiency; you leave no stone unturned when reviewing documentation.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you’re excited about this role and meet most of the qualifications, we encourage you to apply!&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Bonus Points:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience leading a cyber threat intelligence group for a cloud native technology/security vendor.&lt;/li&gt;\n&lt;li&gt;Experience setting up and managing a threat intelligence platform (TIP) to centralize intelligence collection, dissemination, and threat research activities.&lt;/li&gt;\n&lt;li&gt;Experience responding to large scale emerging threats and vulnerabilities in a threat intelligence or incident response capacity.&lt;/li&gt;\n&lt;li&gt;Experience working with Product Managers and Engineering teams on security products focused around threat detection and threat intelligence.&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate&#39;s skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;The reasonably estimated yearly salary for this role at Datadog is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$187,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$240,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;hr&gt;\n&lt;p&gt;&lt;strong&gt;About Datadog:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on &lt;a href=&quot;https://www.instagram.com/datadoghq/?hl=en&quot; target=&quot;_blank&quot;&gt;Instagram&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/company/datadog&quot; target=&quot;_blank&quot;&gt;LinkedIn,&lt;/a&gt; and &lt;a href=&quot;https://learn.datadoghq.com/&quot; target=&quot;_blank&quot;&gt;Datadog Learning Center. &lt;/a&gt;&lt;/p&gt;\n&lt;hr&gt;\n&lt;p data-renderer-start-pos=&quot;215&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Equal Opportunity at Datadog:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog is proud to offer &lt;a href=&quot;https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf&quot; target=&quot;_blank&quot;&gt;equal employment opportunity&lt;/a&gt; to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our &lt;a href=&quot;https://www.datadoghq.com/legal/candidate-legal-notices/&quot; target=&quot;_blank&quot;&gt;Candidate Legal Notices&lt;/a&gt; for your reference.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSeoJeduEZ2NdZF_65uZmWUrCM-zee7yADXX1s6Xr9zAGq8iKA/viewform&quot; target=&quot;_blank&quot;&gt;this form&lt;/a&gt;. This form is for accommodation requests only and cannot be used to inquire about the status of applications.&amp;nbsp;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Privacy and AI Guidelines:&lt;/strong&gt;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; data-sk=&quot;tooltip_parent&quot;&gt;Applicant and Candidate Privacy Notice&lt;/a&gt;. For information on our AI policy, please visit &lt;a href=&quot;https://www.datadoghq.com/legal/interviewing-at-datadog-ai-guidelines/&quot; target=&quot;_blank&quot;&gt;Interviewing at Datadog AI Guidelines&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7181025
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Channel Development Representative, West (Salt Lake City)",
    "employer_name": "verkada",
    "job_city": "Salt Lake City, UT United States",
    "job_apply_link": "https://job-boards.greenhouse.io/verkada/jobs/5008900007",
    "job_posted_at_datetime_utc": "2026-01-16T13:43:26-05:00",
    "job_description": "Who We Are Verkada is transforming how organizations protect their people and places with an integrated, AI-powered platform. A leader in cloud physical security, Verkada helps organizations strengthen safety and efficiency through one connected software platform that includes solutions for video security, access control, air quality sensors, alarms, intercoms, and visitor management.Over 30,000 organizations worldwide, including more than 100 companies in the Fortune 500, trust Verkada as their physical security layer for easier management, intelligent control, and scalable deployments. Founded in 2016, Verkada has expanded rapidly with 15 offices and 2,200+ full-time employees. What You’ll Do Verkada is looking for a high-energy Channel Development Representative to help drive the growth and success of our reseller partners across the West region. In this role, you’ll: Introduce Verkada’s solutions into new partner accounts and support partner growth and development. Work closely with partners to get them producing quickly, before handing off to the assigned Channel Sales Manager (CSM). Manage partner applications, onboarding, and actively develop newly onboarded target accounts. Step in as an inside CSM when field coverage is needed. Build experience and prepare to move into a CSM role over time, with the opportunity to manage a territory when required. This is a career-launching opportunity to grow within tech sales, gain deep channel experience, and build a path toward a full CSM role in a fast-growing, innovative company. What You Bring Bachelor’s degree 1-2 years of sales experience in a quota and metric driven environment. IT or SaaS experience preferred. Confident presenting product demos and delivering high-level partner training Highly organized, able to thrive independently Engaging personality with polished verbal and written communication skills Scrappy hunter mentality and coachable mindset Must be located Greater Salt Lake City Area and able to work on-site daily in our SLC office as well as travel in the field for partner onsite visits, conferences, etc. US Employee Benefits Verkada is committed to fostering a workplace environment that prioritizes the holistic health and wellbeing of our employees and their families by offering comprehensive wellness perks, benefits, and resources. Our benefits and perks programs include, but are not limited to: Healthcare programs that can be tailored to meet the personal health and financial well-being needs - Premiums are 100% covered for the employee under at least one plan and 80% for family premiums under all plans Nationwide medical, vision and dental coverage Health Saving Account (HSA) with annual employer contributions and Flexible Spending Account (FSA) with tax saving options Expanded mental health support Paid parental leave policy & fertility benefits Time off to relax and recharge through our paid holidays, firmwide extended holidays, flexible PTO and personal sick time Professional development stipend Fertility Stipend Wellness/fitness benefits Healthy lunches provided daily Commuter benefits Additional Information You must be independently authorized to work in the U.S. We are unable to sponsor or take over sponsorship of an employment visa for this role, at this time. Pay Disclosure At Verkada, we want to attract and retain the best employees, and compensate them in a way that appropriately and fairly values their individual contribution to the company. With that in mind, we carefully consider a number of factors to determine the appropriate starting pay for an employee, including their primary work location and an assessment of a candidate’s skills and experience, as well as market demands and internal parity. This estimate can vary based on the factors described above, so the actual starting base pay may be above or below this range. Base pay is also just one component of Verkada’s total rewards package. A Verkada employee may be eligible for additional forms of compensation, depending on their role, including sales incentives, discretionary bonuses, and/or equity in the company in the form of Restricted Stock Units (RSUs).Estimated Hourly Pay Range$30.29 - $30.29 USDAnnual Pay Range At Verkada, we want to attract and retain the best employees, and compensate them in a way that appropriately and fairly values their individual contribution to the company. With that in mind, we carefully consider a number of factors to determine the appropriate starting pay for an employee, including their primary work location and an assessment of a candidate's skills and experience, as well as market demands and internal parity. A Verkada employee may be eligible for additional forms of compensation, depending on their role, including sales incentives, discretionary bonuses, and/or equity in the company in the form of restricted stock units (RSUs) Below is the annual on-target earnings (OTE) range for full-time employees for this position, comprised of base compensation and commissions (if applicable).Estimated Annual Pay Range$30.29 - $30.29 USDVerkada Is An Equal Opportunity Employer As an equal opportunity employer, Verkada is committed to providing employment opportunities to all individuals. All applicants for positions at Verkada will be treated without regard to race, color, ethnicity, religion, sex, gender, gender identity and expression, sexual orientation, national origin, disability, age, marital status, veteran status, pregnancy, or any other basis prohibited by applicable law. Your application will be handled in accordance with our Candidate Privacy Policy.",
    "id": "job-boards-greenhouse-io-verkada-jobs-5008900007",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5008900007",
    "title": "Channel Development Representative, West (Salt Lake City)",
    "company_name": "verkada",
    "company_slug": "verkada",
    "location": "Salt Lake City, UT United States",
    "locations": [
      "Salt Lake City, UT United States"
    ],
    "url": "https://job-boards.greenhouse.io/verkada/jobs/5008900007",
    "departments": [
      "Channel"
    ],
    "employment_type": null,
    "posted_at": "2026-01-16T13:43:26-05:00",
    "fetched_at": "2026-01-19T19:10:18.438Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h3&gt;&lt;strong&gt;Who We Are&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;Verkada is transforming how organizations protect their people and places with an integrated, AI-powered platform. A leader in cloud physical security, Verkada helps organizations strengthen safety and efficiency through one connected software platform that includes solutions for video security, access control, air quality sensors, alarms, intercoms, and visitor management.&lt;br&gt;&lt;br&gt;Over 30,000 organizations worldwide, including more than 100 companies in the Fortune 500, trust Verkada as their physical security layer for easier management, intelligent control, and scalable deployments. Founded in 2016, Verkada has expanded rapidly with 15 offices and 2,200+ full-time employees.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;div&gt;\n&lt;h3 data-start=&quot;112&quot; data-end=&quot;310&quot;&gt;What You’ll Do&lt;/h3&gt;\n&lt;p data-start=&quot;112&quot; data-end=&quot;310&quot;&gt;Verkada is looking for a high-energy Channel Development Representative to help drive the growth and success of our reseller partners across the West region. In this role, you’ll:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li data-start=&quot;313&quot; data-end=&quot;414&quot;&gt;Introduce Verkada’s solutions into new partner accounts and support partner growth and development.&lt;/li&gt;\n&lt;li data-start=&quot;417&quot; data-end=&quot;540&quot;&gt;Work closely with partners to get them producing quickly, before handing off to the assigned Channel Sales Manager (CSM).&lt;/li&gt;\n&lt;li data-start=&quot;543&quot; data-end=&quot;639&quot;&gt;Manage partner applications, onboarding, and actively develop newly onboarded target accounts.&lt;/li&gt;\n&lt;li data-start=&quot;642&quot; data-end=&quot;699&quot;&gt;Step in as an inside CSM when field coverage is needed.&lt;/li&gt;\n&lt;li data-start=&quot;702&quot; data-end=&quot;825&quot;&gt;Build experience and prepare to move into a CSM role over time, with the opportunity to manage a territory when required.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;This is a career-launching opportunity to grow within tech sales, gain deep channel experience, and build a path toward a full CSM role in a fast-growing, innovative company.&lt;/p&gt;\n&lt;h3 data-start=&quot;827&quot; data-end=&quot;847&quot;&gt;What You Bring&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li data-start=&quot;850&quot; data-end=&quot;869&quot;&gt;Bachelor’s degree&lt;/li&gt;\n&lt;li data-start=&quot;872&quot; data-end=&quot;911&quot;&gt;1-2 years of sales experience in a quota and metric driven environment. IT or SaaS experience preferred.&amp;nbsp;&lt;/li&gt;\n&lt;li data-start=&quot;914&quot; data-end=&quot;993&quot;&gt;Confident presenting product demos and delivering high-level partner training&lt;/li&gt;\n&lt;li data-start=&quot;996&quot; data-end=&quot;1044&quot;&gt;Highly organized, able to thrive independently&lt;/li&gt;\n&lt;li data-start=&quot;1047&quot; data-end=&quot;1123&quot;&gt;Engaging personality with polished verbal and written communication skills&lt;/li&gt;\n&lt;li data-start=&quot;1126&quot; data-end=&quot;1174&quot;&gt;Scrappy hunter mentality and coachable mindset&lt;/li&gt;\n&lt;li style=&quot;font-weight: bold;&quot; data-start=&quot;1177&quot; data-end=&quot;1251&quot;&gt;&lt;strong&gt;Must be located Greater Salt Lake City Area and able to work on-site daily in our SLC office as well as travel in the field for partner onsite visits, conferences, etc.&amp;nbsp;&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 data-start=&quot;1253&quot; data-end=&quot;1455&quot;&gt;US Employee Benefits&lt;/h3&gt;\n&lt;p&gt;Verkada is committed to fostering a workplace environment that prioritizes the holistic health and wellbeing of our employees and their families by offering comprehensive wellness perks, benefits, and resources. Our benefits and perks programs include, but are not limited to:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Healthcare programs that can be tailored to meet the personal health and financial well-being needs - Premiums are 100% covered for the employee under at least one plan and 80% for family premiums under all plans&lt;/li&gt;\n&lt;li&gt;Nationwide medical, vision and dental coverage&lt;/li&gt;\n&lt;li&gt;Health Saving Account (HSA) with annual employer contributions and Flexible Spending Account (FSA) with tax saving options&lt;/li&gt;\n&lt;li&gt;Expanded mental health support&lt;/li&gt;\n&lt;li&gt;Paid parental leave policy &amp;amp; fertility benefits&lt;/li&gt;\n&lt;li&gt;Time off to relax and recharge through our paid holidays, firmwide extended holidays, flexible PTO and personal sick time&lt;/li&gt;\n&lt;li&gt;Professional development stipend&lt;/li&gt;\n&lt;li&gt;Fertility Stipend&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Wellness/fitness benefits&lt;/li&gt;\n&lt;li&gt;Healthy lunches provided daily&lt;/li&gt;\n&lt;li&gt;Commuter benefits&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 data-start=&quot;1108&quot; data-end=&quot;1130&quot;&gt;Additional Information&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;You must be independently authorized to work in the U.S. We are unable to sponsor or take over sponsorship of an employment visa for this role, at this time.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;Pay Disclosure&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span class=&quot;C9DxTc &quot;&gt;At Verkada, we want to attract and retain the best employees, and compensate them in a way that appropriately and fairly values their individual contribution to the company. With that in mind, we carefully consider a number of factors to determine the appropriate starting pay for an employee, including their primary work location and an assessment of a candidate’s skills and experience, as well as market demands and internal parity&lt;/span&gt;&lt;span class=&quot;C9DxTc &quot;&gt;. This estimate can vary based on the factors described above, so the actual starting base pay may be above or below this range. Base pay is also just one component of Verkada’s total rewards package. A Verkada employee may be eligible for additional forms of compensation, depending on their role, including sales incentives, discretionary bonuses, and/or equity in the company in the form of Restricted Stock Units (RSUs).&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Estimated Hourly Pay Range&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$30.29&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$30.29 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;strong&gt;&lt;span class=&quot;C9DxTc &quot;&gt;Annual Pay Range&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;At Verkada, we want to attract and retain the best employees, and compensate them in a way that appropriately and fairly values their individual contribution to the company. With that in mind, we carefully consider a number of factors to determine the appropriate starting pay for an employee, including their primary work location and an assessment of a candidate&#39;s skills and experience, as well as market demands and internal parity. A Verkada employee may be eligible for additional forms of compensation, depending on their role, including sales incentives, discretionary bonuses, and/or equity in the company in the form of restricted stock units (RSUs)&lt;/p&gt;\n&lt;p&gt;Below is the annual on-target earnings (OTE) range for full-time employees for this position, comprised of base compensation and commissions (if applicable).&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Estimated Annual Pay Range&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$30.29&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$30.29 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h3&gt;&lt;strong&gt;Verkada Is An Equal Opportunity Employer&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;As an equal opportunity employer, Verkada is committed to providing employment opportunities to all individuals. All applicants for positions at Verkada will be treated without regard to race, color, ethnicity, religion, sex, gender, gender identity and expression, sexual orientation, national origin, disability, age, marital status, veteran status, pregnancy, or any other basis prohibited by applicable law.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Your application will be handled in accordance with our &lt;a href=&quot;https://www.verkada.com/privacy/candidate-privacy-policy&quot; target=&quot;_blank&quot; data-saferedirecturl=&quot;https://www.google.com/url?q=https://url.uk.m.mimecastprotect.com/s/E_spClO3Ac9pX43h9dXa8/&amp;amp;source=gmail&amp;amp;ust=1719327847319000&amp;amp;usg=AOvVaw10eB41dX5dzNP9yveIJLsf&quot;&gt;Candidate Privacy Policy&lt;/a&gt;.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5008900007
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Software Engineer, ML Networking",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4926242008",
    "job_posted_at_datetime_utc": "2026-01-15T19:38:31-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Role Summary A systems-level engineer specializing in network infrastructure and network optimization, with expertise in building and maintaining software that interacts with networks. You will be responsible for writing and maintaining software that interfaces between our accelerators and our high-speed networks. This role requires deep technical knowledge of network protocols, kernel-space and/or user-space networks, interfacing with hardware, and the ability to debug and optimize distributed software at the network level. You may be a good fit if you have: Networking Systems Engineering: Expert-level proficiency with network protocols and networking concepts Deep kernel networking: TCP/IP stack internals, XDP, eBPF, io_uring, and epoll User-space networking: DPDK, RDMA, kernel bypass techniques Understanding of how to build higher-level abstractions like collectives and RPC Skilled at diagnosing and resolving networking issues in distributed systems, especially at OSI model layers 2-4 Low-Level Systems and OS Programming: Strong programming skills in a systems programming language, including memory management, lock-free data structures, and NUMA-aware programming Software, driver, and OS performance optimization tools and techniques Comfort with or desire to learn Rust Strong candidates may have: Understanding of ML accelerators and accelerator drivers Demonstrated ability to design new network protocols Experience with PCIe and drivers for PCIe devices Expertise in algorithms used in networking, including compression and graph algorithms Experience programming on SmartNICs 5+ years of experience in systems programming or network programming Often comes from backgrounds in: HPC, telecommunications, host networking software, OS/kernel engineering, or embedded systems Strong debugging mindset with patience for complex, multi-layered issues Representative Projects: Build a system for accelerator-initiated tensor movement over the network Benchmark software for a new networking environment Implement a new collective algorithm to improve latency Optimize congestion control algorithms for large-scale synchronous workloads Debug kernel-level network latency spikes The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4926242008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4926242008",
    "title": "Software Engineer, ML Networking",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4926242008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:38:31-05:00",
    "fetched_at": "2026-01-19T19:10:07.740Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;Role Summary&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;A systems-level engineer specializing in network infrastructure and network optimization, with expertise in building and maintaining software that interacts with networks. You will be responsible for writing and maintaining software that interfaces between our accelerators and our high-speed networks. This role requires deep technical knowledge of network protocols, kernel-space and/or user-space networks, interfacing with hardware, and the ability to debug and optimize distributed software at the network level.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;h3&gt;&lt;strong&gt;Networking Systems Engineering:&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Expert-level proficiency with network protocols and networking concepts&lt;/li&gt;\n&lt;li&gt;Deep kernel networking: TCP/IP stack internals, XDP, eBPF, io_uring, and epoll&lt;/li&gt;\n&lt;li&gt;User-space networking: DPDK, RDMA, kernel bypass techniques&lt;/li&gt;\n&lt;li&gt;Understanding of how to build higher-level abstractions like collectives and RPC&lt;/li&gt;\n&lt;li&gt;Skilled at diagnosing and resolving networking issues in distributed systems, especially at OSI model layers 2-4&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Low-Level Systems and OS Programming:&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Strong programming skills in a systems programming language, including memory management, lock-free data structures, and NUMA-aware programming&lt;/li&gt;\n&lt;li&gt;Software, driver, and OS performance optimization tools and techniques&lt;/li&gt;\n&lt;li&gt;Comfort with or desire to learn Rust&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Understanding of ML accelerators and accelerator drivers&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to design new network protocols&lt;/li&gt;\n&lt;li&gt;Experience with PCIe and drivers for PCIe devices&lt;/li&gt;\n&lt;li&gt;Expertise in algorithms used in networking, including compression and graph algorithms&lt;/li&gt;\n&lt;li&gt;Experience programming on SmartNICs&lt;/li&gt;\n&lt;li&gt;5+ years of experience in systems programming or network programming&lt;/li&gt;\n&lt;li&gt;Often comes from backgrounds in: HPC, telecommunications, host networking software, OS/kernel engineering, or embedded systems&lt;/li&gt;\n&lt;li&gt;Strong debugging mindset with patience for complex, multi-layered issues&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative Projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Build a system for accelerator-initiated tensor movement over the network&lt;/li&gt;\n&lt;li&gt;Benchmark software for a new networking environment&lt;/li&gt;\n&lt;li&gt;Implement a new collective algorithm to improve latency&lt;/li&gt;\n&lt;li&gt;Optimize congestion control algorithms for large-scale synchronous workloads&lt;/li&gt;\n&lt;li&gt;Debug kernel-level network latency spikes&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4926242008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "TPU Kernel Engineer",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4720576008",
    "job_posted_at_datetime_utc": "2026-01-15T19:34:17-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role As a TPU Kernel Engineer, you'll be responsible for identifying and addressing performance issues across many different ML systems, including research, training, and inference. A significant portion of this work will involve designing and optimizing kernels for the TPU. You will also provide feedback to researchers about how model changes impact performance. Strong candidates will have a track record of solving large-scale systems problems and low-level optimization. You may be a good fit if you: Have significant experience optimizing ML systems for TPUs, GPUs, or other accelerators Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large-scale ML systems Designing and implementing kernels for TPUs or other ML accelerators Understanding accelerators at a deep level, e.g. a background in computer architecture ML framework internals Language modeling with transformers Representative projects: Implement low-latency, high-throughput sampling for large language models Adapt existing models for low-precision inference Build quantitative models of system performance Design and implement custom collective communication algorithms Debug kernel performance at the assembly level The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4720576008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4720576008",
    "title": "TPU Kernel Engineer",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4720576008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:34:17-05:00",
    "fetched_at": "2026-01-19T19:10:07.740Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a TPU Kernel Engineer, you&#39;ll be responsible for identifying and addressing performance issues across many different ML systems, including research, training, and inference. A significant portion of this work will involve designing and optimizing kernels for the TPU. You will also provide feedback to researchers about how model changes impact performance. Strong candidates will have a track record of solving large-scale systems problems and low-level optimization.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant experience optimizing ML systems for TPUs, GPUs, or other accelerators&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Want to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have experience with:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;High performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;Designing and implementing kernels for TPUs or other ML accelerators&lt;/li&gt;\n&lt;li&gt;Understanding accelerators at a deep level, e.g. a background in computer architecture&lt;/li&gt;\n&lt;li&gt;ML framework internals&lt;/li&gt;\n&lt;li&gt;Language modeling with transformers&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Implement low-latency, high-throughput sampling for large language models&lt;/li&gt;\n&lt;li&gt;Adapt existing models for low-precision inference&lt;/li&gt;\n&lt;li&gt;Build quantitative models of system performance&lt;/li&gt;\n&lt;li&gt;Design and implement custom collective communication algorithms&lt;/li&gt;\n&lt;li&gt;Debug kernel performance at the assembly level&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&amp;nbsp;&lt;/h2&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4720576008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Performance Engineer",
    "employer_name": "anthropic",
    "job_city": "New York City, NY | Seattle, WA; San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4020350008",
    "job_posted_at_datetime_utc": "2026-01-15T19:33:38-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: Running machine learning (ML) algorithms at our scale often requires solving novel systems problems. As a Performance Engineer, you'll be responsible for identifying these problems, and then developing systems that optimize the throughput and robustness of our largest distributed systems. Strong candidates here will have a track record of solving large-scale systems problems and will be excited to grow to become an expert in ML also. You may be a good fit if you: Have significant software engineering or machine learning experience, particularly at supercomputing scale Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large-scale ML systems GPU/Accelerator programming ML framework internals OS internals Language modeling with transformers Representative projects: Implement low-latency high-throughput sampling for large language models Implement GPU kernels to adapt our models to low-precision inference Write a custom load-balancing algorithm to optimize serving efficiency Build quantitative models of system performance Design and implement a fault-tolerant distributed system running with a complex network topology Debug kernel-level network latency spikes in a containerized environment Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4020350008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4020350008",
    "title": "Performance Engineer",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY | Seattle, WA; San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "New York City, NY | Seattle, WA; San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4020350008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:33:38-05:00",
    "fetched_at": "2026-01-19T19:10:07.739Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;div&gt;\n&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div&gt;Running machine learning (ML) algorithms at our scale often requires solving novel systems problems. As a Performance Engineer, you&#39;ll be responsible for identifying these problems, and then developing systems that optimize the throughput and robustness of our largest distributed systems. Strong candidates here will have a track record of solving large-scale systems problems and will be excited to grow to become an expert in ML also.&lt;/div&gt;\n&lt;/div&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant software engineering or machine learning experience, particularly at supercomputing scale&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Want to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&amp;nbsp;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;High performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;GPU/Accelerator programming&lt;/li&gt;\n&lt;li&gt;ML framework internals&lt;/li&gt;\n&lt;li&gt;OS internals&lt;/li&gt;\n&lt;li&gt;Language modeling with transformers&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Implement low-latency high-throughput sampling for large language models&lt;/li&gt;\n&lt;li&gt;Implement GPU kernels to adapt our models to low-precision inference&lt;/li&gt;\n&lt;li&gt;Write a custom load-balancing algorithm to optimize serving efficiency&lt;/li&gt;\n&lt;li&gt;Build quantitative models of system performance&lt;/li&gt;\n&lt;li&gt;Design and implement a fault-tolerant distributed system running with a complex network topology&lt;/li&gt;\n&lt;li&gt;Debug kernel-level network latency spikes in a containerized environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4020350008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Machine Learning (Reinforcement Learning) ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4613568008",
    "job_posted_at_datetime_utc": "2026-01-15T19:33:06-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the teams Our Reinforcement Learning teams lead Anthropic's reinforcement learning research and development, playing a critical role in advancing our AI systems. We've contributed to all Claude models, with significant impacts on the autonomy and coding capabilities of Claude Sonnet 4.5 and Opus 4.5. Our work spans several key areas: Developing systems that enable models to use computers effectively Advancing code generation through reinforcement learning Pioneering fundamental RL research for large language models Building scalable RL infrastructure and training methodologies Enhancing model reasoning capabilities We collaborate closely with Anthropic's alignment and frontier red teams to ensure our systems are both capable and safe. We partner with the applied production training team to bring research innovations into deployed models, and are dedicated to implement our research at scale. Our Reinforcement Learning teams sit at the intersection of cutting-edge research and engineering excellence, with a deep commitment to building high-quality, scalable systems that push the boundaries of what AI can accomplish. About the Role As a Research Engineer within Reinforcement Learning, you will collaborate with a diverse group of researchers and engineers to advance the capabilities and safety of large language models. This role blends research and engineering responsibilities, requiring you to both implement novel approaches and contribute to the research direction. You'll work on fundamental research in reinforcement learning, creating 'agentic' models via tool use for open-ended tasks such as computer use and autonomous software generation, improving reasoning abilities in areas such as mathematics, and developing prototypes for internal use, productivity, and evaluation. Representative projects: Architect and optimize core reinforcement learning infrastructure, from clean training abstractions to distributed experiment management across GPU clusters. Help scale our systems to handle increasingly complex research workflows. Design, implement, and test novel training environments, evaluations, and methodologies for reinforcement learning agents which push the state of the art for the next generation of models. Drive performance improvements across our stack through profiling, optimization, and benchmarking. Implement efficient caching solutions and debug distributed systems to accelerate both training and evaluation workflows. Collaborate across research and engineering teams to develop automated testing frameworks, design clean APIs, and build scalable infrastructure that accelerates AI research. You may be a good fit if you: Are proficient in Python and async/concurrent programming with frameworks like Trio Have experience with machine learning frameworks (PyTorch, TensorFlow, JAX) Have industry experience in machine learning research Can balance research exploration with engineering implementation Enjoy pair programming (we love to pair!) Care about code quality, testing, and performance Have strong systems design and communication skills Are passionate about the potential impact of AI and are committed to developing safe and beneficial systems Strong candidates may have: Familiarity with LLM architectures and training methodologies Experience with reinforcement learning techniques and environments Experience with virtualization and sandboxed code execution environments Experience with Kubernetes Experience with distributed systems or high-performance computing Experience with Rust and/or C++ Strong candidates need not have: Formal certifications or education credentials Academic research experience or publication history Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$500,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4613568008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4613568008",
    "title": "Research Engineer, Machine Learning (Reinforcement Learning) ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4613568008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:33:06-05:00",
    "fetched_at": "2026-01-19T19:10:07.739Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About the teams&lt;/h2&gt;\n&lt;p&gt;Our Reinforcement Learning teams lead Anthropic&#39;s reinforcement learning research and development, playing a critical role in advancing our AI systems. We&#39;ve contributed to all Claude models, with significant impacts on the autonomy and coding capabilities of Claude Sonnet 4.5 and Opus 4.5. Our work spans several key areas:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Developing systems that enable models to use computers effectively&lt;/li&gt;\n&lt;li&gt;Advancing code generation through reinforcement learning&lt;/li&gt;\n&lt;li&gt;Pioneering fundamental RL research for large language models&lt;/li&gt;\n&lt;li&gt;Building scalable RL infrastructure and training methodologies&lt;/li&gt;\n&lt;li&gt;Enhancing model reasoning capabilities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;We collaborate closely with Anthropic&#39;s alignment and frontier red teams to ensure our systems are both capable and safe. We partner with the applied production training team to bring research innovations into deployed models, and are dedicated to implement our research at scale. Our Reinforcement Learning teams sit at the intersection of cutting-edge research and engineering excellence, with a deep commitment to building high-quality, scalable systems that push the boundaries of what AI can accomplish.&lt;/p&gt;\n&lt;/div&gt;\n&lt;h2&gt;About the Role&lt;/h2&gt;\n&lt;div&gt;\n&lt;p&gt;As a Research Engineer within Reinforcement Learning, you will collaborate with a diverse group of researchers and engineers to advance the capabilities and safety of large language models. This role blends research and engineering responsibilities, requiring you to both implement novel approaches and contribute to the research direction. You&#39;ll work on fundamental research in reinforcement learning, creating &#39;agentic&#39; models via tool use for open-ended tasks such as computer use and autonomous software generation, improving reasoning abilities in areas such as mathematics, and developing prototypes for internal use, productivity, and evaluation.&lt;/p&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Architect and optimize core reinforcement learning infrastructure, from clean training abstractions to distributed experiment management across GPU clusters. Help scale our systems to handle increasingly complex research workflows.&lt;/li&gt;\n&lt;li&gt;Design, implement, and test novel training environments, evaluations, and methodologies for reinforcement learning agents which push the state of the art for the next generation of models.&lt;/li&gt;\n&lt;li&gt;Drive performance improvements across our stack through profiling, optimization, and benchmarking. Implement efficient caching solutions and debug distributed systems to accelerate both training and evaluation workflows.&lt;/li&gt;\n&lt;li&gt;Collaborate across research and engineering teams to develop automated testing frameworks, design clean APIs, and build scalable infrastructure that accelerates AI research.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Are proficient in Python and async/concurrent programming with frameworks like Trio&lt;/li&gt;\n&lt;li&gt;Have experience with machine learning frameworks (PyTorch, TensorFlow, JAX)&lt;/li&gt;\n&lt;li&gt;Have industry experience in machine learning research&lt;/li&gt;\n&lt;li&gt;Can balance research exploration with engineering implementation&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Care about code quality, testing, and performance&lt;/li&gt;\n&lt;li&gt;Have strong systems design and communication skills&lt;/li&gt;\n&lt;li&gt;Are passionate about the potential impact of AI and are committed to developing safe and beneficial systems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may have:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;ul&gt;\n&lt;li&gt;Familiarity with LLM architectures and training methodologies&lt;/li&gt;\n&lt;li&gt;Experience with reinforcement learning techniques and environments&lt;/li&gt;\n&lt;li&gt;Experience with virtualization and sandboxed code execution environments&lt;/li&gt;\n&lt;li&gt;Experience with Kubernetes&lt;/li&gt;\n&lt;li&gt;Experience with distributed systems or high-performance computing&lt;/li&gt;\n&lt;li&gt;Experience with Rust and/or C++&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates need not have:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;ul&gt;\n&lt;li&gt;Formal certifications or education credentials&lt;/li&gt;\n&lt;li&gt;Academic research experience or publication history&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$500,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4613568008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Machine Learning Systems Engineer, RL Engineering",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4952051008",
    "job_posted_at_datetime_utc": "2026-01-15T19:31:25-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: You want to build the cutting-edge systems that train AI models like Claude. You're excited to work at the frontier of machine learning, implementing and improving advanced techniques to create ever more capable, reliable and steerable AI. As an ML Systems Engineer on our Reinforcement Learning Engineering team, you'll be responsible for the critical algorithms and infrastructure that our researchers depend on to train models. Your work will directly enable breakthroughs in AI capabilities and safety. You'll focus obsessively on improving the performance, robustness, and usability of these systems so our research can progress as quickly as possible. You're energized by the challenge of supporting and empowering our research team in the mission to build beneficial AI systems. Our finetuning researchers train our production Claude models, and internal research models, using RLHF and other related methods. Your job will be to build, maintain, and improve the algorithms and systems that these researchers use to train models. You’ll be responsible for improving the speed, reliability, and ease-of-use of these systems. You may be a good fit if you: Have 4+ years of software engineering experience Like working on systems and tools that make other people more productive Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large scale distributed systems Large scale LLM training Python Implementing LLM finetuning algorithms, such as RLHF Representative projects: Profiling our reinforcement learning pipeline to find opportunities for improvement Building a system that regularly launches training jobs in a test environment so that we can quickly detect problems in the training pipeline Making changes to our finetuning systems so they work on new model architectures Building instrumentation to detect and eliminate Python GIL contention in our training code Diagnosing why training runs have started slowing down after some number of steps, and fixing it Implementing a stable, fast version of a new training algorithm proposed by a researcher Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$500,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4952051008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4952051008",
    "title": "Machine Learning Systems Engineer, RL Engineering",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4952051008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:31:25-05:00",
    "fetched_at": "2026-01-19T19:10:07.739Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;&lt;strong&gt;About the role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;You want to build the cutting-edge systems that train AI models like Claude. You&#39;re excited to work at the frontier of machine learning, implementing and improving advanced techniques to create ever more capable, reliable and steerable AI. As an ML Systems Engineer on our Reinforcement Learning Engineering team, you&#39;ll be responsible for the critical algorithms and infrastructure that our researchers depend on to train models. Your work will directly enable breakthroughs in AI capabilities and safety. You&#39;ll focus obsessively on improving the performance, robustness, and usability of these systems so our research can progress as quickly as possible. You&#39;re energized by the challenge of supporting and empowering our research team in the mission to build beneficial AI systems.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Our finetuning researchers train our production Claude models, and internal research models, using RLHF and other related methods. Your job will be to build, maintain, and improve the algorithms and systems that these researchers use to train models. You’ll be responsible for improving the speed, reliability, and ease-of-use of these systems.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 4+ years of software engineering experience&lt;/li&gt;\n&lt;li&gt;Like working on systems and tools that make other people more productive&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Want to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have experience with:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;High performance, large scale distributed systems&lt;/li&gt;\n&lt;li&gt;Large scale LLM training&lt;/li&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;Implementing LLM finetuning algorithms, such as RLHF&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Profiling our reinforcement learning pipeline to find opportunities for improvement&lt;/li&gt;\n&lt;li&gt;Building a system that regularly launches training jobs in a test environment so that we can quickly detect problems in the training pipeline&lt;/li&gt;\n&lt;li&gt;Making changes to our finetuning systems so they work on new model architectures&lt;/li&gt;\n&lt;li&gt;Building instrumentation to detect and eliminate Python GIL contention in our training code&lt;/li&gt;\n&lt;li&gt;Diagnosing why training runs have started slowing down after some number of steps, and fixing it&lt;/li&gt;\n&lt;li&gt;Implementing a stable, fast version of a new training algorithm proposed by a researcher&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$500,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4952051008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": " [Expression of Interest] Research Manager, Interpretability",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4980436008",
    "job_posted_at_datetime_utc": "2026-01-15T19:00:30-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Note: we don't have open Research Manager positions on the Interpretability team at this time. However, we're actively growing our team of Research Engineers and Research Scientists. If you're excited about interpretability research and open to an individual contributor role, we encourage you to apply. About the Interpretability team: When you see what modern language models are capable of, do you wonder, \"How do these things work? How can we trust them?\" The Interpretability team’s mission is to reverse engineer how trained models work, and Interpretability research is one of Anthropic’s core research bets on AI safety. We believe that a mechanistic understanding is the most robust way to make advanced systems safe. People mean many different things by \"interpretability\". We're focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do \"biology\" or \"neuroscience\" of neural networks, or as treating neural networks as binary computer programs we're trying to \"reverse engineer\". We aim to create a solid scientific foundation for mechanistically understanding neural networks and making them safe (see our vision post). We have focused on resolving the issue of \"superposition\" (see Toy Models of Superposition, Superposition, Memorization, and Double Descent, and our May 2023 update), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our subsequent work which found millions of features in Claude 3.0 Sonnet, one of our production language models, represents progress in this direction. In our most recent work, we developed methods that allow us to build circuits using features and use these circuits to understand the mechanisms associated with a model's computation and study specific examples of multi-hop reasoning, planning, and chain-of-thought faithfulness on Claude Haiku 3.5, one of our production models.” This is a stepping stone towards our overall goal of mechanistically understanding neural networks. A few places to learn more about our work and team are this introduction to Interpretability from our research lead, Chris Olah, Stanford CS25 lecture given by Josh Batson, and TWIML AI podcast with Emmanuel Ameisen. Some of our team's notable publications include and our Circuits’ Methods and Biology papers, Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet, Towards Monosemanticity: Decomposing Language Models With Dictionary Learning, A Mathematical Framework for Transformer Circuits, In-context Learning and Induction Heads, and Toy Models of Superposition. This work builds on ideas from members' work prior to Anthropic such as the original circuits thread, Multimodal Neurons, Activation Atlases, and Building Blocks. About the role: As a manager on the Interpretability team, you'll support a team of expert researchers and engineers who are trying to understand at a deep, mechanistic level, how modern large language models work internally. Few things can accelerate this work more than great managers. Your work as manager will be critical in making sure that our fast-growing team is able to meet its ambitious safety research goals over the coming years. In this role, you will partner closely with an individual contributor research lead to drive the team's success, translating cutting-edge research ideas into tangible goals and overseeing their execution. You will manage team execution, careers and performance, facilitate relationships within and across teams, and drive the hiring pipeline. If you're more interested in making individual direct technical contributions to our research as the primary focus of your role, feel free to apply to our Research Scientist or Research Engineer roles instead. Responsibilities: Partner with a research lead on direction, project planning and execution, hiring, and people development Set and maintain a high bar for execution speed and quality, including identifying improvements to processes that help the team operate effectively Coach and support team members to have more impact and develop in their careers Drive the team's recruiting efforts, including hiring planning, process improvements, and sourcing and closing Help identify and support opportunities for collaboration with other teams across Anthropic Communicate team updates and results to other teams and leadership Maintain a deep understanding of the team's technical work and its implications for AI safety You may be a good fit if you: Are an experienced manager (minimum 2-5 years) with a track record of effectively leading highly technical research and/or engineering teams Have a background in machine learning, AI, or a related technical field Actively enjoy people management and are experienced with coaching and mentorship, performance evaluation, career development, and hiring for technical roles Have strong project management skills, including prioritization and cross-functional coordination and collaboration Have managed technical teams through periods of ambiguity and change Are a quick learner, capable of understanding and contributing to discussions on complex technical topics and are motivated to learn about our research Are a strong communicator both in speaking and in writing Believe that advanced AI systems could have a transformative effect on the world, and are passionate about helping make sure that transformation goes well Strong candidates may also have: Experience scaling engineering infrastructure Experience working on open-ended, exploratory research agendas aimed at foundational insights Some familiarity with our work and mechanistic interpretability Role Specific Location Policy: This role is expected to be in our SF office for 3 days a week. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4980436008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4980436008",
    "title": " [Expression of Interest] Research Manager, Interpretability",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4980436008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:00:30-05:00",
    "fetched_at": "2026-01-19T19:10:07.739Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Note: we don&#39;t have open Research Manager positions on the Interpretability team at this time. However, we&#39;re actively growing our team of &lt;a href=&quot;https://job-boards.greenhouse.io/anthropic/jobs/4980430008&quot;&gt;Research Engineers&lt;/a&gt; and &lt;a href=&quot;https://job-boards.greenhouse.io/anthropic/jobs/4980427008&quot;&gt;Research Scientists&lt;/a&gt;. If you&#39;re excited about interpretability research and open to an individual contributor role, we encourage you to apply.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;About the Interpretability team:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;When you see what modern language models are capable of, do you wonder, &quot;How do these things work? How can we trust them?&quot;&lt;/p&gt;\n&lt;p&gt;The Interpretability team’s mission is to reverse engineer how trained models work, and Interpretability research is one of Anthropic’s core research bets on AI safety. We believe that a mechanistic understanding is the most robust way to make advanced systems safe.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;People mean many different things by &quot;interpretability&quot;. We&#39;re focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do &quot;biology&quot; or &quot;neuroscience&quot; of neural networks, or as treating neural networks as binary computer programs we&#39;re trying to &quot;reverse engineer&quot;.&lt;/p&gt;\n&lt;p&gt;We aim to create a solid scientific foundation for mechanistically understanding neural networks and making them safe (see our &lt;a href=&quot;https://transformer-circuits.pub/2023/interpretability-dreams/index.html&quot;&gt;vision post&lt;/a&gt;). We have focused on resolving the issue of &quot;superposition&quot; (see &lt;a href=&quot;https://transformer-circuits.pub/2022/toy_model/index.html&quot;&gt;Toy Models of Superposition&lt;/a&gt;, &lt;a href=&quot;https://transformer-circuits.pub/2023/toy-double-descent/index.html&quot;&gt;Superposition, Memorization, and Double Descent&lt;/a&gt;, and our &lt;a href=&quot;https://transformer-circuits.pub/2023/may-update/index.html&quot;&gt;May 2023 update&lt;/a&gt;), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our subsequent &lt;a href=&quot;https://www.anthropic.com/news/mapping-mind-language-model&quot;&gt;work&lt;/a&gt; which found millions of features in Claude 3.0 Sonnet, one of our production language models, represents progress in this direction. In our &lt;a href=&quot;https://transformer-circuits.pub/2025/attribution-graphs/methods.html&quot;&gt;most recent work&lt;/a&gt;, we developed methods that allow us to build circuits using features and use these circuits to understand the mechanisms associated with a model&#39;s computation and study specific examples of multi-hop reasoning, planning, and chain-of-thought faithfulness on Claude Haiku 3.5, one of our production models.” This is a stepping stone towards our overall goal of mechanistically understanding neural networks.&lt;/p&gt;\n&lt;p&gt;A few places to learn more about our work and team are this &lt;a href=&quot;https://www.youtube.com/watch?v=TxhhMTOTMDg&quot;&gt;introduction to Interpretability&lt;/a&gt; from our research lead, &lt;a href=&quot;https://colah.github.io/about.html&quot;&gt;Chris Olah, Stanford CS25 lecture given by Josh Batson, and&lt;/a&gt; &lt;a href=&quot;https://twimlai.com/podcast/twimlai/exploring-the-biology-of-llms-with-circuit-tracing/&quot;&gt;TWIML AI podcast&lt;/a&gt; with Emmanuel Ameisen.&lt;/p&gt;\n&lt;p&gt;Some of our team&#39;s notable publications include and our Circuits’&amp;nbsp;&lt;a href=&quot;https://transformer-circuits.pub/2025/attribution-graphs/methods.html&quot;&gt;Methods&lt;/a&gt; and &lt;a href=&quot;https://transformer-circuits.pub/2025/attribution-graphs/biology.html&quot;&gt;Biology&lt;/a&gt; papers, &lt;a href=&quot;https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html&quot;&gt;Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet&lt;/a&gt;, &lt;a href=&quot;https://transformer-circuits.pub/2023/monosemantic-features/index.html&quot;&gt;Towards Monosemanticity: Decomposing Language Models With Dictionary Learning&lt;/a&gt;, &lt;a href=&quot;https://transformer-circuits.pub/2021/framework/index.html&quot;&gt;A Mathematical Framework for Transformer Circuits&lt;/a&gt;, &lt;a href=&quot;https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html&quot;&gt;In-context Learning and Induction Heads&lt;/a&gt;, and &lt;a href=&quot;https://transformer-circuits.pub/2022/toy_model/index.html&quot;&gt;Toy Models of Superposition&lt;/a&gt;. This work builds on ideas from members&#39; work prior to Anthropic such as the &lt;a href=&quot;https://distill.pub/2020/circuits/&quot;&gt;original circuits thread&lt;/a&gt;, &lt;a href=&quot;https://distill.pub/2021/multimodal-neurons/&quot;&gt;Multimodal Neurons&lt;/a&gt;, &lt;a href=&quot;https://distill.pub/2019/activation-atlas/&quot;&gt;Activation Atlases&lt;/a&gt;, and &lt;a href=&quot;https://distill.pub/2018/building-blocks/&quot;&gt;Building Blocks&lt;/a&gt;.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;About the role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a manager on the Interpretability team, you&#39;ll support a team of expert researchers and engineers who are trying to understand at a deep, mechanistic level, how modern large language models work internally.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Few things can accelerate this work more than great managers. Your work as manager will be critical in making sure that our fast-growing team is able to meet its ambitious safety research goals over the coming years. In this role, you will partner closely with an individual contributor research lead to drive the team&#39;s success, translating cutting-edge research ideas into tangible goals and overseeing their execution. You will manage team execution, careers and performance, facilitate relationships within and across teams, and drive the hiring pipeline.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;If you&#39;re more interested in making individual direct technical contributions to our research as the primary focus of your role, feel free to apply to our &lt;a href=&quot;https://boards.greenhouse.io/anthropic/jobs/4020159008&quot;&gt;Research Scientist&lt;/a&gt; or &lt;a href=&quot;https://boards.greenhouse.io/anthropic/jobs/4020305008&quot;&gt;Research Engineer&lt;/a&gt; roles instead.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Partner with a research lead on direction, project planning and execution, hiring, and people development&lt;/li&gt;\n&lt;li&gt;Set and maintain a high bar for execution speed and quality, including identifying improvements to processes that help the team operate effectively&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Coach and support team members to have more impact and develop in their careers&lt;/li&gt;\n&lt;li&gt;Drive the team&#39;s recruiting efforts, including hiring planning, process improvements, and sourcing and closing&lt;/li&gt;\n&lt;li&gt;Help identify and support opportunities for collaboration with other teams across Anthropic&lt;/li&gt;\n&lt;li&gt;Communicate team updates and results to other teams and leadership&lt;/li&gt;\n&lt;li&gt;Maintain a deep understanding of the team&#39;s technical work and its implications for AI safety&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Are an experienced manager (minimum 2-5 years) with a track record of effectively leading highly technical research and/or engineering teams&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Have a background in machine learning, AI, or a related technical field&lt;/li&gt;\n&lt;li&gt;Actively enjoy people management and are experienced with coaching and mentorship, performance evaluation, career development, and hiring for technical roles&lt;/li&gt;\n&lt;li&gt;Have strong project management skills, including prioritization and cross-functional coordination and collaboration&lt;/li&gt;\n&lt;li&gt;Have managed technical teams through periods of ambiguity and change&lt;/li&gt;\n&lt;li&gt;Are a quick learner, capable of understanding and contributing to discussions on complex technical topics and are motivated to learn about our research&lt;/li&gt;\n&lt;li&gt;Are a strong communicator both in speaking and in writing&lt;/li&gt;\n&lt;li&gt;Believe that advanced AI systems could have a transformative effect on the world, and are passionate about helping make sure that transformation goes well&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience scaling engineering infrastructure&lt;/li&gt;\n&lt;li&gt;Experience working on open-ended, exploratory research agendas aimed at foundational insights&lt;/li&gt;\n&lt;li&gt;Some familiarity with our work and mechanistic interpretability&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Role Specific Location Policy:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;This role is expected to be in our SF office for 3 days a week.&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4980436008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "ML/Research Engineer, Safeguards",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4949336008",
    "job_posted_at_datetime_utc": "2026-01-15T18:59:38-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role We are looking for ML Engineers and Research Engineers to help detect and mitigate misuse of our AI systems. As a member of the Safeguards ML team, you will build systems that identify harmful use—from individual policy violations to sophisticated, coordinated attacks—and develop defenses that keep our products safe as capabilities advance. You will also work on systems that protect user wellbeing and ensure our models behave appropriately across a wide range of contexts. This work feeds directly into Anthropic's Responsible Scaling Policy commitments. Responsibilities Develop classifiers to detect misuse and anomalous behavior at scale. This includes developing synthetic data pipelines for training classifiers and methods to automatically source representative evaluations to iterate on Build systems to monitor for harms that span multiple exchanges, such as coordinated cyber attacks and influence operations, and develop new methods for aggregating and analyzing signals across contexts Evaluate and improve the safety of agentic products—developing both threat models and environments to test for agentic risks, and developing and deploying mitigations for prompt injection attacks Conduct research on automated red-teaming, adversarial robustness, and other research that helps test for or find misuse You may be a good fit if you Have 4+ years of experience in ML engineering, research engineering, or applied research, in academia or industry Have proficiency in Python and experience building ML systems Are comfortable working across the research-to-deployment pipeline, from exploratory experiments to production systems Are worried about misuse risks of AI systems, and want to work to mitigate them Have strong communication skills and ability to explain complex technical concepts to non-technical stakeholders Strong candidates may also have experience with Language modeling and transformers Building classifiers, anomaly detection systems, or behavioral ML Adversarial machine learning or red-teaming Interpretability or probes Reinforcement learning High-performance, large-scale ML systems The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4949336008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4949336008",
    "title": "ML/Research Engineer, Safeguards",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4949336008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:59:38-05:00",
    "fetched_at": "2026-01-19T19:10:07.739Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We are looking for ML Engineers and Research Engineers to help detect and mitigate misuse of our AI systems. As a member of the Safeguards ML team, you will build systems that identify harmful use—from individual policy violations to sophisticated, coordinated attacks—and develop defenses that keep our products safe as capabilities advance. You will also work on systems that protect user wellbeing and ensure our models behave appropriately across a wide range of contexts. This work feeds directly into Anthropic&#39;s Responsible Scaling Policy commitments.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop classifiers to detect misuse and anomalous behavior at scale. This includes developing synthetic data pipelines for training classifiers and methods to automatically source representative evaluations to iterate on&lt;/li&gt;\n&lt;li&gt;Build systems to monitor for harms that span multiple exchanges, such as coordinated cyber attacks and influence operations, and develop new methods for aggregating and analyzing signals across contexts&lt;/li&gt;\n&lt;li&gt;Evaluate and improve the safety of agentic products—developing both threat models and environments to test for agentic risks, and developing and deploying mitigations for prompt injection attacks&lt;/li&gt;\n&lt;li&gt;Conduct research on automated red-teaming, adversarial robustness, and other research that helps test for or find misuse&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 4+ years of experience in ML engineering, research engineering, or applied research, in academia or industry&lt;/li&gt;\n&lt;li&gt;Have proficiency in Python and experience building ML systems&lt;/li&gt;\n&lt;li&gt;Are comfortable working across the research-to-deployment pipeline, from exploratory experiments to production systems&lt;/li&gt;\n&lt;li&gt;Are worried about misuse risks of AI systems, and want to work to mitigate them&lt;/li&gt;\n&lt;li&gt;Have strong communication skills and ability to explain complex technical concepts to non-technical stakeholders&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have experience with&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Language modeling and transformers&lt;/li&gt;\n&lt;li&gt;Building classifiers, anomaly detection systems, or behavioral ML&lt;/li&gt;\n&lt;li&gt;Adversarial machine learning or red-teaming&lt;/li&gt;\n&lt;li&gt;Interpretability or probes&lt;/li&gt;\n&lt;li&gt;Reinforcement learning&lt;/li&gt;\n&lt;li&gt;High-performance, large-scale ML systems&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4949336008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]