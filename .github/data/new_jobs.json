[
  {
    "job_title": "Partner Marketing Manager (Public Sector)",
    "employer_name": "datadog",
    "job_city": "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote",
    "job_apply_link": "https://careers.datadoghq.com/detail/7476873/?gh_jid=7476873",
    "job_posted_at_datetime_utc": "2026-01-12T12:36:11-05:00",
    "job_description": "Datadog’s Public Sector Marketing team is seeking an experienced Partner Marketing Manager to build and scale co-marketing programs with our strategic public sector partners, including AWS, Carahsoft, systems integrators (SIs), and resellers to drive pipeline and brand impact. This individual will develop, execute, and optimize co-marketing campaigns and enablement programs that position Datadog as the observability and security platform of choice for U.S. Federal, State, Local, and Education (SLED) markets.This role requires knowledge of the public sector ecosystem, government procurement processes, and the unique compliance and security requirements (e.g., FedRAMP, GovRAMP). You will work cross-functionally with sales, product marketing, field marketing, alliances, and demand generation teams to ensure partner marketing efforts are aligned to Datadog’s growth goals in the public sector.At Datadog, we place value in our office culture - the relationships and collaboration it builds, and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.What You’ll DoLead partner go-to-market strategy by developing and executing joint marketing plans with key public sector partners (AWS, Carahsoft, systems integrators, resellers).Manage MDF through planning, approving, tracking, and optimizing partner marketing development fund investments for campaigns, events, and targeted digital programs.Own the end-to-end execution of partner-led and co-branded marketing activities, from planning to performance analysis.Create and maintain enablement resources including partner playbooks, battlecards, solution briefs, and co-branded partner collateral to position Datadog effectively with public sector audiences.Drive partner seller readiness through training sessions, workshops, and enablement programs that empower partners to articulate Datadog’s value in mission-critical environments.Develop customer success storytelling with partners by producing case studies and proof points that highlight government and education wins.Collaborate cross-functionally with Public Sector Sales, Field Marketing, Product Marketing, and Demand Generation teams to align campaigns, messaging, and market approach. Build relationships with partner marketing teams to maximize collaboration and program impact.Track and report performance using Salesforce, partner portals, and analytics to measure sourced / influenced pipeline, enablement adoption, and MDF ROI.Who You Are6+ years of experience in partner marketing, alliances marketing, or channel marketing, ideally with a SaaS or cloud technology company serving the public sector.Strong understanding of public sector sales cycles, procurement vehicles, and compliance requirements (FedRAMP, SEWP, GSA).Proven track record building co-marketing campaigns with hyperscalers (AWS, Azure, GCP) and/or leading distributors / SIs in the public sector.Skilled at navigating complex partner organizations and building trusted relationships across marketing, sales, and alliance teams.Excellent written and verbal communicator, adept at translating technical concepts into mission-relevant messaging for government audiences.You work fluidly across multiple internal teams and external partners.Strong communication skills with both technical and executive-level audiences.You understand the mechanics of SaaS / cloud partner ecosystems, especially managing MDF and enabling co‑marketing efforts.Self-starter who thrives in a fast-paced, collaborative environment. Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply. Why Join Datadog Public Sector MarketingYou’ll join a fast-moving, data-driven team executing high-impact campaigns that help government agencies secure critical systems, modernize faster, and operate more efficiently. This role offers the opportunity to shape Datadog’s public sector partner marketing engine at a time of rapid growth, with significant impact on pipeline and market positioning. Benefits and Growth: Generous and competitive benefits packageNew hire stock equity (RSUs) and employee stock purchase planContinuous career development and pathing opportunities Product training to develop an in-depth understanding of our product and spaceBest in breed onboardingInternal mentor and buddy program cross-departmentallyFriendly and inclusive workplace cultureBenefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate's skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.The reasonably estimated yearly salary for this role at Datadog is:$96,000—$128,000 USDAbout Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog Learning Center.Equal Opportunity at Datadog:Datadog is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our Candidate Legal Notices for your reference. Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete this form. This form is for accommodation requests only and cannot be used to inquire about the status of applications. Privacy and AI Guidelines:Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice. For information on our AI policy, please visit Interviewing at Datadog AI Guidelines.Requisition ID: R17071",
    "id": "careers-datadoghq-com-detail-7476873",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7476873",
    "title": "Partner Marketing Manager (Public Sector)",
    "company_name": "datadog",
    "company_slug": "datadog",
    "location": "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote",
    "locations": [
      "District of Columbia, USA, Remote; Maryland, USA, Remote; Virginia, USA, Remote"
    ],
    "url": "https://careers.datadoghq.com/detail/7476873/?gh_jid=7476873",
    "departments": [
      "Field Marketing"
    ],
    "employment_type": null,
    "posted_at": "2026-01-12T12:36:11-05:00",
    "fetched_at": "2026-01-19T18:49:28.845Z",
    "description": "&lt;p&gt;Datadog’s Public Sector Marketing team is seeking an experienced Partner Marketing Manager to build and scale co-marketing programs with our strategic public sector partners, including AWS, Carahsoft, systems integrators (SIs), and resellers to drive pipeline and brand impact. This individual will develop, execute, and optimize co-marketing campaigns and enablement programs that position Datadog as the observability and security platform of choice for U.S. Federal, State, Local, and Education (SLED) markets.&lt;/p&gt;\n&lt;p&gt;This role requires knowledge of the public sector ecosystem, government procurement processes, and the unique compliance and security requirements (e.g., FedRAMP, GovRAMP). You will work cross-functionally with sales, product marketing, field marketing, alliances, and demand generation teams to ensure partner marketing efforts are aligned to Datadog’s growth goals in the public sector.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;At Datadog, we place value in our office culture - the relationships and collaboration it builds, and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.&lt;/em&gt;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;What You’ll Do&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead partner go-to-market strategy by developing and executing joint marketing plans with key public sector partners (AWS, Carahsoft, systems integrators, resellers).&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Manage MDF through planning, approving, tracking, and optimizing partner marketing development fund investments for campaigns, events, and targeted digital programs.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Own the end-to-end execution of partner-led and co-branded marketing activities, from planning to performance analysis.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Create and maintain enablement resources including partner playbooks, battlecards, solution briefs, and co-branded partner collateral to position Datadog effectively with public sector audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Drive partner seller readiness through training sessions, workshops, and enablement programs that empower partners to articulate Datadog’s value in mission-critical environments.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Develop customer success storytelling with partners by producing case studies and proof points that highlight government and education wins.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Collaborate cross-functionally with Public Sector Sales, Field Marketing, Product Marketing, and Demand Generation teams to align campaigns, messaging, and market approach. Build relationships with partner marketing teams to maximize collaboration and program impact.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Track and report performance using Salesforce, partner portals, and analytics to measure sourced / influenced pipeline, enablement adoption, and MDF ROI.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Who You Are&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;6+ years of experience in partner marketing, alliances marketing, or channel marketing, ideally with a SaaS or cloud technology company serving the public sector.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Strong understanding of public sector sales cycles, procurement vehicles, and compliance requirements (FedRAMP, SEWP, GSA).&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Proven track record building co-marketing campaigns with hyperscalers (AWS, Azure, GCP) and/or leading distributors / SIs in the public sector.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Skilled at navigating complex partner organizations and building trusted relationships across marketing, sales, and alliance teams.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Excellent written and verbal communicator, adept at translating technical concepts into mission-relevant messaging for government audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;You work fluidly across multiple internal teams and external partners.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Strong communication skills with both technical and executive-level audiences.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;You understand the mechanics of SaaS / cloud partner ecosystems, especially managing MDF and enabling co‑marketing efforts.&lt;br&gt;&lt;br&gt;&lt;/li&gt;\n&lt;li&gt;Self-starter who thrives in a fast-paced, collaborative environment.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That&#39;s okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply.&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;Why Join Datadog Public Sector Marketing&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;You’ll join a fast-moving, data-driven team executing high-impact campaigns that help government agencies secure critical systems, modernize faster, and operate more efficiently. This role offers the opportunity to shape Datadog’s public sector partner marketing engine at a time of rapid growth, with significant impact on pipeline and market positioning.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Benefits and Growth:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Generous and competitive benefits package&lt;/li&gt;\n&lt;li&gt;New hire stock equity (RSUs) and employee stock purchase plan&lt;/li&gt;\n&lt;li&gt;Continuous career development and pathing opportunities&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Product training to develop an in-depth understanding of our product and space&lt;/li&gt;\n&lt;li&gt;Best in breed onboarding&lt;/li&gt;\n&lt;li&gt;Internal mentor and buddy program cross-departmentally&lt;/li&gt;\n&lt;li&gt;Friendly and inclusive workplace culture&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate&#39;s skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;The reasonably estimated yearly salary for this role at Datadog is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$96,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$128,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;hr&gt;\n&lt;p&gt;&lt;strong&gt;About Datadog:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on &lt;a href=&quot;https://www.instagram.com/datadoghq/?hl=en&quot; target=&quot;_blank&quot;&gt;Instagram&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/company/datadog&quot; target=&quot;_blank&quot;&gt;LinkedIn,&lt;/a&gt; and &lt;a href=&quot;https://learn.datadoghq.com/&quot; target=&quot;_blank&quot;&gt;Datadog Learning Center. &lt;/a&gt;&lt;/p&gt;\n&lt;hr&gt;\n&lt;p data-renderer-start-pos=&quot;215&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Equal Opportunity at Datadog:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog is proud to offer &lt;a href=&quot;https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf&quot; target=&quot;_blank&quot;&gt;equal employment opportunity&lt;/a&gt; to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our &lt;a href=&quot;https://www.datadoghq.com/legal/candidate-legal-notices/&quot; target=&quot;_blank&quot;&gt;Candidate Legal Notices&lt;/a&gt; for your reference.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSeoJeduEZ2NdZF_65uZmWUrCM-zee7yADXX1s6Xr9zAGq8iKA/viewform&quot; target=&quot;_blank&quot;&gt;this form&lt;/a&gt;. This form is for accommodation requests only and cannot be used to inquire about the status of applications.&amp;nbsp;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Privacy and AI Guidelines:&lt;/strong&gt;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; data-sk=&quot;tooltip_parent&quot;&gt;Applicant and Candidate Privacy Notice&lt;/a&gt;. For information on our AI policy, please visit &lt;a href=&quot;https://www.datadoghq.com/legal/interviewing-at-datadog-ai-guidelines/&quot; target=&quot;_blank&quot;&gt;Interviewing at Datadog AI Guidelines&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7476873
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Production Model Post Training",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4613592008",
    "job_posted_at_datetime_utc": "2026-01-15T18:56:11-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role Anthropic's production models undergo sophisticated post-training processes to enhance their capabilities, alignment, and safety. As a Research Engineer on our Post-Training team, you'll train our base models through the complete post-training stack to deliver the production Claude models that users interact with. You'll work at the intersection of cutting-edge research and production engineering, implementing, scaling, and improving post-training techniques like Constitutional AI, RLHF, and other alignment methodologies. Your work will directly impact the quality, safety, and capabilities of our production models. Note: For this role, we conduct all interviews in Python. This role may require responding to incidents on short-notice, including on weekends. Responsibilities: Implement and optimize post-training techniques at scale on frontier models Conduct research to develop and optimize post-training recipes that directly improve production model quality Design, build, and run robust, efficient pipelines for model fine-tuning and evaluation Develop tools to measure and improve model performance across various dimensions Collaborate with research teams to translate emerging techniques into production-ready implementations Debug complex issues in training pipelines and model behavior Help establish best practices for reliable, reproducible model post-training You may be a good fit if you: Thrive in controlled chaos and are energised, rather than overwhelmed, when juggling multiple urgent priorities Adapt quickly to changing priorities Maintain clarity when debugging complex, time-sensitive issues Have strong software engineering skills with experience building complex ML systems Are comfortable working with large-scale distributed systems and high-performance computing Have experience with training, fine-tuning, or evaluating large language models Can balance research exploration with engineering rigor and operational reliability Are adept at analyzing and debugging model training processes Enjoy collaborating across research and engineering disciplines Can navigate ambiguity and make progress in fast-moving research environments Strong candidates may also: Have experience with LLMs Have a keen interest in AI safety and responsible deployment We welcome candidates at various experience levels, with a preference for senior engineers who have hands-on experience with frontier AI systems. However, proficiency in Python, deep learning frameworks, and distributed computing is required for this role.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4613592008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4613592008",
    "title": "Research Engineer, Production Model Post Training",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4613592008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:56:11-05:00",
    "fetched_at": "2026-01-19T19:10:07.740Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;Anthropic&#39;s production models undergo sophisticated post-training processes to enhance their capabilities, alignment, and safety. As a Research Engineer on our Post-Training team, you&#39;ll train our base models through the complete post-training stack to deliver the production Claude models that users interact with.&lt;/p&gt;\n&lt;p&gt;You&#39;ll work at the intersection of cutting-edge research and production engineering, implementing, scaling, and improving post-training techniques like Constitutional AI, RLHF, and other alignment methodologies. Your work will directly impact the quality, safety, and capabilities of our production models.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python. This role may require responding to incidents on short-notice, including on weekends.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Implement and optimize post-training techniques at scale on frontier models&lt;/li&gt;\n&lt;li&gt;Conduct research to develop and optimize post-training recipes that directly improve production model quality&lt;/li&gt;\n&lt;li&gt;Design, build, and run robust, efficient pipelines for model fine-tuning and evaluation&lt;/li&gt;\n&lt;li&gt;Develop tools to measure and improve model performance across various dimensions&lt;/li&gt;\n&lt;li&gt;Collaborate with research teams to translate emerging techniques into production-ready implementations&lt;/li&gt;\n&lt;li&gt;Debug complex issues in training pipelines and model behavior&lt;/li&gt;\n&lt;li&gt;Help establish best practices for reliable, reproducible model post-training&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Thrive in controlled chaos and&amp;nbsp;are energised, rather than overwhelmed, when juggling multiple urgent priorities&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Adapt quickly to changing priorities&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Maintain clarity when debugging complex, time-sensitive issues&lt;/li&gt;\n&lt;li&gt;Have strong software engineering skills with experience building complex ML systems&lt;/li&gt;\n&lt;li&gt;Are comfortable working with large-scale distributed systems and high-performance computing&lt;/li&gt;\n&lt;li&gt;Have experience with training, fine-tuning, or evaluating large language models&lt;/li&gt;\n&lt;li&gt;Can balance research exploration with engineering rigor and operational reliability&lt;/li&gt;\n&lt;li&gt;Are adept at analyzing and debugging model training processes&lt;/li&gt;\n&lt;li&gt;Enjoy collaborating across research and engineering disciplines&lt;/li&gt;\n&lt;li&gt;Can navigate ambiguity and make progress in fast-moving research environments&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have experience with LLMs&lt;/li&gt;\n&lt;li&gt;Have a keen interest in AI safety and responsible deployment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;We welcome candidates at various experience levels, with a preference for senior engineers who have hands-on experience with frontier AI systems. However, proficiency in Python, deep learning frameworks, and distributed computing is required for this role.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4613592008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer / Scientist, Alignment Science",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4631822008",
    "job_posted_at_datetime_utc": "2026-01-15T18:55:31-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: You want to build and run elegant and thorough machine learning experiments to help us understand and steer the behavior of powerful AI systems. You care about making AI helpful, honest, and harmless, and are interested in the ways that this could be challenging in the context of human-level capabilities. You could describe yourself as both a scientist and an engineer. As a Research Engineer on Alignment Science, you'll contribute to exploratory experimental research on AI safety, with a focus on risks from powerful future systems (like those we would designate as ASL-3 or ASL-4 under our Responsible Scaling Policy), often in collaboration with other teams including Interpretability, Fine-Tuning, and the Frontier Red Team. Our blog provides an overview of topics that the Alignment Science team is either currently exploring or has previously explored. Our current topics of focus include... Scalable Oversight: Developing techniques to keep highly capable models helpful and honest, even as they surpass human-level intelligence in various domains. AI Control: Creating methods to ensure advanced AI systems remain safe and harmless in unfamiliar or adversarial scenarios. Alignment Stress-testing: Creating model organisms of misalignment to improve our empirical understanding of how alignment failures might arise. Automated Alignment Research: Building and aligning a system that can speed up & improve alignment research. Alignment Assessments: Understanding and documenting the highest-stakes and most concerning emerging properties of models through pre-deployment alignment and welfare assessments (see our Claude 4 System Card), misalignment-risk safety cases, and coordination with third-party evaluators. Safeguards Research: Developing robust defenses against adversarial attacks, comprehensive evaluation frameworks for model safety, and automated systems to detect and mitigate potential risks before deployment. Model Welfare: Investigating and addressing potential model welfare, moral status, and related questions. See our program announcement and welfare assessment in the Claude 4 system card for more. Note: For this role, we conduct all interviews in Python and prefer candidates to be based in the Bay Area. Representative projects: Testing the robustness of our safety techniques by training language models to subvert our safety techniques, and seeing how effective they are at subverting our interventions. Run multi-agent reinforcement learning experiments to test out techniques like AI Debate. Build tooling to efficiently evaluate the effectiveness of novel LLM-generated jailbreaks. Write scripts and prompts to efficiently produce evaluation questions to test models’ reasoning abilities in safety-relevant contexts. Contribute ideas, figures, and writing to research papers, blog posts, and talks. Run experiments that feed into key AI safety efforts at Anthropic, like the design and implementation of our Responsible Scaling Policy. You may be a good fit if you: Have significant software, ML, or research engineering experience Have some experience contributing to empirical AI research projects Have some familiarity with technical AI safety research Prefer fast-moving collaborative projects to extensive solo efforts Pick up slack, even if it goes outside your job description Care about the impacts of AI Strong candidates may also: Have experience authoring research papers in machine learning, NLP, or AI safety Have experience with LLMs Have experience with reinforcement learning Have experience with Kubernetes clusters and complex shared codebases Candidates need not have: 100% of the skills needed to perform the job Formal certifications or education credentials The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4631822008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4631822008",
    "title": "Research Engineer / Scientist, Alignment Science",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4631822008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:55:31-05:00",
    "fetched_at": "2026-01-19T19:10:07.740Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div&gt;You want to build and run elegant and thorough machine learning experiments to help us understand and steer the behavior of powerful AI systems. You care about making AI helpful, honest, and harmless, and are interested in the ways that this could be challenging in the context of human-level capabilities. You could describe yourself as both a scientist and an engineer. As a Research Engineer on Alignment Science, you&#39;ll contribute to exploratory experimental research on AI safety, with a focus on risks from powerful future systems (like those we would designate as ASL-3 or ASL-4 under our &lt;a class=&quot;postings-link&quot; href=&quot;https://www.anthropic.com/news/anthropics-responsible-scaling-policy&quot;&gt;Responsible Scaling Policy&lt;/a&gt;), often in collaboration with other teams including Interpretability, Fine-Tuning, and the Frontier Red Team.&lt;/div&gt;\n&lt;div&gt;&amp;nbsp;&lt;/div&gt;\n&lt;div&gt;&lt;a href=&quot;https://alignment.anthropic.com/&quot;&gt;Our blog&lt;/a&gt; provides an overview of topics that the Alignment Science team is either currently exploring or has previously explored. Our current topics of focus include...\n&lt;ul class=&quot;p-rich_text_list p-rich_text_list__bullet p-rich_text_list--nested&quot; data-stringify-type=&quot;unordered-list&quot; data-list-tree=&quot;true&quot; data-indent=&quot;0&quot; data-border=&quot;0&quot;&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Scalable Oversight:&amp;nbsp;&lt;/strong&gt;Developing techniques to keep highly capable models helpful and honest, even as they surpass human-level intelligence in various domains.&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;AI Control:&amp;nbsp;&lt;/strong&gt;Creating methods to ensure advanced AI systems remain safe and harmless in unfamiliar or adversarial scenarios.&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;&lt;a class=&quot;c-link&quot; href=&quot;https://www.lesswrong.com/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.lesswrong.com/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic&quot; data-sk=&quot;tooltip_parent&quot;&gt;Alignment Stress-testing&lt;/a&gt;&lt;/strong&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;:&lt;/strong&gt;&amp;nbsp;Creating&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1&quot; data-sk=&quot;tooltip_parent&quot;&gt;model organisms of misalignment&lt;/a&gt;&amp;nbsp;to improve our empirical understanding of how alignment failures might arise.&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Automated Alignment Research:&amp;nbsp;&lt;/strong&gt;Building and aligning a system that can speed up &amp;amp; improve alignment research.&lt;/li&gt;\n&lt;li class=&quot;whitespace-normal break-words&quot;&gt;&lt;strong&gt;Alignment Assessments&lt;/strong&gt;: Understanding and documenting the highest-stakes and most concerning emerging properties of models through pre-deployment alignment and welfare assessments (see our &lt;span class=&quot;s1&quot;&gt;&lt;a href=&quot;https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf&quot;&gt;&lt;span class=&quot;s2&quot;&gt;Claude 4 System Card&lt;/span&gt;&lt;/a&gt;)&lt;/span&gt;, misalignment-risk safety cases, and coordination with third-party evaluators.&lt;/li&gt;\n&lt;li class=&quot;whitespace-normal break-words&quot;&gt;&lt;a href=&quot;https://job-boards.greenhouse.io/anthropic/jobs/4459012008&quot;&gt;&lt;strong&gt;Safeguards Research&lt;/strong&gt;&lt;/a&gt;: Developing robust defenses against adversarial attacks, comprehensive evaluation frameworks for model safety, and automated systems to detect and mitigate potential risks before deployment.&lt;/li&gt;\n&lt;li class=&quot;whitespace-normal break-words&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Model Welfare:&amp;nbsp;&lt;/strong&gt;Investigating and addressing potential model welfare, moral status, and related questions. See our&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/research/exploring-model-welfare&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/research/exploring-model-welfare&quot; data-sk=&quot;tooltip_parent&quot;&gt;program announcement&lt;/a&gt;&amp;nbsp;and welfare assessment in the&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www-cdn.anthropic.com/07b2a3f9902ee19fe39a36ca638e5ae987bc64dd.pdf&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www-cdn.anthropic.com/07b2a3f9902ee19fe39a36ca638e5ae987bc64dd.pdf&quot; data-sk=&quot;tooltip_parent&quot;&gt;Claude 4 system card&lt;/a&gt;&amp;nbsp;for more.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python and prefer candidates to be based in the Bay Area.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Testing the robustness of our safety techniques by training language models to subvert our safety techniques, and seeing how effective they are at subverting our interventions.&lt;/li&gt;\n&lt;li&gt;Run multi-agent reinforcement learning experiments to test out techniques like&amp;nbsp;&lt;a class=&quot;postings-link&quot; href=&quot;https://arxiv.org/abs/1805.00899&quot;&gt;AI Debate&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;Build tooling to efficiently evaluate the effectiveness of novel LLM-generated jailbreaks.&lt;/li&gt;\n&lt;li&gt;Write scripts and prompts to efficiently produce evaluation questions to test models’ reasoning abilities in safety-relevant contexts.&lt;/li&gt;\n&lt;li&gt;Contribute ideas, figures, and writing to research papers, blog posts, and talks.&lt;/li&gt;\n&lt;li&gt;Run experiments that feed into key AI safety efforts at Anthropic, like the design and implementation of our&amp;nbsp;&lt;a class=&quot;postings-link&quot; href=&quot;https://www.anthropic.com/news/anthropics-responsible-scaling-policy&quot;&gt;Responsible Scaling Policy&lt;/a&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant software, ML, or research engineering experience&lt;/li&gt;\n&lt;li&gt;Have some experience contributing to empirical AI research projects&lt;/li&gt;\n&lt;li&gt;Have some familiarity with technical AI safety research&lt;/li&gt;\n&lt;li&gt;Prefer fast-moving collaborative projects to extensive solo efforts&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Care about the impacts of AI&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;Strong candidates may also:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have experience authoring research papers in machine learning, NLP, or AI safety&lt;/li&gt;\n&lt;li&gt;Have experience with LLMs&lt;/li&gt;\n&lt;li&gt;Have experience with reinforcement learning&lt;/li&gt;\n&lt;li&gt;Have experience with Kubernetes clusters and complex shared codebases&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;Candidates need not have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;100% of the skills needed to perform the job&lt;/li&gt;\n&lt;li&gt;Formal certifications or education credentials&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4631822008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "[Expression of Interest] Research Scientist/Engineer, Honesty",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4532887008",
    "job_posted_at_datetime_utc": "2026-01-15T18:51:00-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As a Research Scientist/Engineer focused on honesty within the Finetuning Alignment team, you'll spearhead the development of techniques to minimize hallucinations and enhance truthfulness in language models. Your work will focus on creating robust systems that are accurate and reflect their true levels of confidence across all domains, and that work to avoid being deceptive or misleading. Your work will be critical for ensuring our models maintain high standards of accuracy and honesty across diverse domains. Note: The team is based in New York and so we have a preference for candidates who can be based in New York. For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year Responsibilities: Design and implement novel data curation pipelines to identify, verify, and filter training data for accuracy given the model’s knowledge Develop specialized classifiers to detect potential hallucinations or miscalibrated claims made by the model Create and maintain comprehensive honesty benchmarks and evaluation frameworks Implement techniques to ground model outputs in verified information, such as search and retrieval-augmented generation (RAG) systems Design and deploy human feedback collection specifically for identifying and correcting miscalibrated responses Design and implement prompting pipelines to generate data that improves model accuracy and honesty Develop and test novel RL environments that reward truthful outputs and penalize fabricated claims Create tools to help human evaluators efficiently assess model outputs for accuracy You may be a good fit if you: Have an MS/PhD in Computer Science, ML, or related field Possess strong programming skills in Python Have industry experience with language model finetuning and classifier training Show proficiency in experimental design and statistical analysis for measuring improvements in calibration and accuracy Care about AI safety and the accuracy and honesty of both current and future AI systems Have experience in data science or the creation and curation of datasets for finetuning LLMs An understanding of various metrics of uncertainty, calibration, and truthfulness in model outputs Strong candidates may also have: Published work on hallucination prevention, factual grounding, or knowledge integration in language models Experience with fact-grounding techniques Background in developing confidence estimation or calibration methods for ML models A track record of creating and maintaining factual knowledge bases Familiarity with RLHF specifically applied to improving model truthfulness Worked with crowd-sourcing platforms and human feedback collection systems Experience developing evaluations of model accuracy or hallucinations Join us in our mission to ensure advanced AI systems behave reliably and ethically while staying aligned with human values. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4532887008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4532887008",
    "title": "[Expression of Interest] Research Scientist/Engineer, Honesty",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA",
    "locations": [
      "New York City, NY; San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4532887008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:51:00-05:00",
    "fetched_at": "2026-01-19T19:10:07.739Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&amp;nbsp;&lt;/h2&gt;\n&lt;p&gt;As a Research Scientist/Engineer focused on honesty within the Finetuning Alignment team, you&#39;ll spearhead the development of techniques to minimize hallucinations and enhance truthfulness in language models. Your work will focus on creating robust systems that are accurate and reflect their true levels of confidence across all domains, and that work to avoid being deceptive or misleading. Your work will be critical for ensuring our models maintain high standards of accuracy and honesty across diverse domains.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: The team is based in New York and so we have a preference for candidates who can be based in New York. &lt;/em&gt;&lt;em&gt;For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement novel data curation pipelines to identify, verify, and filter training data for accuracy given the model’s knowledge&lt;/li&gt;\n&lt;li&gt;Develop specialized classifiers to detect potential hallucinations or miscalibrated claims made by the model&lt;/li&gt;\n&lt;li&gt;Create and maintain comprehensive honesty benchmarks and evaluation frameworks&lt;/li&gt;\n&lt;li&gt;Implement techniques to ground model outputs in verified information, such as search and retrieval-augmented generation (RAG) systems&lt;/li&gt;\n&lt;li&gt;Design and deploy human feedback collection specifically for identifying and correcting miscalibrated responses&lt;/li&gt;\n&lt;li&gt;Design and implement prompting pipelines to generate data that improves model accuracy and honesty&lt;/li&gt;\n&lt;li&gt;Develop and test novel RL environments that reward truthful outputs and penalize fabricated claims&lt;/li&gt;\n&lt;li&gt;Create tools to help human evaluators efficiently assess model outputs for accuracy&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have an MS/PhD in Computer Science, ML, or related field&lt;/li&gt;\n&lt;li&gt;Possess strong programming skills in Python&lt;/li&gt;\n&lt;li&gt;Have industry experience with language model finetuning and classifier training&lt;/li&gt;\n&lt;li&gt;Show proficiency in experimental design and statistical analysis for measuring improvements in calibration and accuracy&lt;/li&gt;\n&lt;li&gt;Care about AI safety and the accuracy and honesty of both current and future AI systems&lt;/li&gt;\n&lt;li&gt;Have experience in data science or the creation and curation of datasets for finetuning LLMs&lt;/li&gt;\n&lt;li&gt;An understanding of various metrics of uncertainty, calibration, and truthfulness in model outputs&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Published work on hallucination prevention, factual grounding, or knowledge integration in language models&lt;/li&gt;\n&lt;li&gt;Experience with fact-grounding techniques&lt;/li&gt;\n&lt;li&gt;Background in developing confidence estimation or calibration methods for ML models&lt;/li&gt;\n&lt;li&gt;A track record of creating and maintaining factual knowledge bases&lt;/li&gt;\n&lt;li&gt;Familiarity with RLHF specifically applied to improving model truthfulness&lt;/li&gt;\n&lt;li&gt;Worked with crowd-sourcing platforms and human feedback collection systems&lt;/li&gt;\n&lt;li&gt;Experience developing evaluations of model accuracy or hallucinations&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Join us in our mission to ensure advanced AI systems behave reliably and ethically while staying aligned with human values.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4532887008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "[Expression of Interest] Research Scientist/Engineer, Alignment Finetuning",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4520279008",
    "job_posted_at_datetime_utc": "2026-01-15T18:50:19-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As a Research Scientist/Engineer on the Alignment Finetuning team at Anthropic, you'll lead the development and implementation of techniques aimed at training language models that are more aligned with human values: that demonstrate better moral reasoning, improved honesty, and good character. You'll work to develop novel finetuning techniques and to use these to demonstrably improve model behavior. Note: For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year Responsibilities: Develop and implement novel finetuning techniques using synthetic data generation and advanced training pipelines Use these to train models to have better alignment properties including honesty, character, and harmlessness Create and maintain evaluation frameworks to measure alignment properties in models Collaborate across teams to integrate alignment improvements into production models Develop processes to help automate and scale the work of the team You may be a good fit if you: Have an MS/PhD in Computer Science, ML, or related field, or equivalent experience Possess strong programming skills, especially in Python Have experience with ML model training and experimentation Have a track record of implementing ML research Demonstrate strong analytical skills for interpreting experimental results Have experience with ML metrics and evaluation frameworks Excel at turning research ideas into working code Can identify and resolve practical implementation challenges Strong candidates may also have: Experience with language model finetuning Background in AI alignment research Published work in ML or alignment Experience with synthetic data generation Familiarity with techniques like RLHF, constitutional AI, and reward modeling Track record of designing and implementing novel training approaches Experience with model behavior evaluation and improvement The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4520279008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4520279008",
    "title": "[Expression of Interest] Research Scientist/Engineer, Alignment Finetuning",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4520279008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:50:19-05:00",
    "fetched_at": "2026-01-19T19:10:07.739Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Research Scientist/Engineer on the Alignment Finetuning team at Anthropic, you&#39;ll lead the development and implementation of techniques aimed at training language models that are more aligned with human values: that demonstrate better moral reasoning, improved honesty, and good character. You&#39;ll work to develop novel finetuning techniques and to use these to demonstrably improve model behavior.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and implement novel finetuning techniques using synthetic data generation and advanced training pipelines&lt;/li&gt;\n&lt;li&gt;Use these to train models to have better alignment properties including honesty, character, and harmlessness&lt;/li&gt;\n&lt;li&gt;Create and maintain evaluation frameworks to measure alignment properties in models&lt;/li&gt;\n&lt;li&gt;Collaborate across teams to integrate alignment improvements into production models&lt;/li&gt;\n&lt;li&gt;Develop processes to help automate and scale the work of the team&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have an MS/PhD in Computer Science, ML, or related field, or equivalent experience&lt;/li&gt;\n&lt;li&gt;Possess strong programming skills, especially in Python&lt;/li&gt;\n&lt;li&gt;Have experience with ML model training and experimentation&lt;/li&gt;\n&lt;li&gt;Have a track record of implementing ML research&lt;/li&gt;\n&lt;li&gt;Demonstrate strong analytical skills for interpreting experimental results&lt;/li&gt;\n&lt;li&gt;Have experience with ML metrics and evaluation frameworks&lt;/li&gt;\n&lt;li&gt;Excel at turning research ideas into working code&lt;/li&gt;\n&lt;li&gt;Can identify and resolve practical implementation challenges&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with language model finetuning&lt;/li&gt;\n&lt;li&gt;Background in AI alignment research&lt;/li&gt;\n&lt;li&gt;Published work in ML or alignment&lt;/li&gt;\n&lt;li&gt;Experience with synthetic data generation&lt;/li&gt;\n&lt;li&gt;Familiarity with techniques like RLHF, constitutional AI, and reward modeling&lt;/li&gt;\n&lt;li&gt;Track record of designing and implementing novel training approaches&lt;/li&gt;\n&lt;li&gt;Experience with model behavior evaluation and improvement&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4520279008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer / Research Scientist, Biology & Life Sciences",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4924308008",
    "job_posted_at_datetime_utc": "2026-01-15T18:48:40-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role We're seeking an exceptional Research Engineer / Research Scientist to join our Life Science team at Anthropic. Our team is organized around the north star goal of accelerating progress in the life sciences, from early discovery through translation, by an order of magnitude. Our team likes to think across the whole model stack. In this role, you'll combine your deep expertise in biology with machine learning engineering to develop novel evaluation frameworks and training strategies that push the frontier of what AI can achieve in biology. As a founding member of our team, you'll work at the intersection of cutting-edge AI and the biological sciences, developing rigorous methods to measure and improve model performance on complex scientific tasks. You'll collaborate closely with world-class researchers and engineers to build AI systems that can engage in all phases of research and development, while maintaining our commitment to safety and beneficial impact. Responsibilities: Design and implement evaluation methodologies for assessing AI model capabilities relevant to biological research and applications Develop and execute strategies to systematically improve model performance on scientific tasks Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery Collaborate with domain experts and partners to establish benchmarks and gather high-quality data Translate between biological domain knowledge and machine learning objectives You may be a good fit if you: Have 8+ years of machine learning experience, with demonstrated ability to train and evaluate large language models Have 5+ years of hands-on experience in life sciences R&D, with deep expertise in areas such as molecular biology, drug discovery, or computational biology Have a track record of bridging biological domain knowledge with computational approaches to solve real scientific problems Are proficient in Python and familiar with modern ML development practices Are comfortable navigating ambiguity and developing solutions in rapidly evolving research environments Can work independently while maintaining strong collaboration with cross-functional teams Are results-oriented, with a bias towards flexibility and impact Thrive in a fast-paced research environment where you balance rigorous scientific standards with rapid iteration Are passionate about using AI to accelerate scientific discovery while maintaining high ethical standards Have experience managing data pipelines and working with large-scale biological datasets Strong candidates may have: Ph.D. in a biological science (molecular biology, biochemistry, computational biology), in Machine Learning, or in a related field, or equivalent industry experience Published research or practical experience in scientific AI applications or long-horizon reasoning A history working on Reinforcement Learning and/or Pretraining Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing) Experience with modern machine learning techniques and model training methodologies Familiarity with biological databases (UniProt, GenBank, PDB) and computational biology tools Experience in drug discovery, including computational chemistry or structure-based design Knowledge of regulatory requirements for therapeutic development or clinical research Contributions to open-source scientific software or databases This role offers a unique opportunity to shape how AI transforms biological research. You'll work with some of the world's best AI researchers while tackling problems that matter deeply for human health and scientific understanding. If you're excited about using your expertise to guide the development of transformative AI systems, we want to hear from you. Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$280,000 - $350,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4924308008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4924308008",
    "title": "Research Engineer / Research Scientist, Biology & Life Sciences",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4924308008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:48:40-05:00",
    "fetched_at": "2026-01-19T19:10:07.740Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We&#39;re seeking an exceptional Research Engineer / Research Scientist to join our Life Science team at Anthropic. Our team is organized around the north star goal of accelerating progress in the life sciences, from early discovery through translation, by an order of magnitude. Our team likes to think across the whole model stack. In this role, you&#39;ll combine your deep expertise in biology with machine learning engineering to develop novel evaluation frameworks and training strategies that push the frontier of what AI can achieve in biology.&lt;/p&gt;\n&lt;p&gt;As a founding member of our team, you&#39;ll work at the intersection of cutting-edge AI and the biological sciences, developing rigorous methods to measure and improve model performance on complex scientific tasks. You&#39;ll collaborate closely with world-class researchers and engineers to build AI systems that can engage in all phases of research and development, while maintaining our commitment to safety and beneficial impact.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement evaluation methodologies for assessing AI model capabilities relevant to biological research and applications&lt;/li&gt;\n&lt;li&gt;Develop and execute strategies to systematically improve model performance on scientific tasks&lt;/li&gt;\n&lt;li&gt;Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery&lt;/li&gt;\n&lt;li&gt;Collaborate with domain experts and partners to establish benchmarks and gather high-quality data&lt;/li&gt;\n&lt;li&gt;Translate between biological domain knowledge and machine learning objectives&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 8+ years of machine learning experience, with demonstrated ability to train and evaluate large language models&lt;/li&gt;\n&lt;li&gt;Have 5+ years of hands-on experience in life sciences R&amp;amp;D, with deep expertise in areas such as molecular biology, drug discovery, or computational biology&lt;/li&gt;\n&lt;li&gt;Have a track record of bridging biological domain knowledge with computational approaches to solve real scientific problems&lt;/li&gt;\n&lt;li&gt;Are proficient in Python and familiar with modern ML development practices&lt;/li&gt;\n&lt;li&gt;Are comfortable navigating ambiguity and developing solutions in rapidly evolving research environments&lt;/li&gt;\n&lt;li&gt;Can work independently while maintaining strong collaboration with cross-functional teams&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Thrive in a fast-paced research environment where you balance rigorous scientific standards with rapid iteration&lt;/li&gt;\n&lt;li&gt;Are passionate about using AI to accelerate scientific discovery while maintaining high ethical standards&lt;/li&gt;\n&lt;li&gt;Have experience managing data pipelines and working with large-scale biological datasets&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ph.D. in a biological science (molecular biology, biochemistry, computational biology), in Machine Learning, or in a related field, or equivalent industry experience&lt;/li&gt;\n&lt;li&gt;Published research or practical experience in scientific AI applications or long-horizon reasoning&lt;/li&gt;\n&lt;li&gt;A history working on Reinforcement Learning and/or Pretraining&lt;/li&gt;\n&lt;li&gt;Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing)&lt;/li&gt;\n&lt;li&gt;Experience with modern machine learning techniques and model training methodologies&lt;/li&gt;\n&lt;li&gt;Familiarity with biological databases (UniProt, GenBank, PDB) and computational biology tools&lt;/li&gt;\n&lt;li&gt;Experience in drug discovery, including computational chemistry or structure-based design&lt;/li&gt;\n&lt;li&gt;Knowledge of regulatory requirements for therapeutic development or clinical research&lt;/li&gt;\n&lt;li&gt;Contributions to open-source scientific software or databases&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;This role offers a unique opportunity to shape how AI transforms biological research. You&#39;ll work with some of the world&#39;s best AI researchers while tackling problems that matter deeply for human health and scientific understanding. If you&#39;re excited about using your expertise to guide the development of transformative AI systems, we want to hear from you.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$280,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$350,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4924308008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Staff Machine Learning Engineer, Virtual Collaborator",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA; Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4946308008",
    "job_posted_at_datetime_utc": "2026-01-15T18:48:02-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role We are looking for a Machine Learning Engineer to help us train Claude specifically for virtual collaborator workflows. While Claude excels at general tasks, a lot of knowledge work requires targeted training on real organizational data and workflows. Your job will be to design and implement reinforcement learning environments that transform Claude into the best virtual collaborator, training on everything from navigating internal knowledge to creating financial models. Responsibilities: Designing and implementing reinforcement learning pipelines specifically targeted at virtual collaborator use cases (productivity, organizational navigation, vertical domains) Building and scaling our data creation platform for generating high-quality, open-ended tasks with domain experts and crowdworkers Integrating real organizational data to create authentic training environments Developing robust rubric-based evaluation systems that maintain quality while avoiding reward hacking Training Claude on advanced document manipulation, including understanding, enhancing, and co-creating Partnering directly with product teams to ensure training aligns with shipped features You may be a good fit if you: Are a very experienced Python programmer who can quickly produce reliable, high quality code that your teammates love using Have strong machine learning experience Thrive at the intersection of research and product, with a pragmatic approach to solving real-world problems Are comfortable with ambiguity and can balance research rigor with shipping deadlines Enjoy collaborating across multiple teams (data operations, model training, product) Can context-switch between research problems and product engineering tasks Care about making AI genuinely helpful for everyday enterprise workflows Strong candidates may also have experience with: Building human-in-the-loop training systems or crowdsourcing platforms Working with enterprise tools and APIs (Google Workspace, Microsoft Office, Slack, etc.) Developing evaluation frameworks for open-ended tasks Domain expertise in finance, legal, or healthcare workflows Creating scalable data pipelines with quality control mechanisms Reward modeling and preventing reward hacking in RL systems Translating product requirements into technical training objectives Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$500,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4946308008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4946308008",
    "title": "Staff Machine Learning Engineer, Virtual Collaborator",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA; Seattle, WA",
    "locations": [
      "New York City, NY; San Francisco, CA; Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4946308008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:48:02-05:00",
    "fetched_at": "2026-01-19T19:10:07.740Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;We are looking for a Machine Learning Engineer to help us train Claude specifically for virtual collaborator workflows. While Claude excels at general tasks, a lot of knowledge work requires targeted training on real organizational data and workflows. Your job will be to design and implement reinforcement learning environments that transform Claude into the best virtual collaborator, training on everything from navigating internal knowledge to creating financial models.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Designing and implementing reinforcement learning pipelines specifically targeted at virtual collaborator use cases (productivity, organizational navigation, vertical domains)&lt;/li&gt;\n&lt;li&gt;Building and scaling our data creation platform for generating high-quality, open-ended tasks with domain experts and crowdworkers Integrating real organizational data to create authentic training environments&lt;/li&gt;\n&lt;li&gt;Developing robust rubric-based evaluation systems that maintain quality while avoiding reward hacking&lt;/li&gt;\n&lt;li&gt;Training Claude on advanced document manipulation, including understanding, enhancing, and co-creating&lt;/li&gt;\n&lt;li&gt;Partnering directly with product teams to ensure training aligns with shipped features&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Are a very experienced Python programmer who can quickly produce reliable, high quality code that your teammates love using&lt;/li&gt;\n&lt;li&gt;Have strong machine learning experience&lt;/li&gt;\n&lt;li&gt;Thrive at the intersection of research and product, with a pragmatic approach to solving real-world problems&lt;/li&gt;\n&lt;li&gt;Are comfortable with ambiguity and can balance research rigor with shipping deadlines&lt;/li&gt;\n&lt;li&gt;Enjoy collaborating across multiple teams (data operations, model training, product)&lt;/li&gt;\n&lt;li&gt;Can context-switch between research problems and product engineering tasks&lt;/li&gt;\n&lt;li&gt;Care about making AI genuinely helpful for everyday enterprise workflows&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Building human-in-the-loop training systems or crowdsourcing platforms&lt;/li&gt;\n&lt;li&gt;Working with enterprise tools and APIs (Google Workspace, Microsoft Office, Slack, etc.)&lt;/li&gt;\n&lt;li&gt;Developing evaluation frameworks for open-ended tasks&lt;/li&gt;\n&lt;li&gt;Domain expertise in finance, legal, or healthcare workflows&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Creating scalable data pipelines with quality control mechanisms&lt;/li&gt;\n&lt;li&gt;Reward modeling and preventing reward hacking in RL systems&lt;/li&gt;\n&lt;li&gt;Translating product requirements into technical training objectives&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$500,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4946308008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Developer Operations Analyst",
    "employer_name": "discord",
    "job_city": "San Francisco Bay Area",
    "job_apply_link": "https://job-boards.greenhouse.io/discord/jobs/8330419002",
    "job_posted_at_datetime_utc": "2026-01-14T16:30:07-05:00",
    "job_description": "Discord is used by over 200 million people every month for many different reasons, but there’s one thing that nearly everyone does on our platform: play video games. Over 90% of our users play games, spending a combined 1.5 billion hours playing thousands of unique titles on Discord each month. Discord plays a uniquely important role in the future of gaming. We are focused on making it easier and more fun for people to talk and hang out before, during, and after playing games.About the Role Join Discord's Developer Operations team as our second analytics hire. Our team helps game developers understand how building communities on Discord improves their games' success. You'll provide the data-driven insights that prove Discord's impact on game performance, supporting our operations team with analytics for beta launches, SDK integrations, and partnership decisions. You'll build datasets from scratch, create dashboards, and work cross-functionally with product, data engineering, and data science teams. Your work directly influences how Discord demonstrates value to developers and shapes our gaming ecosystem strategy. This role reports to Analytics Lead for Developer Operations. What you'll be doing: Build net-new analytics datasets by aggregating data across multiple sources, translating business questions into measurable metrics and reusable data models Assess Discord SDK impact on games by analyzing how Discord's social features drive player retention, engagement, and monetization Own end-to-end analytics from requirements gathering through SQL-based analysis to delivering stakeholder-ready dashboards in Looker and Mode Support high-volume ad hoc analytics requests for developer conversations, SDK integrations, and partnership decisions Collaborate with product managers, data engineers, and data scientists on strategic analytics initiatives Create self-service analytics solutions that enable the DBO team to access insights independently What you should have: Analytics Infrastructure Building: 3+ years experience defining KPIs and building new data points by aggregating datasets across multiple sources. Must demonstrate ability to translate business questions into measurable metrics and create reusable data models. End-to-End Analytics Execution: Proven track record taking analytics vision from concept to implementation - including data point creation, SQL-based analysis, and stakeholder-ready visualizations. Should be comfortable owning the full lifecycle from requirements gathering to dashboard delivery. Analytics Foundation: 2+ years hands-on experience with live ops analytics (retention, engagement, monetization metrics) for gaming or large-scale live products (social platforms, streaming apps, etc.). Understanding of user lifecycle analytics and ability to connect product features to performance outcomes. Technical SQL Proficiency: Strong SQL skills for complex data manipulation including joins, CTEs, window functions, and aggregations. Ability to write efficient, well-documented queries that others can build upon. Gaming or Live Product Experience: Background in analyzing large-scale live products with millions of daily active users, including games, social platforms, and consumer applications. Experienced in user segmentation, behavioral trend analysis, and engagement measurement at scale. Experience with data visualization tools (Looker, Mode, Tableau) Bonus Points: Familiarity with gaming SDKs, APIs, or developer platforms Background in game analytics or live operations for apps ML-Enhanced Data Aggregation: Experience using ML models to classify and tag unstructured data (e.g., chat sentiment, topic categorization), then aggregating these enriched labels with SQL datasets to generate behavioral insights and community health metrics San Francisco Bay Area: Candidates must reside in or be willing to relocate to the San Francisco Bay Area (Alameda, Contra Costa, Marin, Napa, San Francisco, San Mateo, Santa Clara, Solano, and Sonoma counties). Relocation assistance may be available. For this role, the Hiring Manager would like folks to be in the office 3 days a week. The US base salary range for this full-time position is $156,000 - $175,500 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.Why Discord? Discord plays a uniquely important role in the future of gaming. We're a multiplatform, multigenerational and multiplayer platform that helps people deepen their friendships around games and shared interests. We believe games give us a way to have fun with our favorite people, whether listening to music together or grinding in competitive matches for diamond rank. Join us in our mission! Your future is just a click away! Discord is committed to inclusion and providing reasonable accommodations during the interview process. We want you to feel set up for success, so if you are in need of reasonable accommodations, please let your recruiter know. Please see our Applicant and Candidate Privacy Policy for details regarding Discord’s collection and usage of personal information relating to the application and recruitment process by clicking HERE.",
    "id": "job-boards-greenhouse-io-discord-jobs-8330419002",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "8330419002",
    "title": "Developer Operations Analyst",
    "company_name": "discord",
    "company_slug": "discord",
    "location": "San Francisco Bay Area",
    "locations": [
      "San Francisco Bay Area"
    ],
    "url": "https://job-boards.greenhouse.io/discord/jobs/8330419002",
    "departments": [
      "Customer Success & Ops"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T16:30:07-05:00",
    "fetched_at": "2026-01-19T19:10:08.551Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;p&gt;Discord is used by over 200 million people every month for many different reasons, but there’s one thing that nearly everyone does on our platform:&lt;strong&gt; play video games.&lt;/strong&gt; Over 90% of our users play games, spending a combined 1.5 billion hours playing thousands of unique titles on Discord each month. Discord plays a uniquely important role in the future of gaming. We are focused on making it easier and more fun for people to talk and hang out before, during, and after playing games.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Join Discord&#39;s Developer Operations team as our second analytics hire. Our team helps game developers understand how building communities on Discord improves their games&#39; success. You&#39;ll provide the data-driven insights that prove Discord&#39;s impact on game performance, supporting our operations team with analytics for beta launches, SDK integrations, and partnership decisions.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;You&#39;ll build datasets from scratch, create dashboards, and work cross-functionally with product, data engineering, and data science teams. Your work directly influences how Discord demonstrates value to developers and shapes our gaming ecosystem strategy. This role reports to Analytics Lead for Developer Operations.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;What you&#39;ll be doing:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Build net-new analytics datasets by aggregating data across multiple sources, translating business questions into measurable metrics and reusable data models&lt;/li&gt;\n&lt;li&gt;Assess Discord SDK impact on games by analyzing how Discord&#39;s social features drive player retention, engagement, and monetization&lt;/li&gt;\n&lt;li&gt;Own end-to-end analytics from requirements gathering through SQL-based analysis to delivering stakeholder-ready dashboards in Looker and Mode&lt;/li&gt;\n&lt;li&gt;Support high-volume ad hoc analytics requests for developer conversations, SDK integrations, and partnership decisions&lt;/li&gt;\n&lt;li&gt;Collaborate with product managers, data engineers, and data scientists on strategic analytics initiatives&lt;/li&gt;\n&lt;li&gt;Create self-service analytics solutions that enable the DBO team to access insights independently&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;What you should have:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Analytics Infrastructure Building:&lt;/strong&gt; 3+ years experience defining KPIs and building new data points by aggregating datasets across multiple sources. Must demonstrate ability to translate business questions into measurable metrics and create reusable data models.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;End-to-End Analytics Execution:&lt;/strong&gt; Proven track record taking analytics vision from concept to implementation - including data point creation, SQL-based analysis, and stakeholder-ready visualizations. Should be comfortable owning the full lifecycle from requirements gathering to dashboard delivery.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Analytics Foundation:&lt;/strong&gt; 2+ years hands-on experience with live ops analytics (retention, engagement, monetization metrics) for gaming or large-scale live products (social platforms, streaming apps, etc.). Understanding of user lifecycle analytics and ability to connect product features to performance outcomes.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Technical SQL Proficiency:&lt;/strong&gt; Strong SQL skills for complex data manipulation including joins, CTEs, window functions, and aggregations. Ability to write efficient, well-documented queries that others can build upon.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Gaming or Live Product Experience:&lt;/strong&gt; Background in analyzing large-scale live products with millions of daily active users, including games, social platforms, and consumer applications. Experienced in user segmentation, behavioral trend analysis, and engagement measurement at scale.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Experience with data visualization tools &lt;/strong&gt;(Looker, Mode, Tableau)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Bonus Points:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Familiarity with gaming SDKs, APIs, or developer platforms&lt;/li&gt;\n&lt;li&gt;Background in game analytics or live operations for apps&lt;/li&gt;\n&lt;li&gt;ML-Enhanced Data Aggregation: Experience using ML models to classify and tag unstructured data (e.g., chat sentiment, topic categorization), then aggregating these enriched labels with SQL datasets to generate behavioral insights and community health metrics&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;San Francisco Bay Area: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;Candidates must reside in or be willing to relocate to the San Francisco Bay Area (Alameda, Contra Costa, Marin, Napa, San Francisco, San Mateo, Santa Clara, Solano, and Sonoma counties). Relocation assistance may be available. &lt;/em&gt;&lt;em&gt;For this role, the Hiring Manager would like folks to be in the office &lt;/em&gt;&lt;strong&gt;&lt;em&gt;3&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; &lt;/em&gt;&lt;strong&gt;&lt;em&gt;days &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;a week.&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;The US base salary range for this full-time position is $156,000 - $175,500 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;p&gt;&lt;strong&gt;Why Discord?&amp;nbsp;&lt;/strong&gt;&lt;br&gt;&lt;br&gt;Discord plays a uniquely important role in the future of gaming. We&#39;re a multiplatform, multigenerational and multiplayer platform that helps people deepen their friendships around games and shared interests. We believe games give us a way to have fun with our favorite people, whether listening to music together or grinding in competitive matches for diamond rank. &lt;strong&gt;Join us in our mission! Your future is just a click away!&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Discord is committed to inclusion and providing reasonable accommodations during the interview process. &lt;/strong&gt;We want you to feel set up for success, so if you are in need of reasonable accommodations, please let your recruiter know.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;&lt;strong&gt;Please see our Applicant and Candidate Privacy Policy for details regarding Discord’s collection and usage of personal information relating to the application and recruitment process by clicking&amp;nbsp;&lt;a href=&quot;https://discord.com/terms/applicant-candidate-privacy-policy&quot;&gt;HERE.&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 8330419002
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Performance Engineer, GPU",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4926227008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: Pioneering the next generation of AI requires breakthrough innovations in GPU performance and systems engineering. As a GPU Performance Engineer, you'll architect and implement the foundational systems that power Claude and push the frontiers of what's possible with large language models. You'll be responsible for maximizing GPU utilization and performance at unprecedented scale, developing cutting-edge optimizations that directly enable new model capabilities and dramatically improve inference efficiency. Working at the intersection of hardware and software, you'll implement state-of-the-art techniques from custom kernel development to distributed system architectures. Your work will span the entire stack—from low-level tensor core optimizations to orchestrating thousands of GPUs in perfect synchronization. Strong candidates will have a track record of delivering transformative GPU performance improvements in production ML systems and will be excited to shape the future of AI infrastructure alongside world-class researchers and engineers. You might be a good fit if you: Have deep experience with GPU programming and optimization at scale Are impact-driven, passionate about delivering measurable performance breakthroughs Can navigate complex systems from hardware interfaces to high-level ML frameworks Enjoy collaborative problem-solving and pair programming Want to work on state-of-the-art language models with real-world impact Care about the societal impacts of your work Thrive in ambiguous environments where you define the path forward Strong candidates may also have experience with: GPU Kernel Development: CUDA, Triton, CUTLASS, Flash Attention, tensor core optimization ML Compilers & Frameworks: PyTorch/JAX internals, torch.compile, XLA, custom operators Performance Engineering: Kernel fusion, memory bandwidth optimization, profiling with Nsight Distributed Systems: NCCL, NVLink, collective communication, model parallelism Low-Precision: INT8/FP8 quantization, mixed-precision techniques Production Systems: Large-scale training infrastructure, fault tolerance, cluster orchestration Representative projects: Co-design attention mechanisms and algorithms for next-generation hardware architectures Develop custom kernels for emerging quantization formats and mixed-precision techniques Design distributed communication strategies for multi-node GPU clusters Optimize end-to-end training and inference pipelines for frontier language models Build performance modeling frameworks to predict and optimize GPU utilization Implement kernel fusion strategies to minimize memory bandwidth bottlenecks Create resilient systems for planet-scale distributed training infrastructure Profile and eliminate performance bottlenecks in production serving infrastructure Partner with hardware vendors to influence future accelerator capabilities and software stacks Deadline to apply: None. Applications will be reviewed on a rolling basis. The expected salary range for this position is:The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$315,000 - $560,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4926227008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4926227008",
    "title": "Performance Engineer, GPU",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4926227008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-19T19:10:07.739Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;Pioneering the next generation of AI requires breakthrough innovations in GPU performance and systems engineering. As a GPU Performance Engineer, you&#39;ll architect and implement the foundational systems that power Claude and push the frontiers of what&#39;s possible with large language models. You&#39;ll be responsible for maximizing GPU utilization and performance at unprecedented scale, developing cutting-edge optimizations that directly enable new model capabilities and dramatically improve inference efficiency.&lt;/p&gt;\n&lt;p&gt;Working at the intersection of hardware and software, you&#39;ll implement state-of-the-art techniques from custom kernel development to distributed system architectures. Your work will span the entire stack—from low-level tensor core optimizations to orchestrating thousands of GPUs in perfect synchronization.&lt;/p&gt;\n&lt;p&gt;Strong candidates will have a track record of delivering transformative GPU performance improvements in production ML systems and will be excited to shape the future of AI infrastructure alongside world-class researchers and engineers.&lt;/p&gt;\n&lt;h2&gt;You might be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have deep experience with GPU programming and optimization at scale&lt;/li&gt;\n&lt;li&gt;Are impact-driven, passionate about delivering measurable performance breakthroughs&lt;/li&gt;\n&lt;li&gt;Can navigate complex systems from hardware interfaces to high-level ML frameworks&lt;/li&gt;\n&lt;li&gt;Enjoy collaborative problem-solving and pair programming&lt;/li&gt;\n&lt;li&gt;Want to work on state-of-the-art language models with real-world impact&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;li&gt;Thrive in ambiguous environments where you define the path forward&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;GPU Kernel Development: CUDA, Triton, CUTLASS, Flash Attention, tensor core optimization&lt;/li&gt;\n&lt;li&gt;ML Compilers &amp;amp; Frameworks: PyTorch/JAX internals, torch.compile, XLA, custom operators&lt;/li&gt;\n&lt;li&gt;Performance Engineering: Kernel fusion, memory bandwidth optimization, profiling with Nsight&lt;/li&gt;\n&lt;li&gt;Distributed Systems: NCCL, NVLink, collective communication, model parallelism&lt;/li&gt;\n&lt;li&gt;Low-Precision: INT8/FP8 quantization, mixed-precision techniques&lt;/li&gt;\n&lt;li&gt;Production Systems: Large-scale training infrastructure, fault tolerance, cluster orchestration&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Co-design attention mechanisms and algorithms for next-generation hardware architectures&lt;/li&gt;\n&lt;li&gt;Develop custom kernels for emerging quantization formats and mixed-precision techniques&lt;/li&gt;\n&lt;li&gt;Design distributed communication strategies for multi-node GPU clusters&lt;/li&gt;\n&lt;li&gt;Optimize end-to-end training and inference pipelines for frontier language models&lt;/li&gt;\n&lt;li&gt;Build performance modeling frameworks to predict and optimize GPU utilization&lt;/li&gt;\n&lt;li&gt;Implement kernel fusion strategies to minimize memory bandwidth bottlenecks&lt;/li&gt;\n&lt;li&gt;Create resilient systems for planet-scale distributed training infrastructure&lt;/li&gt;\n&lt;li&gt;Profile and eliminate performance bottlenecks in production serving infrastructure&lt;/li&gt;\n&lt;li&gt;Partner with hardware vendors to influence future accelerator capabilities and software stacks&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&amp;nbsp;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;The expected salary range for this position is:&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$315,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$560,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4926227008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Enterprise Sales Executive",
    "employer_name": "datadog",
    "job_city": "San Francisco, California, USA",
    "job_apply_link": "https://careers.datadoghq.com/detail/7426752/?gh_jid=7426752",
    "job_posted_at_datetime_utc": "2026-01-14T10:42:52-05:00",
    "job_description": "Our SLED sales team works with a best-of-breed product that solves real problems for our customers. Sellers follow a well-defined methodology that helps them identify the customer's unique needs and clearly convey the value of the Datadog product. Whether you're looking to learn from the best or be the best, the Datadog sales team is dedicated to furthering personal development and team success.We are searching for an experienced SLED Sales Executive that has a real passion for technology and can deliver on bold revenue targets. As we continue to enter into bigger markets, and formalize our support for the Public Sector enterprise segment, this division within Datadog will blaze the path for organizational growth. This is a lucrative opportunity to break into new State, Local, and Education accounts within a rich territory, as well work with accounts who are in a hybrid state and transitioning to the cloud. At Datadog, we place value in our office culture - the relationships and collaboration it builds and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.What You’ll Do:Prospect into State, Local, and Education organizations while running an efficient sales processMaintain, build and own specific relationship maps for your territory including existing relationships and aspirational contactsDevelop a deep comprehension of customer's businessNegotiate favorable pricing and business terms with SLED enterprises by selling value and ROIHandle existing customer expectations while expanding reach and depth into assigned territoryDemonstrate resourcefulness when faced with challenges that defy easy solutionHave intuitive sense of necessary steps to close business and gain customer validationIdentify robust set of value drivers behind all opportunitiesEnsure high forecasting accuracy and consistencyWho You Are: Someone with 3+ years closing experience (mix of field selling within mid-market or enterprise)Driven and have met/exceeded direct sales goals of 800k+ and operated with an average deal size of $50k+Able to demonstrate methodology to prospect and build pipeline on your ownExperienced in working for an innovative tech company (SaaS, IT infrastructure or similar preferred)Experienced in selling into state, local, and education organizations with the ability to win new logosAble to sit up to 4 hours, traveling to and from client sitesAble to travel via auto, train or air up to 50% of the timeDatadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply.Benefits and Growth: High income earning opportunities based on self performanceNew hire stock equity (RSU) and employee stock purchase plan (ESPP)Continuous professional development, product training, and career pathing Sales training in MEDDIC and Command of the Message Intra-departmental mentor and buddy program for in-house networking An inclusive company culture, opportunity to join our Community GuildsGenerous and competitive medical benefits packageRetirement savings matchPet adoption and insurance programBenefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate's skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.The reasonably estimated yearly salary for this role at Datadog is:$110,000—$120,000 USDAbout Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog Learning Center.Equal Opportunity at Datadog:Datadog is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our Candidate Legal Notices for your reference. Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete this form. This form is for accommodation requests only and cannot be used to inquire about the status of applications. Privacy and AI Guidelines:Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice. For information on our AI policy, please visit Interviewing at Datadog AI Guidelines.Requisition ID: 943",
    "id": "careers-datadoghq-com-detail-7426752",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7426752",
    "title": "Enterprise Sales Executive",
    "company_name": "datadog",
    "company_slug": "datadog",
    "location": "San Francisco, California, USA",
    "locations": [
      "San Francisco, California, USA"
    ],
    "url": "https://careers.datadoghq.com/detail/7426752/?gh_jid=7426752",
    "departments": [
      "Enterprise Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T10:42:52-05:00",
    "fetched_at": "2026-01-19T19:10:12.363Z",
    "description": "&lt;p&gt;Our SLED sales team works with a best-of-breed product that solves real problems for our customers. Sellers follow a well-defined methodology that helps them identify the customer&#39;s unique needs and clearly convey the value of the Datadog product. Whether you&#39;re looking to learn from the best or be the best, the Datadog sales team is dedicated to furthering personal development and team success.&lt;/p&gt;\n&lt;p&gt;We are searching for an experienced SLED Sales Executive that has a real passion for technology and can deliver on bold revenue targets. As we continue to enter into bigger markets, and formalize our support for the Public Sector enterprise segment, this division within Datadog will blaze the path for organizational growth. This is a lucrative opportunity to break into new State, Local, and Education accounts within a rich territory, as well work with accounts who are in a hybrid state and transitioning to the cloud.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;At Datadog, we place value in our office culture - the relationships and collaboration it builds and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;What You’ll Do:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Prospect into State, Local, and Education organizations while running an efficient sales process&lt;/li&gt;\n&lt;li&gt;Maintain, build and own specific relationship maps for your territory including existing relationships and aspirational contacts&lt;/li&gt;\n&lt;li&gt;Develop a deep comprehension of customer&#39;s business&lt;/li&gt;\n&lt;li&gt;Negotiate favorable pricing and business terms with SLED enterprises by selling value and ROI&lt;/li&gt;\n&lt;li&gt;Handle existing customer expectations while expanding reach and depth into assigned territory&lt;/li&gt;\n&lt;li&gt;Demonstrate resourcefulness when faced with challenges that defy easy solution&lt;/li&gt;\n&lt;li&gt;Have intuitive sense of necessary steps to close business and gain customer validation&lt;/li&gt;\n&lt;li&gt;Identify robust set of value drivers behind all opportunities&lt;/li&gt;\n&lt;li&gt;Ensure high forecasting accuracy and consistency&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Who You Are:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Someone with 3+ years closing experience (mix of field selling within mid-market or enterprise)&lt;/li&gt;\n&lt;li&gt;Driven and have met/exceeded direct sales goals of 800k+ and operated with an average deal size of $50k+&lt;/li&gt;\n&lt;li&gt;Able to demonstrate methodology to prospect and build pipeline on your own&lt;/li&gt;\n&lt;li&gt;Experienced in working for an innovative tech company (SaaS, IT infrastructure or similar preferred)&lt;/li&gt;\n&lt;li&gt;Experienced in selling into state, local, and education organizations with the ability to win new logos&lt;/li&gt;\n&lt;li&gt;Able to sit up to 4 hours, traveling to and from client sites&lt;/li&gt;\n&lt;li&gt;Able to travel via auto, train or air up to 50% of the time&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;em&gt;Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That&#39;s okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply.&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Benefits and Growth:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;High income earning opportunities based on self performance&lt;/li&gt;\n&lt;li&gt;New hire stock equity (RSU) and employee stock purchase plan (ESPP)&lt;/li&gt;\n&lt;li&gt;Continuous professional development, product training, and career pathing&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Sales training in MEDDIC and Command of the Message&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Intra-departmental mentor and buddy program for in-house networking&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;An inclusive company culture, opportunity to join our Community Guilds&lt;/li&gt;\n&lt;li&gt;Generous and competitive medical benefits package&lt;/li&gt;\n&lt;li&gt;Retirement savings match&lt;/li&gt;\n&lt;li&gt;Pet adoption and insurance program&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;em&gt;Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate&#39;s skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;The reasonably estimated yearly salary for this role at Datadog is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$110,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$120,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;hr&gt;\n&lt;p&gt;&lt;strong&gt;About Datadog:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on &lt;a href=&quot;https://www.instagram.com/datadoghq/?hl=en&quot; target=&quot;_blank&quot;&gt;Instagram&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/company/datadog&quot; target=&quot;_blank&quot;&gt;LinkedIn,&lt;/a&gt; and &lt;a href=&quot;https://learn.datadoghq.com/&quot; target=&quot;_blank&quot;&gt;Datadog Learning Center. &lt;/a&gt;&lt;/p&gt;\n&lt;hr&gt;\n&lt;p data-renderer-start-pos=&quot;215&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Equal Opportunity at Datadog:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog is proud to offer &lt;a href=&quot;https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf&quot; target=&quot;_blank&quot;&gt;equal employment opportunity&lt;/a&gt; to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our &lt;a href=&quot;https://www.datadoghq.com/legal/candidate-legal-notices/&quot; target=&quot;_blank&quot;&gt;Candidate Legal Notices&lt;/a&gt; for your reference.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSeoJeduEZ2NdZF_65uZmWUrCM-zee7yADXX1s6Xr9zAGq8iKA/viewform&quot; target=&quot;_blank&quot;&gt;this form&lt;/a&gt;. This form is for accommodation requests only and cannot be used to inquire about the status of applications.&amp;nbsp;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Privacy and AI Guidelines:&lt;/strong&gt;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; data-sk=&quot;tooltip_parent&quot;&gt;Applicant and Candidate Privacy Notice&lt;/a&gt;. For information on our AI policy, please visit &lt;a href=&quot;https://www.datadoghq.com/legal/interviewing-at-datadog-ai-guidelines/&quot; target=&quot;_blank&quot;&gt;Interviewing at Datadog AI Guidelines&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7426752
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  }
]