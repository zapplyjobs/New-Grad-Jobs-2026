[
  {
    "job_title": "Research Engineer/Research Scientist, Audio",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5074815008",
    "job_posted_at_datetime_utc": "2026-01-31T18:39:33-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Anthropic’s Audio team pushes the boundaries of what's possible with audio with large language models. We care about making safe, steerable, reliable systems that can understand and generate speech and audio, prioritizing not only naturalness but also steerability and robustness. As a researcher on the Audio team, you'll work across the full stack of audio ML, developing audio codecs and representations, sourcing and synthesizing high quality audio data, training large-scale speech language models and large audio diffusion models, and developing novel architectures for incorporating continuous signals into LLMs. Our team focuses primarily but not exclusively on speech, building advanced steerable systems spanning end-to-end conversational systems, speech and audio understanding models, and speech synthesis capabilities. The team works closely with many collaborators across pretraining, finetuning, reinforcement learning, production inference, and product to get advanced audio technologies from early research to high impact real-world deployments. You may be a good fit if you: Have hands-on experience with training audio models, whether that's conversational speech-to-speech, speech translation, speech recognition, text-to-speech, diarization, codecs, or generative audio models Genuinely enjoy both research and engineering work, and you'd describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other Are comfortable working across abstraction levels, from signal processing fundamentals to large-scale model training and inference optimization Have deep expertise with JAX, PyTorch, or large-scale distributed training, and can debug performance issues across the full stack Thrive in fast-moving environments where the most important problem might shift as we learn more about what works Communicate clearly and collaborate effectively; audio touches many parts of our systems, so you'll work closely with teams across the company Are passionate about building conversational AI that feels natural, steerable, and safe Care about the societal impacts of voice AI and want to help shape how these systems are developed responsibly Strong candidates may also have experience with: Large language model pretraining and finetuning Training diffusion models for image and audio generation Reinforcement learning for large language models and diffusion models End-to-end system optimization, from performance benchmarking to kernel optimization GPUs, Kubernetes, PyTorch, or distributed training infrastructure Representative projects: Training state-of-the art neural audio codecs for 48 kHz stereo audio Developing novel algorithms for diffusion pretraining and reinforcement learning Scaling audio datasets to millions of hours of high quality audio Creating robust evaluation methodologies for hard-to-measure qualities such as naturalness or expressiveness Studying training dynamics of mixed audio-text language models Optimizing latency and inference throughput for deployed streaming audio systems The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5074815008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5074815008",
    "title": "Research Engineer/Research Scientist, Audio",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5074815008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-31T18:39:33-05:00",
    "fetched_at": "2026-02-01T18:23:02.264Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Anthropic’s Audio team pushes the boundaries of what&#39;s possible with audio with large language models. We care about making safe, steerable, reliable systems that can understand and generate speech and audio, prioritizing not only naturalness but also steerability and robustness. As a researcher on the Audio team, you&#39;ll work across the full stack of audio ML, developing audio codecs and representations, sourcing and synthesizing high quality audio data, training large-scale speech language models and large audio diffusion models, and developing novel architectures for incorporating continuous signals into LLMs.&lt;/p&gt;\n&lt;p&gt;Our team focuses primarily but not exclusively on speech, building advanced steerable systems spanning end-to-end conversational systems, speech and audio understanding models, and speech synthesis capabilities. The team works closely with many collaborators across pretraining, finetuning, reinforcement learning, production inference, and product to get advanced audio technologies from early research to high impact real-world deployments.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have hands-on experience with training audio models, whether that&#39;s conversational speech-to-speech, speech translation, speech recognition, text-to-speech, diarization, codecs, or generative audio models&lt;/li&gt;\n&lt;li&gt;Genuinely enjoy both research and engineering work, and you&#39;d describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other&lt;/li&gt;\n&lt;li&gt;Are comfortable working across abstraction levels, from signal processing fundamentals to large-scale model training and inference optimization&lt;/li&gt;\n&lt;li&gt;Have deep expertise with JAX, PyTorch, or large-scale distributed training, and can debug performance issues across the full stack&lt;/li&gt;\n&lt;li&gt;Thrive in fast-moving environments where the most important problem might shift as we learn more about what works&lt;/li&gt;\n&lt;li&gt;Communicate clearly and collaborate effectively; audio touches many parts of our systems, so you&#39;ll work closely with teams across the company&lt;/li&gt;\n&lt;li&gt;Are passionate about building conversational AI that feels natural, steerable, and safe&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of voice AI and want to help shape how these systems are developed responsibly&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Strong candidates may also have experience with:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Large language model pretraining and finetuning&lt;/li&gt;\n&lt;li&gt;Training diffusion models for image and audio generation&lt;/li&gt;\n&lt;li&gt;Reinforcement learning for large language models and diffusion models&lt;/li&gt;\n&lt;li&gt;End-to-end system optimization, from performance benchmarking to kernel optimization&lt;/li&gt;\n&lt;li&gt;GPUs, Kubernetes, PyTorch, or distributed training infrastructure&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Representative projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Training state-of-the art neural audio codecs for 48 kHz stereo audio&lt;/li&gt;\n&lt;li&gt;Developing novel algorithms for diffusion pretraining and reinforcement learning&lt;/li&gt;\n&lt;li&gt;Scaling audio datasets to millions of hours of high quality audio&lt;/li&gt;\n&lt;li&gt;Creating robust evaluation methodologies for hard-to-measure qualities such as naturalness or expressiveness&lt;/li&gt;\n&lt;li&gt;Studying training dynamics of mixed audio-text language models&lt;/li&gt;\n&lt;li&gt;Optimizing latency and inference throughput for deployed streaming audio systems&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5074815008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Manager, Customer Success",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4914907008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Manager of Customer Success at Anthropic, you'll be a pivotal front-line leader managing our Customer Success Managers who drive value across our entire product portfolio—including API, Claude.ai, and Claude Code. You'll directly coach and develop a team of 5-8 CSMs while maintaining strategic oversight of high-impact customer engagements. This role demands exceptional people leadership combined with deep product knowledge and customer success acumen to guide your team in maximizing customer value, driving consumption, and expanding our footprint across enterprise accounts. You'll be instrumental in building scalable CS processes, methodologies, and playbooks that will define how we grow and mature as an organization. Responsibilities: Directly manage and develop a team of 5-8 Customer Success Managers supporting strategic enterprise accounts across all Anthropic products (API, Claude.ai, Claude Code) Coach team members on customer success best practices, including change management and adoption strategies, value realization, and expansion methodologies across our product suite Drive team accountability to core CS metrics: expansion (consumption growth, cross-sell/upsell opportunity identification), customer health scores, retention (NRR), and customer satisfaction (CSAT) Join strategic customer engagements and escalations, demonstrating executive presence with C-level stakeholders at Fortune 500 companies Build and refine scalable CS processes including success planning frameworks, QBR templates, and expansion playbooks Partner closely with Sales to identify expansion opportunities, facilitate smooth handoffs, and ensure aligned account strategies Collaborate cross-functionally with Product, Engineering, and Marketing to advocate for customer needs and drive product adoption Contribute to hiring, onboarding, and training initiatives as the Customer Success organization scales Establish and nurture an AI-first, innovation-focused team culture, improving team processes and deepening team hands-on expertise Conduct regular 1:1s, performance reviews, and career development planning for direct reports Own portfolio-level planning and forecasting, including renewal risk mitigation and expansion pipeline development Serve as escalation point for at-risk accounts and complex customer situations within your team's portfolio Develop customer advocacy programs including case studies, testimonials, and reference architecture development Champion responsible AI deployment practices with customers and represent Anthropic's values in all customer interactions You may be a good fit if you have: 7+ years of experience in customer success, account management, or customer-facing roles, with 2+ years of front-line management experience Proven track record of managing and building customer success teams in SaaS, API, or AI/ML companies Experience managing customer portfolios at enterprise scale, including accounts with $1M-$100M+ annual contract values Strong understanding of both consumption-based and seat-based business models, with proven ability to drive adoption, expansion, and value realization across different pricing structures Technical fluency to understand AI/ML products, navigate technical conversations, and coach teams on product capabilities across multiple offerings Strong executive presence and ability to represent Anthropic with customer technical and business leaders Strong business acumen with ability to articulate value, calculate ROI, and drive customer business outcomes Ability to balance strategic thinking with tactical execution and context-switch between coaching, customer engagement, and operational planning Experience building CS processes, playbooks and operational frameworks, using data to drive team and customer outcomes Demonstrated ability to coach customer success professionals and systematically improve team performance against KPIs Track record of achieving team targets for expansion, retention and customer satisfaction Passion for responsible AI development and helping customers transform their businesses with cutting-edge technology The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$260,000 - $315,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4914907008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4914907008",
    "title": "Manager, Customer Success",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4914907008",
    "departments": [
      "Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T07:12:37.952Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Manager of Customer Success at Anthropic, you&#39;ll be a pivotal front-line leader managing our Customer Success Managers who drive value across our entire product portfolio—including API, Claude.ai, and Claude Code. You&#39;ll directly coach and develop a team of 5-8 CSMs while maintaining strategic oversight of high-impact customer engagements. This role demands exceptional people leadership combined with deep product knowledge and customer success acumen to guide your team in maximizing customer value, driving consumption, and expanding our footprint across enterprise accounts. You&#39;ll be instrumental in building scalable CS processes, methodologies, and playbooks that will define how we grow and mature as an organization.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Directly manage and develop a team of 5-8 Customer Success Managers supporting strategic enterprise accounts across all Anthropic products (API, Claude.ai, Claude Code)&lt;/li&gt;\n&lt;li&gt;Coach team members on customer success best practices, including change management and adoption strategies, value realization, and expansion methodologies across our product suite&lt;/li&gt;\n&lt;li&gt;Drive team accountability to core CS metrics: expansion (consumption growth, cross-sell/upsell opportunity identification), customer health scores, retention (NRR), and customer satisfaction (CSAT)&lt;/li&gt;\n&lt;li&gt;Join strategic customer engagements and escalations, demonstrating executive presence with C-level stakeholders at Fortune 500 companies&lt;/li&gt;\n&lt;li&gt;Build and refine scalable CS processes including success planning frameworks, QBR templates, and expansion playbooks&lt;/li&gt;\n&lt;li&gt;Partner closely with Sales to identify expansion opportunities, facilitate smooth handoffs, and ensure aligned account strategies&lt;/li&gt;\n&lt;li&gt;Collaborate cross-functionally with Product, Engineering, and Marketing to advocate for customer needs and drive product adoption&lt;/li&gt;\n&lt;li&gt;Contribute to hiring, onboarding, and training initiatives as the Customer Success organization scales&lt;/li&gt;\n&lt;li&gt;Establish and nurture an AI-first, innovation-focused team culture, improving team processes and deepening team hands-on expertise&lt;/li&gt;\n&lt;li&gt;Conduct regular 1:1s, performance reviews, and career development planning for direct reports&lt;/li&gt;\n&lt;li&gt;Own portfolio-level planning and forecasting, including renewal risk mitigation and expansion pipeline development&lt;/li&gt;\n&lt;li&gt;Serve as escalation point for at-risk accounts and complex customer situations within your team&#39;s portfolio&lt;/li&gt;\n&lt;li&gt;Develop customer advocacy programs including case studies, testimonials, and reference architecture development&lt;/li&gt;\n&lt;li&gt;Champion responsible AI deployment practices with customers and represent Anthropic&#39;s values in all customer interactions&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;7+ years of experience in customer success, account management, or customer-facing roles, with 2+ years of front-line management experience&lt;/li&gt;\n&lt;li&gt;Proven track record of managing and building customer success teams in SaaS, API, or AI/ML companies&lt;/li&gt;\n&lt;li&gt;Experience managing customer portfolios at enterprise scale, including accounts with $1M-$100M+ annual contract values&lt;/li&gt;\n&lt;li&gt;Strong understanding of both consumption-based and seat-based business models, with proven ability to drive adoption, expansion, and value realization across different pricing structures&lt;/li&gt;\n&lt;li&gt;Technical fluency to understand AI/ML products, navigate technical conversations, and coach teams on product capabilities across multiple offerings&lt;/li&gt;\n&lt;li&gt;Strong executive presence and ability to represent Anthropic with customer technical and business leaders&lt;/li&gt;\n&lt;li&gt;Strong business acumen with ability to articulate value, calculate ROI, and drive customer business outcomes&lt;/li&gt;\n&lt;li&gt;Ability to balance strategic thinking with tactical execution and context-switch between coaching, customer engagement, and operational planning&lt;/li&gt;\n&lt;li&gt;Experience building CS processes, playbooks and operational frameworks, using data to drive team and customer outcomes&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to coach customer success professionals and systematically improve team performance against KPIs&lt;/li&gt;\n&lt;li&gt;Track record of achieving team targets for expansion, retention and customer satisfaction&lt;/li&gt;\n&lt;li&gt;Passion for responsible AI development and helping customers transform their businesses with cutting-edge technology&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$260,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$315,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4914907008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Manager, Growth Account Executive",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4976328008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Manager on the Startups team at Anthropic, you'll lead a team of 5-10 Growth Account Executives responsible for driving expansion and retention across our fastest-growing startup customers. You'll build and develop a high-performing team while establishing the frameworks, processes, and best practices that enable them to help customers harness the transformative potential of safe, frontier AI. In this role, you'll be responsible for growing team revenue, driving optimal commercial outcomes, and ensuring Anthropic is building long-term partnerships with the world’s fastest growing AI native startups. Responsibilities: Lead, coach, and develop a team of 5-10 Startup Growth AEs, providing regular feedback and guidance to drive both individual and team performance Own team revenue targets, developing strategies to accelerate growth Build scalable frameworks and processes for deal negotiations, account planning, quarterly business reviews, and customer health monitoring Partner with Product, Marketing, and other GTM teams to identify and execute on strategic growth opportunities across the startup portfolio Regularly review customer health metrics and collaborate with team members to develop action plans for at-risk accounts Mentor team members in developing consultative sales skills, negotiation best practices, and technical understanding of AI applications Drive operational excellence through pipeline management, forecasting accuracy, and team productivity metrics Participate in strategic customer conversations and support Growth AEs in complex negotiations You may be a good fit if you have: 10+ years of experience in enterprise software sales or account management, with 3+ years leading sales teams Proven track record of consistently exceeding team revenue targets and developing high-performing account executives Strong understanding of the startup ecosystem and experience working with high-growth technology companies Deep expertise in strategic account planning and scaling account management processes in a fast-paced environment Strong analytical and problem-solving skills with a data-driven approach to decision making Excellence in cross-functional collaboration and stakeholder management Background in technical product sales, particularly in areas like APIs, infrastructure, or ML/AI solutions Demonstrated ability to coach and develop talent while maintaining high performance standards The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$360,000 - $435,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4976328008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4976328008",
    "title": "Manager, Growth Account Executive",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA",
    "locations": [
      "New York City, NY; San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4976328008",
    "departments": [
      "Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T07:12:37.952Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a Manager on the Startups team at Anthropic, you&#39;ll lead a team of 5-10 Growth Account Executives responsible for driving expansion and retention across our fastest-growing startup customers. You&#39;ll build and develop a high-performing team while establishing the frameworks, processes, and best practices that enable them to help customers harness the transformative potential of safe, frontier AI. In this role, you&#39;ll be responsible for growing team revenue, driving optimal commercial outcomes, and ensuring Anthropic is building long-term partnerships with the world’s fastest growing AI native startups.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Lead, coach, and develop a team of 5-10 Startup Growth AEs, providing regular feedback and guidance to drive both individual and team performance&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Own team revenue targets, developing strategies to accelerate growth&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Build scalable frameworks and processes for deal negotiations, account planning, quarterly business reviews, and customer health monitoring&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Partner with Product, Marketing, and other GTM teams to identify and execute on strategic growth opportunities across the startup portfolio&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Regularly review customer health metrics and collaborate with team members to develop action plans for at-risk accounts&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Mentor team members in developing consultative sales skills, negotiation best practices, and technical understanding of AI applications&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Drive operational excellence through pipeline management, forecasting accuracy, and team productivity metrics&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Participate in strategic customer conversations and support Growth AEs in complex negotiations&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;10+ years of experience in enterprise software sales or account management, with 3+ years leading sales teams&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Proven track record of consistently exceeding team revenue targets and developing high-performing account executives&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Strong understanding of the startup ecosystem and experience working with high-growth technology companies&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Deep expertise in strategic account planning and scaling account management processes in a fast-paced environment&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Strong analytical and problem-solving skills with a data-driven approach to decision making&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Excellence in cross-functional collaboration and stakeholder management&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Background in technical product sales, particularly in areas like APIs, infrastructure, or ML/AI solutions&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Demonstrated ability to coach and develop talent while maintaining high performance standards&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$360,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$435,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4976328008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Manager, IT Support & Operations",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5041319008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role We're looking for a Manager, IT Support & Operations to lead and transform our globally distributed IT support and operations function. You'll define the strategy, build the team, and design the systems that keep Ants productive and secure—24/7/365, around the world. This role goes beyond running operations: you'll evolve our support model from reactive to proactive, build self-service and automated support capabilities that scale, and establish IT as a strategic partner to the business. You'll partner closely with Security, People Operations, Workplace, and IT Engineering leadership to deliver an exceptional employee experience while maintaining the rigorous security posture our mission demands. Responsibilities: Define and execute the multi-year vision for IT Support & Operations, aligned with company growth Build, lead, and develop a high-performing, globally distributed team spanning IT Support and Operations functions Hire and develop managers and senior ICs who can scale with the organization Design and operate a 24/7/365 global support model that delivers fast, high-quality support across all time zones Own the IT Support & Operations budget and make strategic investment decisions Define and track key performance metrics—response time, resolution time, employee satisfaction, SLA compliance—and drive continuous improvement Build scalable systems for asset management, endpoint lifecycle, and SaaS administration Invest in automation and self-service to reduce ticket volume and improve employee experience at scale Collaborate with Workplace, People Ops, and other teams to support office operations and company events Manage vendor relationships and negotiate contracts for IT services and tools Travel occasionally to support global team members and office locations You may be a good fit if you have: 10+ years of experience in IT support and operations, with 5+ years leading globally distributed teams Track record of building or transforming IT operations at a fast-growing technology company Experience designing and operating follow-the-sun or 24/7 support models Experience managing managers and building organizational capability Strong familiarity with ITIL frameworks and IT service management best practices A security-first mindset with experience operating in high-security environments Comfort with ambiguity and rapidly shifting priorities in a fast-paced environment Excellent judgment and the ability to balance user experience with security requirements Strong communication skills and the ability to influence cross-functional leaders Budget ownership and vendor management experience Strong candidates may also have: Experience supporting AI/ML research environments or highly technical user bases Experience building self-service platforms or support automation programs Background in companies with significant security or compliance requirements (e.g., SOC 2, FedRAMP) Deadline to apply: None applications will be received on a rolling basis.The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$265,000 - $335,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5041319008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5041319008",
    "title": "Manager, IT Support & Operations",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5041319008",
    "departments": [
      "Security"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T07:12:37.952Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;About the Role&lt;/h2&gt;\n&lt;p&gt;We&#39;re looking for a Manager, IT Support &amp;amp; Operations to lead and transform our globally distributed IT support and operations function. You&#39;ll define the strategy, build the team, and design the systems that keep Ants productive and secure—24/7/365, around the world.&lt;/p&gt;\n&lt;p&gt;This role goes beyond running operations: you&#39;ll evolve our support model from reactive to proactive, build self-service and automated support capabilities that scale, and establish IT as a strategic partner to the business. You&#39;ll partner closely with Security, People Operations, Workplace, and IT Engineering leadership to deliver an exceptional employee experience while maintaining the rigorous security posture our mission demands.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Define and execute the multi-year vision for IT Support &amp;amp; Operations, aligned with company growth&lt;/li&gt;\n&lt;li&gt;Build, lead, and develop a high-performing, globally distributed team spanning IT Support and Operations functions&lt;/li&gt;\n&lt;li&gt;Hire and develop managers and senior ICs who can scale with the organization&lt;/li&gt;\n&lt;li&gt;Design and operate a 24/7/365 global support model that delivers fast, high-quality support across all time zones&lt;/li&gt;\n&lt;li&gt;Own the IT Support &amp;amp; Operations budget and make strategic investment decisions&lt;/li&gt;\n&lt;li&gt;Define and track key performance metrics—response time, resolution time, employee satisfaction, SLA compliance—and drive continuous improvement&lt;/li&gt;\n&lt;li&gt;Build scalable systems for asset management, endpoint lifecycle, and SaaS administration&lt;/li&gt;\n&lt;li&gt;Invest in automation and self-service to reduce ticket volume and improve employee experience at scale&lt;/li&gt;\n&lt;li&gt;Collaborate with Workplace, People Ops, and other teams to support office operations and company events&lt;/li&gt;\n&lt;li&gt;Manage vendor relationships and negotiate contracts for IT services and tools&lt;/li&gt;\n&lt;li&gt;Travel occasionally to support global team members and office locations&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;10+ years of experience in IT support and operations, with 5+ years leading globally distributed teams&lt;/li&gt;\n&lt;li&gt;Track record of building or transforming IT operations at a fast-growing technology company&lt;/li&gt;\n&lt;li&gt;Experience designing and operating follow-the-sun or 24/7 support models&lt;/li&gt;\n&lt;li&gt;Experience managing managers and building organizational capability&lt;/li&gt;\n&lt;li&gt;Strong familiarity with ITIL frameworks and IT service management best practices&lt;/li&gt;\n&lt;li&gt;A security-first mindset with experience operating in high-security environments&lt;/li&gt;\n&lt;li&gt;Comfort with ambiguity and rapidly shifting priorities in a fast-paced environment&lt;/li&gt;\n&lt;li&gt;Excellent judgment and the ability to balance user experience with security requirements&lt;/li&gt;\n&lt;li&gt;Strong communication skills and the ability to influence cross-functional leaders&lt;/li&gt;\n&lt;li&gt;Budget ownership and vendor management experience&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Strong candidates may also have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience supporting AI/ML research environments or highly technical user bases&lt;/li&gt;\n&lt;li&gt;Experience building self-service platforms or support automation programs&lt;/li&gt;\n&lt;li&gt;Background in companies with significant security or compliance requirements (e.g., SOC 2, FedRAMP)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None applications will be received on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$265,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$335,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5041319008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Manager of Associate Solutions Architecture, Applied AI ",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4947472008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role As the Manager of Associate Solutions Architects for Claude Code at Anthropic, you will build and lead a team dedicated to accelerating developer productivity through AI-powered coding tools. You'll be responsible for scaling the adoption of Claude Code across our enterprise customer base by developing talent, establishing best practices, and ensuring your team delivers exceptional technical enablement to engineering organizations. You'll lead a team of early-career Solutions Architects who serve as the technical bridge between Claude Code's capabilities and customer engineering teams. Your role combines hands-on technical leadership, team development, and strategic collaboration with Sales, Product, and Engineering to drive Claude Code's success in the market. This is a foundational role where you'll establish the playbook for how Associate SAs operate, build scalable enablement programs, and create a high-performing team culture. You'll be instrumental in helping early-career technical talent grow into trusted advisors for some of the world's most innovative engineering organizations. Responsibilities Team Leadership & Development Build, manage, and mentor a team of Associate Solutions Architects, providing technical coaching and career development Establish onboarding programs and skill development frameworks tailored for early-career technical talent Set clear goals and performance expectations, conducting regular reviews that promote growth and productivity Create a culture of continuous learning, knowledge sharing, and technical excellence Partner with recruiting to scale the team and build a diverse pipeline of technical talent Claude Code Specialization & Enablement Maintain deep expertise in Claude Code capabilities, integrations, developer workflows, and competitive positioning Develop and refine playbooks, demo scripts, technical content, and best practices for Claude Code engagements Establish standards for technical evaluations, proof-of-concept execution, and rollout strategies Build internal enablement programs to ensure team members are expert practitioners of Claude Code Stay current with developer tooling trends, IDE integrations, and AI-assisted development landscape Customer Success & Pre-Sales Excellence Guide your team in supporting high-value customer engagements, ensuring successful technical evaluations and adoption Personally engage with strategic accounts where senior technical leadership is needed Partner with Account Executives and senior Solutions Architects to drive expansion opportunities Ensure your team effectively identifies and builds technical champions within customer engineering organizations Monitor customer success metrics and iterate on engagement strategies based on outcomes Cross-Functional Collaboration Work closely with Product and Engineering teams to communicate customer feedback and influence product roadmap Partner with GTM leadership to align team activities with overall business objectives Collaborate with other SA leaders to share best practices and ensure consistent customer experience Contribute to thought leadership through technical content, webinars, and conference presentations Establish feedback loops between your team and product development to drive continuous improvement Process & Operations Build scalable processes for managing customer engagements, prioritizing opportunities, and measuring impact Establish metrics and reporting frameworks to track team performance and customer outcomes Create systems for knowledge management, ensuring best practices are documented and accessible Drive operational excellence while maintaining the flexibility needed for a fast-growing product area You may be a good fit if you have: Required Experience 5+ years of experience in solutions architecture, sales engineering, developer relations, or similar technical customer-facing roles 2+ years of people management experience, ideally managing early-career technical talent Deep hands-on expertise with Claude Code or similar AI coding assistants Strong software engineering background with experience across multiple programming languages and development environments Experience with technical sales cycles, customer discovery, proof-of-concept execution, and driving adoption Technical Skills Expertise in modern software development workflows, toolchains, CI/CD, and developer productivity Understanding of IDE integrations, code generation tools, and developer experience optimization Familiarity with large language models, prompt engineering, and AI-powered developer tools Ability to architect technical solutions and guide complex integrations Comfort with debugging, troubleshooting, and solving technical challenges in real-time Leadership & Communication Strong coaching and mentorship abilities with track record of developing technical talent Excellent communication skills with ability to explain complex concepts to both technical and non-technical audiences Experience building processes and best practices in relatively unstructured environments Comfortable operating in ambiguous, fast-moving environments with shifting priorities Executive presence with ability to represent Anthropic at customer executive meetings Mindset & Values Passion for developer productivity and the transformative potential of AI in software development Growth mindset with eagerness to learn and adapt alongside rapidly evolving technology Commitment to making powerful AI technology safe and beneficial for developers and organizations Collaborative approach with strong cross-functional partnership skills Data-driven decision making balanced with qualitative customer insights The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$270,000 - $270,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4947472008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4947472008",
    "title": "Manager of Associate Solutions Architecture, Applied AI ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA | New York City, NY",
    "locations": [
      "New York City, NY; San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4947472008",
    "departments": [
      "Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T07:12:37.952Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As the Manager of Associate Solutions Architects for Claude Code at Anthropic, you will build and lead a team dedicated to accelerating developer productivity through AI-powered coding tools. You&#39;ll be responsible for scaling the adoption of Claude Code across our enterprise customer base by developing talent, establishing best practices, and ensuring your team delivers exceptional technical enablement to engineering organizations.&lt;/p&gt;\n&lt;p&gt;You&#39;ll lead a team of early-career Solutions Architects who serve as the technical bridge between Claude Code&#39;s capabilities and customer engineering teams. Your role combines hands-on technical leadership, team development, and strategic collaboration with Sales, Product, and Engineering to drive Claude Code&#39;s success in the market.&lt;/p&gt;\n&lt;p&gt;This is a foundational role where you&#39;ll establish the playbook for how Associate SAs operate, build scalable enablement programs, and create a high-performing team culture. You&#39;ll be instrumental in helping early-career technical talent grow into trusted advisors for some of the world&#39;s most innovative engineering organizations.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;h3&gt;&lt;strong&gt;Team Leadership &amp;amp; Development&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Build, manage, and mentor a team of Associate Solutions Architects, providing technical coaching and career development&lt;/li&gt;\n&lt;li&gt;Establish onboarding programs and skill development frameworks tailored for early-career technical talent&lt;/li&gt;\n&lt;li&gt;Set clear goals and performance expectations, conducting regular reviews that promote growth and productivity&lt;/li&gt;\n&lt;li&gt;Create a culture of continuous learning, knowledge sharing, and technical excellence&lt;/li&gt;\n&lt;li&gt;Partner with recruiting to scale the team and build a diverse pipeline of technical talent&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Claude Code Specialization &amp;amp; Enablement&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Maintain deep expertise in Claude Code capabilities, integrations, developer workflows, and competitive positioning&lt;/li&gt;\n&lt;li&gt;Develop and refine playbooks, demo scripts, technical content, and best practices for Claude Code engagements&lt;/li&gt;\n&lt;li&gt;Establish standards for technical evaluations, proof-of-concept execution, and rollout strategies&lt;/li&gt;\n&lt;li&gt;Build internal enablement programs to ensure team members are expert practitioners of Claude Code&lt;/li&gt;\n&lt;li&gt;Stay current with developer tooling trends, IDE integrations, and AI-assisted development landscape&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Customer Success &amp;amp; Pre-Sales Excellence&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Guide your team in supporting high-value customer engagements, ensuring successful technical evaluations and adoption&lt;/li&gt;\n&lt;li&gt;Personally engage with strategic accounts where senior technical leadership is needed&lt;/li&gt;\n&lt;li&gt;Partner with Account Executives and senior Solutions Architects to drive expansion opportunities&lt;/li&gt;\n&lt;li&gt;Ensure your team effectively identifies and builds technical champions within customer engineering organizations&lt;/li&gt;\n&lt;li&gt;Monitor customer success metrics and iterate on engagement strategies based on outcomes&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Cross-Functional Collaboration&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Work closely with Product and Engineering teams to communicate customer feedback and influence product roadmap&lt;/li&gt;\n&lt;li&gt;Partner with GTM leadership to align team activities with overall business objectives&lt;/li&gt;\n&lt;li&gt;Collaborate with other SA leaders to share best practices and ensure consistent customer experience&lt;/li&gt;\n&lt;li&gt;Contribute to thought leadership through technical content, webinars, and conference presentations&lt;/li&gt;\n&lt;li&gt;Establish feedback loops between your team and product development to drive continuous improvement&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Process &amp;amp; Operations&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Build scalable processes for managing customer engagements, prioritizing opportunities, and measuring impact&lt;/li&gt;\n&lt;li&gt;Establish metrics and reporting frameworks to track team performance and customer outcomes&lt;/li&gt;\n&lt;li&gt;Create systems for knowledge management, ensuring best practices are documented and accessible&lt;/li&gt;\n&lt;li&gt;Drive operational excellence while maintaining the flexibility needed for a fast-growing product area&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;h3&gt;&lt;strong&gt;Required Experience&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in solutions architecture, sales engineering, developer relations, or similar technical customer-facing roles&lt;/li&gt;\n&lt;li&gt;2+ years of people management experience, ideally managing early-career technical talent&lt;/li&gt;\n&lt;li&gt;Deep hands-on expertise with Claude Code or similar AI coding assistants&lt;/li&gt;\n&lt;li&gt;Strong software engineering background with experience across multiple programming languages and development environments&lt;/li&gt;\n&lt;li&gt;Experience with technical sales cycles, customer discovery, proof-of-concept execution, and driving adoption&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Technical Skills&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Expertise in modern software development workflows, toolchains, CI/CD, and developer productivity&lt;/li&gt;\n&lt;li&gt;Understanding of IDE integrations, code generation tools, and developer experience optimization&lt;/li&gt;\n&lt;li&gt;Familiarity with large language models, prompt engineering, and AI-powered developer tools&lt;/li&gt;\n&lt;li&gt;Ability to architect technical solutions and guide complex integrations&lt;/li&gt;\n&lt;li&gt;Comfort with debugging, troubleshooting, and solving technical challenges in real-time&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Leadership &amp;amp; Communication&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Strong coaching and mentorship abilities with track record of developing technical talent&lt;/li&gt;\n&lt;li&gt;Excellent communication skills with ability to explain complex concepts to both technical and non-technical audiences&lt;/li&gt;\n&lt;li&gt;Experience building processes and best practices in relatively unstructured environments&lt;/li&gt;\n&lt;li&gt;Comfortable operating in ambiguous, fast-moving environments with shifting priorities&lt;/li&gt;\n&lt;li&gt;Executive presence with ability to represent Anthropic at customer executive meetings&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Mindset &amp;amp; Values&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Passion for developer productivity and the transformative potential of AI in software development&lt;/li&gt;\n&lt;li&gt;Growth mindset with eagerness to learn and adapt alongside rapidly evolving technology&lt;/li&gt;\n&lt;li&gt;Commitment to making powerful AI technology safe and beneficial for developers and organizations&lt;/li&gt;\n&lt;li&gt;Collaborative approach with strong cross-functional partnership skills&lt;/li&gt;\n&lt;li&gt;Data-driven decision making balanced with qualitative customer insights&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$270,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$270,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4947472008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Frontier Red Team (Hardware Lead)",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5067098008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Team The Frontier Red Team (FRT) is a small, focused technical research team within Anthropic's Policy organization. Our goal is to make the entire world safer in this era of advanced AI by understanding what these systems can do and building the defenses that matter. In 2026, we're focused on researching and ensuring safety with self-improving, highly autonomous AI systems—especially ones with cyberphysical capabilities. See our previous related work on cyberdefense, robotics, and Project Vend. This is early-stage, high-conviction research with the potential for outsized impact. About the Role Our belief is that hardware capabilities may come very quickly, be very powerful, and come with enormous benefits and risks. Our team is focused on understanding the shape of this frontier and its implications for AI development. How do we measure these capabilities? How will they emerge and how will models behave? How do we ensure their safety and defend against a world where powerful, autonomous, self-improving AI systems may be used adversarially? We're looking for a senior engineer or scientist to lead our hardware research efforts—interfacing Claude with robotics and other cyberphysical systems to understand how autonomous AI interacts with the physical world. This is a senior individual contributor role with the opportunity to grow into team leadership as our hardware research expands. You'll own our hardware research direction, build foundational infrastructure, and shape how Anthropic thinks about cyberphysical AI risks. This is applied research with real-world stakes. Your work will inform decisions at the highest levels of the company, contribute to public demonstrations that shape policy discourse, and help build technical defenses that could matter enormously as AI systems become more capable. What You'll Do Design and build systems that interface Claude with diverse hardware platforms—robotics and other cyberphysical systems Develop some of the first comprehensive evals for hardware-enabled frontier models Build training environments for desirable model behavior Create demonstrations that characterize cyberphysical capabilities and inform policymakers and the public Collaborate with the broader team to integrate hardware capabilities into our defensive AI research Work with external experts in robotics, automation, and national security, to scope and validate research directions Own the technical roadmap for hardware research within FRT Sample Projects Developing simulation stacks and training pipelines for embodied robotics Developing systems where Claude controls diverse hardware and robotics platforms Building test environments and evaluations for characterising autonomous AI behavior in physical and simulated settings Creating demonstrations of cyberphysical risks and defenses for policy stakeholders You May Be a Good Fit If You Have experience building evaluation pipelines for LLMs Have experience optimizing capabilities of LLMs for narrow domains Have deep experience with robotics or other cyberphysical systems Have strong software engineering skills, particularly in Python Have experience building and working with LLM-based agents or autonomous systems Are driven to find solutions to ambiguously scoped, high-stakes problems Design and run experiments quickly, iterating fast toward useful results Thrive in collaborative environments (we love pair programming!) Care deeply about AI safety and want your work to have real-world impact on how humanity navigates advanced AI Can own entire problems end-to-end, including both technical and non-technical components Are comfortable working on sensitive projects that require discretion and integrity Strong Candidates May Also Have Experience leading technical projects or small teams Background in controls, mechatronics, or embedded systems Experience with simulation environments for robotics or autonomous systems Track record of building demos or prototypes that communicate complex technical ideas Experience working with external stakeholders (policymakers, government, researchers) Familiarity with AI safety research and threat modeling for advanced AI systems The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$850,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5067098008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5067098008",
    "title": "Research Engineer, Frontier Red Team (Hardware Lead)",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5067098008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T07:12:37.952Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Team&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;The Frontier Red Team (FRT) is a small, focused technical research team within Anthropic&#39;s Policy organization. Our goal is to make the entire world safer in this era of advanced AI by understanding what these systems can do and building the defenses that matter.&lt;/p&gt;\n&lt;p&gt;In 2026, we&#39;re focused on researching and ensuring safety with self-improving, highly autonomous AI systems—especially ones with cyberphysical capabilities. See our previous related work on &lt;a href=&quot;https://red.anthropic.com/2025/ai-for-cyber-defenders/&quot;&gt;cyberdefense&lt;/a&gt;, &lt;a href=&quot;https://red.anthropic.com/2025/project-fetch/&quot;&gt;robotics&lt;/a&gt;, and &lt;a href=&quot;https://red.anthropic.com/2025/project-vend-2/&quot;&gt;Project Vend&lt;/a&gt;. This is early-stage, high-conviction research with the potential for outsized impact.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Our belief is that hardware capabilities may come very quickly, be very powerful, and come with enormous benefits and risks. Our team is focused on understanding the shape of this frontier and its implications for AI development. How do we measure these capabilities? How will they emerge and how will models behave? How do we ensure their safety and defend against a world where powerful, autonomous, self-improving AI systems may be used adversarially?&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;We&#39;re looking for a senior engineer or scientist to lead our hardware research efforts—interfacing Claude with robotics and other cyberphysical systems to understand how autonomous AI interacts with the physical world.&lt;/p&gt;\n&lt;p&gt;This is a senior individual contributor role with the opportunity to grow into team leadership as our hardware research expands. You&#39;ll own our hardware research direction, build foundational infrastructure, and shape how Anthropic thinks about cyberphysical AI risks.&lt;/p&gt;\n&lt;p&gt;This is applied research with real-world stakes. Your work will inform decisions at the highest levels of the company, contribute to public demonstrations that shape policy discourse, and help build technical defenses that could matter enormously as AI systems become more capable.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;What You&#39;ll Do&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and build systems that interface Claude with diverse hardware platforms—robotics and other cyberphysical systems&lt;/li&gt;\n&lt;li&gt;Develop some of the first comprehensive evals for hardware-enabled frontier models&lt;/li&gt;\n&lt;li&gt;Build training environments for desirable model behavior&lt;/li&gt;\n&lt;li&gt;Create demonstrations that characterize cyberphysical capabilities and inform policymakers and the public&lt;/li&gt;\n&lt;li&gt;Collaborate with the broader team to integrate hardware capabilities into our defensive AI research&lt;/li&gt;\n&lt;li&gt;Work with external experts in robotics, automation, and national security, to scope and validate research directions&lt;/li&gt;\n&lt;li&gt;Own the technical roadmap for hardware research within FRT&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Sample Projects&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Developing simulation stacks and training pipelines for embodied robotics&lt;/li&gt;\n&lt;li&gt;Developing systems where Claude controls diverse hardware and robotics platforms&lt;/li&gt;\n&lt;li&gt;Building test environments and evaluations for characterising autonomous AI behavior in physical and simulated settings&lt;/li&gt;\n&lt;li&gt;Creating demonstrations of cyberphysical risks and defenses for policy stakeholders&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You May Be a Good Fit If You&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have experience building evaluation pipelines for LLMs&lt;/li&gt;\n&lt;li&gt;Have experience optimizing capabilities of LLMs for narrow domains&lt;/li&gt;\n&lt;li&gt;Have deep experience with robotics or other cyberphysical systems&lt;/li&gt;\n&lt;li&gt;Have strong software engineering skills, particularly in Python&lt;/li&gt;\n&lt;li&gt;Have experience building and working with LLM-based agents or autonomous systems&lt;/li&gt;\n&lt;li&gt;Are driven to find solutions to ambiguously scoped, high-stakes problems&lt;/li&gt;\n&lt;li&gt;Design and run experiments quickly, iterating fast toward useful results&lt;/li&gt;\n&lt;li&gt;Thrive in collaborative environments (we love pair programming!)&lt;/li&gt;\n&lt;li&gt;Care deeply about AI safety and want your work to have real-world impact on how humanity navigates advanced AI&lt;/li&gt;\n&lt;li&gt;Can own entire problems end-to-end, including both technical and non-technical components&lt;/li&gt;\n&lt;li&gt;Are comfortable working on sensitive projects that require discretion and integrity&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong Candidates May Also Have&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience leading technical projects or small teams&lt;/li&gt;\n&lt;li&gt;Background in controls, mechatronics, or embedded systems&lt;/li&gt;\n&lt;li&gt;Experience with simulation environments for robotics or autonomous systems&lt;/li&gt;\n&lt;li&gt;Track record of building demos or prototypes that communicate complex technical ideas&lt;/li&gt;\n&lt;li&gt;Experience working with external stakeholders (policymakers, government, researchers)&lt;/li&gt;\n&lt;li&gt;Familiarity with AI safety research and threat modeling for advanced AI systems&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$850,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5067098008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Product Manager, Labs",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5096878008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As a Research Product Manager for the Labs teams at Anthropic, you will own the ideation and development of new, moonshot products as we advance transformative, safe AI. The Labs team runs Anthropic's most ambitious experiments: new product categories that don't exist yet. The team focuses on 0-to-1 product development, taking our most advanced research and transforming it into innovative applications like Claude Code and MCP. We seek experienced founders and product managers who can bridge pure research and ambitious product experimentation, with the ability to identify and ultimately define entirely new product categories enabled by AI. Responsibilities: Work with researchers to understand what's emerging and what it means for users Identify nascent research capabilities that could become transformative products Build prototypes yourself to validate ideas before committing resources Lead 0-to-1 product development from research to internal prototypes to shipped products Define product strategy for experimental initiatives that push beyond our current offerings Creatively build MVPs and prototypes to validate product-market fit with the lowest cost possible Lead vision, strategy, roadmap, and execution of frontier technologies that leverage the latest AI capabilities to solve real-world problems You might be a good fit if you: Have 5+ years in product management, with experience launching new products and scaling existing products. Founder background is a plus. Possess a deep technical background with experience working cross-functionally with engineering teams to ship technical products. Have the ability to navigate and execute amidst ambiguity, and to flex into different domains based on the business problem at hand, finding simple, easy-to-understand solutions Have a track record of launching ambitious products that have found distribution or commercial success Think creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks Stay up-to-date and hands-on with emerging research and industry trends Prototype with AI tools like Claude Code The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$385,000 - $460,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5096878008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5096878008",
    "title": "Research Product Manager, Labs",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5096878008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T07:12:37.952Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Research Product Manager for the Labs teams at Anthropic, you will own the ideation and development of new, moonshot products as we advance transformative, safe AI. The Labs team runs Anthropic&#39;s most ambitious experiments: new product categories that don&#39;t exist yet. The team focuses on 0-to-1 product development, taking our most advanced research and transforming it into innovative applications like Claude Code and MCP.&lt;/p&gt;\n&lt;p&gt;We seek experienced founders and product managers who can bridge pure research and ambitious product experimentation, with the ability to identify and ultimately define entirely new product categories enabled by AI.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Work with researchers to understand what&#39;s emerging and what it means for users&lt;/li&gt;\n&lt;li&gt;Identify nascent research capabilities that could become transformative products&lt;/li&gt;\n&lt;li&gt;Build prototypes yourself to validate ideas before committing resources&lt;/li&gt;\n&lt;li&gt;Lead 0-to-1 product development from research to internal prototypes to shipped products&lt;/li&gt;\n&lt;li&gt;Define product strategy for experimental initiatives that push beyond our current offerings&lt;/li&gt;\n&lt;li&gt;Creatively build MVPs and prototypes to validate product-market fit with the lowest cost possible&lt;/li&gt;\n&lt;li&gt;Lead vision, strategy, roadmap, and execution of frontier technologies that leverage the latest AI capabilities to solve real-world problems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You might be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 5+ years in product management, with experience launching new products and scaling existing products. Founder background is a plus.&lt;/li&gt;\n&lt;li&gt;Possess a deep technical background with experience working cross-functionally with engineering teams to ship technical products.&lt;/li&gt;\n&lt;li&gt;Have the ability to navigate and execute amidst ambiguity, and to flex into different domains based on the business problem at hand, finding simple, easy-to-understand solutions&lt;/li&gt;\n&lt;li&gt;Have a track record of launching ambitious products that have found distribution or commercial success&lt;/li&gt;\n&lt;li&gt;Think creatively about the risks and benefits of new technologies, and think beyond past checklists and playbooks&lt;/li&gt;\n&lt;li&gt;Stay up-to-date and hands-on with emerging research and industry trends&lt;/li&gt;\n&lt;li&gt;Prototype with AI tools like Claude Code&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$385,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$460,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5096878008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Product Manager, Model Behaviors",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5097067008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As a Product Manager for Model Behaviors, you will partner with the Alignment Finetuning team to define and shape Claude's character, behaviors, and reinforcement signals—work that directly influences how millions of people experience AI. You will systematically identify high-priority behavioral improvements, coordinate across Research, Product, and Safeguards teams, and accelerate our ability to ship well-aligned models. The ideal candidate combines deep user empathy with the judgment to navigate nuanced behavior questions where there are no clear right answers. Responsibilities: Define behavioral defaults and steerability constraints Develop and maintain taxonomies of model behaviors across capabilities Identify, triage, and prioritize behavior issues and opportunities, coordinating input from Users, Research, Product, and Safeguards teams Amplify alignment research breakthroughs, translating them into product, process, and model improvements Deeply understand user interaction patterns to identify behavior improvements that make Claude more helpful and safe Contribute to evals that measure alignment progress Identify and scale initiatives and tools that help researchers ship alignment improvements faster You might be a good fit if you: Have a deep passion and curiosity for AI and LLMs. Use AI regularly. Have 5+ years in product management leading scaled conversational AI products. Are a first-principles thinker with the ability to navigate and execute amidst ambiguity, flexing into different domains based on the business problem at hand and finding simple, easy-to-understand solutions Have a track record of delivering products and features to end-users (consumer or end-user b2b focus) Have strong user empathy and the ability to synthesize vague or contradictory feedback into actionable priorities Have strong judgment and model taste, with the ability to make tradeoffs when there is no clear right answer Have a strong grasp of ML concepts and are willing to go deep on technical solutions Have intellectual curiosity without ego—comfortable asking questions and learning independently Think creatively about the risks and benefits of new technologies, moving beyond past checklists and playbooks Have a creative, hacker spirit and love solving puzzles The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$305,000 - $385,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5097067008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5097067008",
    "title": "Research Product Manager, Model Behaviors",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5097067008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T07:12:37.952Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;As a Product Manager for Model Behaviors, you will partner with the Alignment Finetuning team to define and shape Claude&#39;s character, behaviors, and reinforcement signals—work that directly influences how millions of people experience AI. You will systematically identify high-priority behavioral improvements, coordinate across Research, Product, and Safeguards teams, and accelerate our ability to ship well-aligned models. The ideal candidate combines deep user empathy with the judgment to navigate nuanced behavior questions where there are no clear right answers.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Define behavioral defaults and steerability constraints&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Develop and maintain taxonomies of model behaviors across capabilities&lt;/li&gt;\n&lt;li&gt;Identify, triage, and prioritize behavior issues and opportunities, coordinating input from Users, Research, Product, and Safeguards teams&lt;/li&gt;\n&lt;li&gt;Amplify alignment research breakthroughs, translating them into product, process, and model improvements&lt;/li&gt;\n&lt;li&gt;Deeply understand user interaction patterns to identify behavior improvements that make Claude more helpful and safe&lt;/li&gt;\n&lt;li&gt;Contribute to evals that measure alignment progress&lt;/li&gt;\n&lt;li&gt;Identify and scale initiatives and tools that help researchers ship alignment improvements faster&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;You might be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have a deep passion and curiosity for AI and LLMs. Use AI regularly.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Have 5+ years in product management leading scaled conversational AI products.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Are a first-principles thinker with the ability to navigate and execute amidst ambiguity, flexing into different domains based on the business problem at hand and finding simple, easy-to-understand solutions&lt;/li&gt;\n&lt;li&gt;Have a track record of delivering products and features to end-users (consumer or end-user b2b focus)&lt;/li&gt;\n&lt;li&gt;Have strong user empathy and the ability to synthesize vague or contradictory feedback into actionable priorities&lt;/li&gt;\n&lt;li&gt;Have strong judgment and model taste, with the ability to make tradeoffs when there is no clear right answer&lt;/li&gt;\n&lt;li&gt;Have a strong grasp of ML concepts and are willing to go deep on technical solutions&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Have intellectual curiosity without ego—comfortable asking questions and learning independently&lt;/li&gt;\n&lt;li&gt;Think creatively about the risks and benefits of new technologies, moving beyond past checklists and playbooks&lt;/li&gt;\n&lt;li&gt;Have a creative, hacker spirit and love solving puzzles&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$305,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$385,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5097067008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Senior Software Security Engineer",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA; Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4887959008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the Team The Security Engineering team's mission is to safeguard our AI systems and maintain the trust of our users and society at large. Whether we're developing critical security infrastructure, building secure development practices, or partnering with our research and product teams, we are committed to operating as a world-class security organization and keeping the safety and trust of our users at the forefront of everything we do. Responsibilities: Build security for large-scale AI clusters, implementing robust cloud security architecture including IAM, network segmentation, and encryption controls Design secure-by-design workflows, secure CI/CD pipelines across our services, help build secure cloud infrastructure, with expertise in various cloud environments, Kubernetes security, container orchestration and identity management Ship and operate secure, high-reliability services using Infrastructure-as-Code (IaC) practices and GitOps workflows Apply deep expertise in threat modeling and risk assessment to secure complex cloud environments Mentor engineers and contribute to hiring and growth of the Security team You may be a good fit if you have: 5-15+ years of software engineering experience implementing and maintaining critical systems at scale Bachelor's degree in Computer Science/Software Engineering or equivalent industry experience Strong software engineering skills in Python or at least one systems language (Go, Rust, C/C++) Experience managing infrastructure at scale with DevOps and cloud automation best practices Track record of driving engineering excellence through high standards, constructive code reviews, and mentorship Proven ability to lead cross-functional security initiatives and navigate complex organizational dynamics Outstanding communication skills, translating technical concepts effectively across all organizational levels Demonstrated success in bringing clarity and ownership to ambiguous technical problems Strong systems thinking with ability to identify and mitigate risks in complex environments Low ego, high empathy engineer who attracts talent and supports diverse, inclusive teams Experience supporting fast-paced startup engineering teams Passionate about AI safety and alignment, with keen interest in making AI systems more interpretable and aligned with human values Strong candidates may also: Designing and hardening CI/CD pipelines against supply chain attacks through isolated environments, signed attestations, dependency verification, and automated policy enforcement Building secure development workflows through hardened remote environments Implementing network segmentation and access controls in cloud environments Managing infrastructure through automated configuration and policy enforcement Hardening containerized applications and enforcing security policies Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$320,000 - $405,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4887959008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4887959008",
    "title": "Senior Software Security Engineer",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA; Seattle, WA",
    "locations": [
      "New York City, NY; San Francisco, CA; Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4887959008",
    "departments": [
      "Security"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T07:12:37.952Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;&lt;strong&gt;About the Team&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;The Security Engineering team&#39;s mission is to safeguard our AI systems and maintain the trust of our users and society at large. Whether we&#39;re developing critical security infrastructure, building secure development practices, or partnering with our research and product teams, we are committed to operating as a world-class security organization and keeping the safety and trust of our users at the forefront of everything we do.&lt;/p&gt;\n&lt;/div&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Build security for large-scale AI clusters, implementing robust cloud security architecture including IAM, network segmentation, and encryption controls&lt;/li&gt;\n&lt;li&gt;Design secure-by-design workflows, secure CI/CD pipelines across our services, help build secure cloud infrastructure, with expertise in various cloud environments, Kubernetes security, container orchestration and identity management&lt;/li&gt;\n&lt;li&gt;Ship and operate secure, high-reliability services using Infrastructure-as-Code (IaC) practices and GitOps workflows&lt;/li&gt;\n&lt;li&gt;Apply deep expertise in threat modeling and risk assessment to secure complex cloud environments&lt;/li&gt;\n&lt;li&gt;Mentor engineers and contribute to hiring and growth of the Security team&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5-15+ years of software engineering experience implementing and maintaining critical systems at scale&lt;/li&gt;\n&lt;li&gt;Bachelor&#39;s degree in Computer Science/Software Engineering or equivalent industry experience&lt;/li&gt;\n&lt;li&gt;Strong software engineering skills in Python or at least one systems language (Go, Rust, C/C++)&lt;/li&gt;\n&lt;li&gt;Experience managing infrastructure at scale with DevOps and cloud automation best practices&lt;/li&gt;\n&lt;li&gt;Track record of driving engineering excellence through high standards, constructive code reviews, and mentorship&lt;/li&gt;\n&lt;li&gt;Proven ability to lead cross-functional security initiatives and navigate complex organizational dynamics&lt;/li&gt;\n&lt;li&gt;Outstanding communication skills, translating technical concepts effectively across all organizational levels&lt;/li&gt;\n&lt;li&gt;Demonstrated success in bringing clarity and ownership to ambiguous technical problems&lt;/li&gt;\n&lt;li&gt;Strong systems thinking with ability to identify and mitigate risks in complex environments&lt;/li&gt;\n&lt;li&gt;Low ego, high empathy engineer who attracts talent and supports diverse, inclusive teams&lt;/li&gt;\n&lt;li&gt;Experience supporting fast-paced startup engineering teams&lt;/li&gt;\n&lt;li&gt;Passionate about AI safety and alignment, with keen interest in making AI systems more interpretable and aligned with human values&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Designing and hardening CI/CD pipelines against supply chain attacks through isolated environments, signed attestations, dependency verification, and automated policy enforcement&lt;/li&gt;\n&lt;li&gt;Building secure development workflows through hardened remote environments&lt;/li&gt;\n&lt;li&gt;Implementing network segmentation and access controls in cloud environments&lt;/li&gt;\n&lt;li&gt;Managing infrastructure through automated configuration and policy enforcement&lt;/li&gt;\n&lt;li&gt;Hardening containerized applications and enforcing security policies&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$320,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$405,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4887959008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Engineering Manager, Application Security Platform",
    "employer_name": "datadog",
    "job_city": "New York, New York, USA",
    "job_apply_link": "https://careers.datadoghq.com/detail/7476431/?gh_jid=7476431",
    "job_posted_at_datetime_utc": "2026-01-29T15:28:33-05:00",
    "job_description": "Application Security is a core engineering challenge at Datadog. We don't just find bugs and write policies; we build the tooling and infrastructure that prevents them. The Application Security team is part of the Platform Security group which is an engineering organization dedicated to making 'secure' the default state for every Datadog engineer.As the Manager, you’ll lead a team of security and software engineers building high-scale security primitives and automated guardrails integrated directly into the SDLC. If you’re an Engineering Manager who views security as a distributed systems problem rather than a compliance checklist, we want to talk to you.You’ll join at an ideal time for making a big impact. Our products are seeing very high growth, with the platform becoming more interactive and new products and features being developed regularly including products for the Security space.At Datadog, we value people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply.What You’ll Do:Lead and Scale an Engineering Team: Mentor and grow a team of 5+ security focussed engineers focused on building reusable platform tooling.Build the \"Golden Path\": Design and ship secure-by-default configurations and self-service tools for network, compute, and authentication, making it seamless for product teams to build securely without friction.Architect Security Primitives: Partner with Platform and Infrastructure teams to bake security into the foundation of our systems, treating \"secure\" as a high-availability requirement.Drive Developer Experience (DevEx): Collaborate across the organization to ensure security integrations are intuitive, empowering engineers to own their security posture through automation rather than manual checklists.Engineer for Measurement: Define and track KPIs focused on platform adoption, system reliability, and vulnerability reduction to quantify the impact of your team’s work.Internal \"Customer Zero\": Act as a strategic partner to our Product teams by using Datadog’s own security products at scale, providing the feedback loop that shapes our public-facing roadmap.Foster a High-Performance Culture: Build an inclusive environment where engineers don’t need to have all the answers upfront but are empowered to solve complex distributed systems challenges.Who You Are:You have prior experience in Software Engineering, Platform Engineering, Security Architecture, and/or Application Security.You have direct people management experience and a strong desire to develop as an engineering leader.Passionate about security and want to work on complex security problems, at-scale, in a large multi-cloud environmentYou have great communication skills, emotional intelligence and skills at collaborating with and coaching folks from different backgrounds.You thrive in ambiguous, fast-paced environments and find ways to drive outcomes working with key stakeholders.You stay updated with modern security best practices, technologies and emerging threatsBenefits and Growth: New hire stock equity (RSUs) and employee stock purchase plan (ESPP)Continuous professional development, product training, and career pathingIntradepartmental mentor and buddy program for in-house networkingAn inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups)Access to Inclusion Talks, our internal panel discussionsFree, global mental health benefits for employees and dependents age 6+Competitive global benefitsBenefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate's skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.The reasonably estimated yearly salary for this role at Datadog is:$187,000—$240,000 USDAbout Datadog: Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog Learning Center.Equal Opportunity at Datadog:Datadog is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our Candidate Legal Notices for your reference. Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete this form. This form is for accommodation requests only and cannot be used to inquire about the status of applications. Privacy and AI Guidelines:Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice. For information on our AI policy, please visit Interviewing at Datadog AI Guidelines.Requisition ID: R17070",
    "id": "careers-datadoghq-com-detail-7476431",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7476431",
    "title": "Engineering Manager, Application Security Platform",
    "company_name": "datadog",
    "company_slug": "datadog",
    "location": "New York, New York, USA",
    "locations": [
      "New York, New York, USA"
    ],
    "url": "https://careers.datadoghq.com/detail/7476431/?gh_jid=7476431",
    "departments": [
      "Security"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T15:28:33-05:00",
    "fetched_at": "2026-02-03T07:12:41.680Z",
    "description": "&lt;p&gt;Application Security is a core engineering challenge at Datadog. We don&#39;t just find bugs and write policies; we build the tooling and infrastructure that prevents them. The Application Security team is part of the Platform Security group which is an engineering organization dedicated to making &#39;secure&#39; the default state for every Datadog engineer.&lt;/p&gt;\n&lt;p&gt;As the Manager, you’ll lead a team of security and software engineers building high-scale security primitives and automated guardrails integrated directly into the SDLC. If you’re an Engineering Manager who views security as a distributed systems problem rather than a compliance checklist, we want to talk to you.&lt;/p&gt;\n&lt;p&gt;You’ll join at an ideal time for making a big impact. Our products are seeing very high growth, with the platform becoming more interactive and new products and features being developed regularly including products for the Security space.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;At Datadog, we value people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That&#39;s okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply.&lt;/em&gt;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;What You’ll Do:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead and Scale an Engineering Team: Mentor and grow a team of 5+ security focussed engineers focused on building reusable platform tooling.&lt;/li&gt;\n&lt;li&gt;Build the &quot;Golden Path&quot;: Design and ship secure-by-default configurations and self-service tools for network, compute, and authentication, making it seamless for product teams to build securely without friction.&lt;/li&gt;\n&lt;li&gt;Architect Security Primitives: Partner with Platform and Infrastructure teams to bake security into the foundation of our systems, treating &quot;secure&quot; as a high-availability requirement.&lt;/li&gt;\n&lt;li&gt;Drive Developer Experience (DevEx): Collaborate across the organization to ensure security integrations are intuitive, empowering engineers to own their security posture through automation rather than manual checklists.&lt;/li&gt;\n&lt;li&gt;Engineer for Measurement: Define and track KPIs focused on platform adoption, system reliability, and vulnerability reduction to quantify the impact of your team’s work.&lt;/li&gt;\n&lt;li&gt;Internal &quot;Customer Zero&quot;: Act as a strategic partner to our Product teams by using Datadog’s own security products at scale, providing the feedback loop that shapes our public-facing roadmap.&lt;/li&gt;\n&lt;li&gt;Foster a High-Performance Culture: Build an inclusive environment where engineers don’t need to have all the answers upfront but are empowered to solve complex distributed systems challenges.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Who You Are:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;You have prior experience in Software Engineering, Platform Engineering, Security Architecture, and/or Application Security.&lt;/li&gt;\n&lt;li&gt;You have direct people management experience and a strong desire to develop as an engineering leader.&lt;/li&gt;\n&lt;li&gt;Passionate about security and want to work on complex security problems, at-scale, in a large multi-cloud environment&lt;/li&gt;\n&lt;li&gt;You have great communication skills, emotional intelligence and skills at collaborating with and coaching folks from different backgrounds.&lt;/li&gt;\n&lt;li&gt;You thrive in ambiguous, fast-paced environments and find ways to drive outcomes working with key stakeholders.&lt;/li&gt;\n&lt;li&gt;You stay updated with modern security best practices, technologies and emerging threats&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Benefits and Growth:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;New hire stock equity (RSUs) and employee stock purchase plan (ESPP)&lt;/li&gt;\n&lt;li&gt;Continuous professional development, product training, and career pathing&lt;/li&gt;\n&lt;li&gt;Intradepartmental mentor and buddy program for in-house networking&lt;/li&gt;\n&lt;li&gt;An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups)&lt;/li&gt;\n&lt;li&gt;Access to Inclusion Talks, our internal panel discussions&lt;/li&gt;\n&lt;li&gt;Free, global mental health benefits for employees and dependents age 6+&lt;/li&gt;\n&lt;li&gt;Competitive global benefits&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;em&gt;Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.&lt;/em&gt;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate&#39;s skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;The reasonably estimated yearly salary for this role at Datadog is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$187,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$240,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;hr&gt;\n&lt;p&gt;&lt;strong&gt;About Datadog:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on &lt;a href=&quot;https://www.instagram.com/datadoghq/?hl=en&quot; target=&quot;_blank&quot;&gt;Instagram&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/company/datadog&quot; target=&quot;_blank&quot;&gt;LinkedIn,&lt;/a&gt; and &lt;a href=&quot;https://learn.datadoghq.com/&quot; target=&quot;_blank&quot;&gt;Datadog Learning Center. &lt;/a&gt;&lt;/p&gt;\n&lt;hr&gt;\n&lt;p data-renderer-start-pos=&quot;215&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Equal Opportunity at Datadog:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;Datadog is proud to offer &lt;a href=&quot;https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf&quot; target=&quot;_blank&quot;&gt;equal employment opportunity&lt;/a&gt; to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our &lt;a href=&quot;https://www.datadoghq.com/legal/candidate-legal-notices/&quot; target=&quot;_blank&quot;&gt;Candidate Legal Notices&lt;/a&gt; for your reference.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSeoJeduEZ2NdZF_65uZmWUrCM-zee7yADXX1s6Xr9zAGq8iKA/viewform&quot; target=&quot;_blank&quot;&gt;this form&lt;/a&gt;. This form is for accommodation requests only and cannot be used to inquire about the status of applications.&amp;nbsp;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;&lt;strong data-renderer-mark=&quot;true&quot;&gt;Privacy and AI Guidelines:&lt;/strong&gt;&lt;/p&gt;\n&lt;p data-renderer-start-pos=&quot;662&quot;&gt;Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.datadoghq.com/legal/applicant-candidate-privacy/&quot; data-sk=&quot;tooltip_parent&quot;&gt;Applicant and Candidate Privacy Notice&lt;/a&gt;. For information on our AI policy, please visit &lt;a href=&quot;https://www.datadoghq.com/legal/interviewing-at-datadog-ai-guidelines/&quot; target=&quot;_blank&quot;&gt;Interviewing at Datadog AI Guidelines&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7476431
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  }
]