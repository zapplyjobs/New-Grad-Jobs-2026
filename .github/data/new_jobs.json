[
  {
    "job_title": "Research Engineer/Research Scientist, Audio",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5074815008",
    "job_posted_at_datetime_utc": "2026-01-31T18:39:33-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Anthropic’s Audio team pushes the boundaries of what's possible with audio with large language models. We care about making safe, steerable, reliable systems that can understand and generate speech and audio, prioritizing not only naturalness but also steerability and robustness. As a researcher on the Audio team, you'll work across the full stack of audio ML, developing audio codecs and representations, sourcing and synthesizing high quality audio data, training large-scale speech language models and large audio diffusion models, and developing novel architectures for incorporating continuous signals into LLMs. Our team focuses primarily but not exclusively on speech, building advanced steerable systems spanning end-to-end conversational systems, speech and audio understanding models, and speech synthesis capabilities. The team works closely with many collaborators across pretraining, finetuning, reinforcement learning, production inference, and product to get advanced audio technologies from early research to high impact real-world deployments. You may be a good fit if you: Have hands-on experience with training audio models, whether that's conversational speech-to-speech, speech translation, speech recognition, text-to-speech, diarization, codecs, or generative audio models Genuinely enjoy both research and engineering work, and you'd describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other Are comfortable working across abstraction levels, from signal processing fundamentals to large-scale model training and inference optimization Have deep expertise with JAX, PyTorch, or large-scale distributed training, and can debug performance issues across the full stack Thrive in fast-moving environments where the most important problem might shift as we learn more about what works Communicate clearly and collaborate effectively; audio touches many parts of our systems, so you'll work closely with teams across the company Are passionate about building conversational AI that feels natural, steerable, and safe Care about the societal impacts of voice AI and want to help shape how these systems are developed responsibly Strong candidates may also have experience with: Large language model pretraining and finetuning Training diffusion models for image and audio generation Reinforcement learning for large language models and diffusion models End-to-end system optimization, from performance benchmarking to kernel optimization GPUs, Kubernetes, PyTorch, or distributed training infrastructure Representative projects: Training state-of-the art neural audio codecs for 48 kHz stereo audio Developing novel algorithms for diffusion pretraining and reinforcement learning Scaling audio datasets to millions of hours of high quality audio Creating robust evaluation methodologies for hard-to-measure qualities such as naturalness or expressiveness Studying training dynamics of mixed audio-text language models Optimizing latency and inference throughput for deployed streaming audio systems The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5074815008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5074815008",
    "title": "Research Engineer/Research Scientist, Audio",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5074815008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-31T18:39:33-05:00",
    "fetched_at": "2026-02-01T18:23:02.264Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Anthropic’s Audio team pushes the boundaries of what&#39;s possible with audio with large language models. We care about making safe, steerable, reliable systems that can understand and generate speech and audio, prioritizing not only naturalness but also steerability and robustness. As a researcher on the Audio team, you&#39;ll work across the full stack of audio ML, developing audio codecs and representations, sourcing and synthesizing high quality audio data, training large-scale speech language models and large audio diffusion models, and developing novel architectures for incorporating continuous signals into LLMs.&lt;/p&gt;\n&lt;p&gt;Our team focuses primarily but not exclusively on speech, building advanced steerable systems spanning end-to-end conversational systems, speech and audio understanding models, and speech synthesis capabilities. The team works closely with many collaborators across pretraining, finetuning, reinforcement learning, production inference, and product to get advanced audio technologies from early research to high impact real-world deployments.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have hands-on experience with training audio models, whether that&#39;s conversational speech-to-speech, speech translation, speech recognition, text-to-speech, diarization, codecs, or generative audio models&lt;/li&gt;\n&lt;li&gt;Genuinely enjoy both research and engineering work, and you&#39;d describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other&lt;/li&gt;\n&lt;li&gt;Are comfortable working across abstraction levels, from signal processing fundamentals to large-scale model training and inference optimization&lt;/li&gt;\n&lt;li&gt;Have deep expertise with JAX, PyTorch, or large-scale distributed training, and can debug performance issues across the full stack&lt;/li&gt;\n&lt;li&gt;Thrive in fast-moving environments where the most important problem might shift as we learn more about what works&lt;/li&gt;\n&lt;li&gt;Communicate clearly and collaborate effectively; audio touches many parts of our systems, so you&#39;ll work closely with teams across the company&lt;/li&gt;\n&lt;li&gt;Are passionate about building conversational AI that feels natural, steerable, and safe&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of voice AI and want to help shape how these systems are developed responsibly&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Strong candidates may also have experience with:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Large language model pretraining and finetuning&lt;/li&gt;\n&lt;li&gt;Training diffusion models for image and audio generation&lt;/li&gt;\n&lt;li&gt;Reinforcement learning for large language models and diffusion models&lt;/li&gt;\n&lt;li&gt;End-to-end system optimization, from performance benchmarking to kernel optimization&lt;/li&gt;\n&lt;li&gt;GPUs, Kubernetes, PyTorch, or distributed training infrastructure&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Representative projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Training state-of-the art neural audio codecs for 48 kHz stereo audio&lt;/li&gt;\n&lt;li&gt;Developing novel algorithms for diffusion pretraining and reinforcement learning&lt;/li&gt;\n&lt;li&gt;Scaling audio datasets to millions of hours of high quality audio&lt;/li&gt;\n&lt;li&gt;Creating robust evaluation methodologies for hard-to-measure qualities such as naturalness or expressiveness&lt;/li&gt;\n&lt;li&gt;Studying training dynamics of mixed audio-text language models&lt;/li&gt;\n&lt;li&gt;Optimizing latency and inference throughput for deployed streaming audio systems&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5074815008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Partner Marketing Lead, Cloud Partners",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4966206008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Partner Marketing Manager at Anthropic, you will play a pivotal role in building and scaling our partner marketing initiatives with the world's leading cloud technology partners. You will develop and execute comprehensive go-to-market programs that drive enterprise adoption of Claude through strategic partnerships. In this role, you will craft compelling joint value propositions, create executive-level marketing campaigns, and build scalable enablement programs that empower our partners to successfully position and sell Claude to enterprise customers. You'll be a key connector between Anthropic's partner organization and our marketing teams, ensuring seamless execution of high-impact programs that accelerate pipeline and revenue growth. This role requires someone who can think strategically about long-term partner relationships while also rolling up their sleeves to execute flawlessly on campaigns, events, and enablement initiatives. You'll need to balance the art of relationship-building with the science of measuring marketing impact, always keeping the focus on driving measurable business outcomes for both Anthropic and our partners. Responsibilities Design and execute comprehensive go-to-market programs with our major cloud partners, AWS, Azure, and Google Cloud focusing on enterprise customer acquisition Develop joint marketing campaigns targeting C-suite and senior decision-makers at enterprise organizations, creating compelling narratives around AI transformation and business value Build partner messaging frameworks and create high-quality enablement materials (pitch decks, solution briefs, case studies, demo scripts) that empower partners to effectively position Claude Lead end-to-end campaign execution with partners, coordinating across product marketing, demand generation, field marketing, and events teams to ensure flawless delivery Establish and manage joint business planning processes with key partners, including quarterly planning, campaign calendars, and success metrics Collaborate with partner sales teams to identify priority accounts and develop account-based marketing strategies that leverage partner relationships Create and maintain a partner marketing content library and resource center, ensuring partners have easy access to the latest materials and messaging Track, measure, and report on partner marketing performance, including partner-sourced pipeline, influenced revenue, and campaign ROI Represent Anthropic at partner events, executive briefings, and industry conferences as needed Build scalable processes and playbooks that can be replicated across the partner ecosystem as we grow You may be a good fit if you Have 10+ years of marketing experience, with significant focus on partner marketing in B2B technology environments Have deep expertise building and executing partner marketing programs with cloud partners in a startup or scale-up environment - experience working for a late-stage, hypergrowth or pre-IPO technology company is required for this role Demonstrate strong understanding of enterprise buyer journeys and can create marketing programs that resonate with C-level executives Are skilled at developing compelling joint value propositions that articulate clear business outcomes for enterprise customers Have proven ability to manage complex, cross-functional initiatives with multiple stakeholders across organizations Excel at building trusted relationships with partner marketing and sales teams, establishing yourself as a strategic advisor Are highly organized and detail-oriented, with demonstrated ability to manage multiple programs simultaneously while maintaining quality Possess excellent written and verbal communication skills, with experience creating executive-level content and presentations Are data-driven and comfortable tracking marketing metrics, analyzing performance, and optimizing programs based on results Thrive in fast-paced, high-growth environments and are comfortable with ambiguity and changing priorities Have a \"get it done\" mentality and aren't afraid to jump in wherever needed to ensure program success Care about the societal impacts of AI and are excited about enabling enterprises to adopt AI responsibly Strong candidates may also have Experience in the AI/ML industry or working with AI-powered products Background in B2B SaaS partner marketing, particularly in developer tools, data platforms, or enterprise software Experience with marketplace programs (AWS Marketplace, GCP Marketplace, Azure Marketplace) Proven track record launching and scaling new partner programs from the ground up Experience marketing to technical audiences as well as business decision-makers Understanding of enterprise AI use cases across different industries and functions Established relationships within the SaaS ISV or consulting partner ecosystem Experience with marketing automation platforms, CRM systems, and partner relationship management tools Track record of success in high-growth startup environments Role-specific policy: For this role, we expect all staff to be able to work from our San Francisco office at least 2 days a week, though we encourage you to apply even if you might need some flexibility for an interim period of time for relocation. If based in Seattle or New York, this role will require traveling to the San Francisco office once a month. Additionally, this role will also require up to 20% of the time for partner meetings and partner events. Deadline to apply: None. Applications will be reviewed on a rolling basisThe annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$255,000 - $320,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4966206008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4966206008",
    "title": "Partner Marketing Lead, Cloud Partners",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4966206008",
    "departments": [
      "Marketing & Brand"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Partner Marketing Manager at Anthropic, you will play a pivotal role in building and scaling our partner marketing initiatives with the world&#39;s leading cloud technology partners. You will develop and execute comprehensive go-to-market programs that drive enterprise adoption of Claude through strategic partnerships.&lt;/p&gt;\n&lt;p&gt;In this role, you will craft compelling joint value propositions, create executive-level marketing campaigns, and build scalable enablement programs that empower our partners to successfully position and sell Claude to enterprise customers. You&#39;ll be a key connector between Anthropic&#39;s partner organization and our marketing teams, ensuring seamless execution of high-impact programs that accelerate pipeline and revenue growth.&lt;/p&gt;\n&lt;p&gt;This role requires someone who can think strategically about long-term partner relationships while also rolling up their sleeves to execute flawlessly on campaigns, events, and enablement initiatives. You&#39;ll need to balance the art of relationship-building with the science of measuring marketing impact, always keeping the focus on driving measurable business outcomes for both Anthropic and our partners.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and execute comprehensive go-to-market programs with our major cloud partners, AWS, Azure, and Google Cloud focusing on enterprise customer acquisition&lt;/li&gt;\n&lt;li&gt;Develop joint marketing campaigns targeting C-suite and senior decision-makers at enterprise organizations, creating compelling narratives around AI transformation and business value&lt;/li&gt;\n&lt;li&gt;Build partner messaging frameworks and create high-quality enablement materials (pitch decks, solution briefs, case studies, demo scripts) that empower partners to effectively position Claude&lt;/li&gt;\n&lt;li&gt;Lead end-to-end campaign execution with partners, coordinating across product marketing, demand generation, field marketing, and events teams to ensure flawless delivery&lt;/li&gt;\n&lt;li&gt;Establish and manage joint business planning processes with key partners, including quarterly planning, campaign calendars, and success metrics&lt;/li&gt;\n&lt;li&gt;Collaborate with partner sales teams to identify priority accounts and develop account-based marketing strategies that leverage partner relationships&lt;/li&gt;\n&lt;li&gt;Create and maintain a partner marketing content library and resource center, ensuring partners have easy access to the latest materials and messaging&lt;/li&gt;\n&lt;li&gt;Track, measure, and report on partner marketing performance, including partner-sourced pipeline, influenced revenue, and campaign ROI&lt;/li&gt;\n&lt;li&gt;Represent Anthropic at partner events, executive briefings, and industry conferences as needed&lt;/li&gt;\n&lt;li&gt;Build scalable processes and playbooks that can be replicated across the partner ecosystem as we grow&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 10+ years of marketing experience, with significant focus on partner marketing in B2B technology environments&lt;/li&gt;\n&lt;li&gt;Have deep expertise building and executing partner marketing programs with cloud partners in a startup or scale-up environment &lt;em&gt;- experience working for a late-stage, hypergrowth or pre-IPO technology company is required for this role&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;Demonstrate strong understanding of enterprise buyer journeys and can create marketing programs that resonate with C-level executives&lt;/li&gt;\n&lt;li&gt;Are skilled at developing compelling joint value propositions that articulate clear business outcomes for enterprise customers&lt;/li&gt;\n&lt;li&gt;Have proven ability to manage complex, cross-functional initiatives with multiple stakeholders across organizations&lt;/li&gt;\n&lt;li&gt;Excel at building trusted relationships with partner marketing and sales teams, establishing yourself as a strategic advisor&lt;/li&gt;\n&lt;li&gt;Are highly organized and detail-oriented, with demonstrated ability to manage multiple programs simultaneously while maintaining quality&lt;/li&gt;\n&lt;li&gt;Possess excellent written and verbal communication skills, with experience creating executive-level content and presentations&lt;/li&gt;\n&lt;li&gt;Are data-driven and comfortable tracking marketing metrics, analyzing performance, and optimizing programs based on results&lt;/li&gt;\n&lt;li&gt;Thrive in fast-paced, high-growth environments and are comfortable with ambiguity and changing priorities&lt;/li&gt;\n&lt;li&gt;Have a &quot;get it done&quot; mentality and aren&#39;t afraid to jump in wherever needed to ensure program success&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of AI and are excited about enabling enterprises to adopt AI responsibly&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience in the AI/ML industry or working with AI-powered products&lt;/li&gt;\n&lt;li&gt;Background in B2B SaaS partner marketing, particularly in developer tools, data platforms, or enterprise software&lt;/li&gt;\n&lt;li&gt;Experience with marketplace programs (AWS Marketplace, GCP Marketplace, Azure Marketplace)&lt;/li&gt;\n&lt;li&gt;Proven track record launching and scaling new partner programs from the ground up&lt;/li&gt;\n&lt;li&gt;Experience marketing to technical audiences as well as business decision-makers&lt;/li&gt;\n&lt;li&gt;Understanding of enterprise AI use cases across different industries and functions&lt;/li&gt;\n&lt;li&gt;Established relationships within the SaaS ISV or consulting partner ecosystem&lt;/li&gt;\n&lt;li&gt;Experience with marketing automation platforms, CRM systems, and partner relationship management tools&lt;/li&gt;\n&lt;li&gt;Track record of success in high-growth startup environments&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Role-specific policy:&amp;nbsp;&lt;/strong&gt;For this role, we expect all staff to be able to work from our San Francisco office at least 2 days a week, though we encourage you to apply even if you might need some flexibility for an interim period of time for relocation. If based in Seattle or New York, this role will require traveling to the San Francisco office once a month. Additionally, this role will also require up to 20% of the time for partner meetings and partner events.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None. Applications will be reviewed on a rolling basis&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$255,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$320,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4966206008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Partner Marketing Lead, GSIs",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5061729008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Partner Marketing Manager for Global System Integrators (GSIs) at Anthropic, you will play a pivotal role in building and scaling our partner marketing initiatives with the world's leading consulting firms and systems integrators. You will develop and execute comprehensive go-to-market programs that drive enterprise adoption of Claude through these strategic partnerships. In this role, you will craft compelling joint value propositions, create executive-level marketing campaigns, and build scalable enablement programs that empower our GSI partners to successfully position and implement Claude for enterprise customers. You'll be a key connector between Anthropic's alliances organization and our marketing teams, ensuring seamless execution of high-impact programs that accelerate pipeline and revenue growth. This role requires someone who can think strategically about long-term partner relationships while also rolling up their sleeves to execute flawlessly on campaigns, events, and enablement initiatives. You'll need to balance the art of relationship-building with the science of measuring marketing impact, always keeping the focus on driving measurable business outcomes for both Anthropic and our GSI partners. Responsibilities Partner Marketing Strategy & Execution Design and execute comprehensive go-to-market programs with major GSI partners, focusing on enterprise customer acquisition and AI transformation initiatives Develop joint marketing campaigns targeting C-suite and senior decision-makers at enterprise organizations, creating compelling narratives around AI transformation and business value Create repeatable marketing programs that enable GSI partners to effectively position and sell Claude-powered solutions to their enterprise clients Establish and manage joint business planning processes with key GSI partners, including quarterly planning, campaign calendars, and success metrics Collaborate with partner sales and alliances teams to identify priority accounts and develop account-based marketing strategies that leverage GSI relationships Content & Enablement Build partner messaging frameworks and create high-quality enablement materials (pitch decks, solution briefs, case studies, demo scripts) that empower GSI partners to effectively position Claude Develop and deliver partner-specific content that demonstrates the value of Claude integration across different industries and enterprise use cases Create training materials for GSI partners' go-to-market teams, including sales and marketing enablement programs Manage partner resources including brand and co-marketing guidelines, program documentation, and self-service marketing assets Program Management & Execution Lead end-to-end campaign execution with GSI partners, coordinating across product marketing, demand generation, field marketing, and events teams to ensure flawless delivery Manage partner funding programs (MDF/Co-op) and ensure ROI tracking for joint marketing investments Track, measure, and report on partner marketing performance, including partner-sourced pipeline, influenced revenue, and campaign ROI Represent Anthropic at partner events, executive briefings, and industry conferences as needed Build scalable processes and playbooks that can be replicated across the GSI partner ecosystem as we grow You may be a good fit if you Have 10+ years of marketing experience, with significant focus on partner marketing in B2B technology environments Have deep expertise building and executing partner marketing programs with Global System Integrators (GSIs), major consulting firms, or systems integrators Demonstrate strong understanding of enterprise buyer journeys and can create marketing programs that resonate with C-level executives Are skilled at developing compelling joint value propositions that articulate clear business outcomes for enterprise customers Have proven ability to manage complex, cross-functional initiatives with multiple stakeholders across organizations Excel at building trusted relationships with partner marketing and sales teams, establishing yourself as a strategic advisor Are highly organized and detail-oriented, with demonstrated ability to manage multiple programs simultaneously while maintaining quality Possess excellent written and verbal communication skills, with experience creating executive-level content and presentations Are data-driven and comfortable tracking marketing metrics, analyzing performance, and optimizing programs based on results Thrive in fast-paced, high-growth environments and are comfortable with ambiguity and changing priorities Have a \"get it done\" mentality and aren't afraid to jump in wherever needed to ensure program success Care about the societal impacts of AI and are excited about enabling enterprises to adopt AI responsibly Strong candidates may also have Experience in the AI/ML industry or working with AI-powered products Established relationships within the GSI or major consulting firm ecosystem Proven track record launching and scaling new partner programs from the ground up Experience marketing to technical audiences as well as business decision-makers Understanding of enterprise AI use cases across different industries and functions Background in developing partner training and certification programs Experience with marketing automation platforms, CRM systems, and partner relationship management tools Track record of success in high-growth startup environments Role-specific policy: For this role, we expect all staff to be able to work from our San Francisco office at least 2 days a week, though we encourage you to apply even if you might need some flexibility for an interim period of time for relocation. If based in Seattle or New York, this role will require traveling to the San Francisco office once a month. Additionally, this role will also require up to 20% of the time for partner meetings and partner events. Deadline to apply: None. Applications will be reviewed on a rolling basis.The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$255,000 - $320,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5061729008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5061729008",
    "title": "Partner Marketing Lead, GSIs",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5061729008",
    "departments": [
      "Marketing & Brand"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Partner Marketing Manager for Global System Integrators (GSIs) at Anthropic, you will play a pivotal role in building and scaling our partner marketing initiatives with the world&#39;s leading consulting firms and systems integrators. You will develop and execute comprehensive go-to-market programs that drive enterprise adoption of Claude through these strategic partnerships.&lt;/p&gt;\n&lt;p&gt;In this role, you will craft compelling joint value propositions, create executive-level marketing campaigns, and build scalable enablement programs that empower our GSI partners to successfully position and implement Claude for enterprise customers. You&#39;ll be a key connector between Anthropic&#39;s alliances organization and our marketing teams, ensuring seamless execution of high-impact programs that accelerate pipeline and revenue growth.&lt;/p&gt;\n&lt;p&gt;This role requires someone who can think strategically about long-term partner relationships while also rolling up their sleeves to execute flawlessly on campaigns, events, and enablement initiatives. You&#39;ll need to balance the art of relationship-building with the science of measuring marketing impact, always keeping the focus on driving measurable business outcomes for both Anthropic and our GSI partners.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;Partner Marketing Strategy &amp;amp; Execution&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and execute comprehensive go-to-market programs with major GSI partners, focusing on enterprise customer acquisition and AI transformation initiatives&lt;/li&gt;\n&lt;li&gt;Develop joint marketing campaigns targeting C-suite and senior decision-makers at enterprise organizations, creating compelling narratives around AI transformation and business value&lt;/li&gt;\n&lt;li&gt;Create repeatable marketing programs that enable GSI partners to effectively position and sell Claude-powered solutions to their enterprise clients&lt;/li&gt;\n&lt;li&gt;Establish and manage joint business planning processes with key GSI partners, including quarterly planning, campaign calendars, and success metrics&lt;/li&gt;\n&lt;li&gt;Collaborate with partner sales and alliances teams to identify priority accounts and develop account-based marketing strategies that leverage GSI relationships&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;Content &amp;amp; Enablement&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Build partner messaging frameworks and create high-quality enablement materials (pitch decks, solution briefs, case studies, demo scripts) that empower GSI partners to effectively position Claude&lt;/li&gt;\n&lt;li&gt;Develop and deliver partner-specific content that demonstrates the value of Claude integration across different industries and enterprise use cases&lt;/li&gt;\n&lt;li&gt;Create training materials for GSI partners&#39; go-to-market teams, including sales and marketing enablement programs&lt;/li&gt;\n&lt;li&gt;Manage partner resources including brand and co-marketing guidelines, program documentation, and self-service marketing assets&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;Program Management &amp;amp; Execution&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead end-to-end campaign execution with GSI partners, coordinating across product marketing, demand generation, field marketing, and events teams to ensure flawless delivery&lt;/li&gt;\n&lt;li&gt;Manage partner funding programs (MDF/Co-op) and ensure ROI tracking for joint marketing investments&lt;/li&gt;\n&lt;li&gt;Track, measure, and report on partner marketing performance, including partner-sourced pipeline, influenced revenue, and campaign ROI&lt;/li&gt;\n&lt;li&gt;Represent Anthropic at partner events, executive briefings, and industry conferences as needed&lt;/li&gt;\n&lt;li&gt;Build scalable processes and playbooks that can be replicated across the GSI partner ecosystem as we grow&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 10+ years of marketing experience, with significant focus on partner marketing in B2B technology environments&lt;/li&gt;\n&lt;li&gt;Have deep expertise building and executing partner marketing programs with Global System Integrators (GSIs), major consulting firms, or systems integrators&lt;/li&gt;\n&lt;li&gt;Demonstrate strong understanding of enterprise buyer journeys and can create marketing programs that resonate with C-level executives&lt;/li&gt;\n&lt;li&gt;Are skilled at developing compelling joint value propositions that articulate clear business outcomes for enterprise customers&lt;/li&gt;\n&lt;li&gt;Have proven ability to manage complex, cross-functional initiatives with multiple stakeholders across organizations&lt;/li&gt;\n&lt;li&gt;Excel at building trusted relationships with partner marketing and sales teams, establishing yourself as a strategic advisor&lt;/li&gt;\n&lt;li&gt;Are highly organized and detail-oriented, with demonstrated ability to manage multiple programs simultaneously while maintaining quality&lt;/li&gt;\n&lt;li&gt;Possess excellent written and verbal communication skills, with experience creating executive-level content and presentations&lt;/li&gt;\n&lt;li&gt;Are data-driven and comfortable tracking marketing metrics, analyzing performance, and optimizing programs based on results&lt;/li&gt;\n&lt;li&gt;Thrive in fast-paced, high-growth environments and are comfortable with ambiguity and changing priorities&lt;/li&gt;\n&lt;li&gt;Have a &quot;get it done&quot; mentality and aren&#39;t afraid to jump in wherever needed to ensure program success&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of AI and are excited about enabling enterprises to adopt AI responsibly&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience in the AI/ML industry or working with AI-powered products&lt;/li&gt;\n&lt;li&gt;Established relationships within the GSI or major consulting firm ecosystem&lt;/li&gt;\n&lt;li&gt;Proven track record launching and scaling new partner programs from the ground up&lt;/li&gt;\n&lt;li&gt;Experience marketing to technical audiences as well as business decision-makers&lt;/li&gt;\n&lt;li&gt;Understanding of enterprise AI use cases across different industries and functions&lt;/li&gt;\n&lt;li&gt;Background in developing partner training and certification programs&lt;/li&gt;\n&lt;li&gt;Experience with marketing automation platforms, CRM systems, and partner relationship management tools&lt;/li&gt;\n&lt;li&gt;Track record of success in high-growth startup environments&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Role-specific policy:&lt;/strong&gt; For this role, we expect all staff to be able to work from our San Francisco office at least 2 days a week, though we encourage you to apply even if you might need some flexibility for an interim period of time for relocation. If based in Seattle or New York, this role will require traveling to the San Francisco office once a month. Additionally, this role will also require up to 20% of the time for partner meetings and partner events.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply: &lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$255,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$320,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5061729008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Policy Communications Manager",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY; San Francisco, CA | Washington, DC",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4979661008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role Anthropic seeks an exceptional policy communications professional to promote understanding and awareness of the organization’s mission and policy perspectives. Reporting into the Head of Policy Communications, you will work with policy, legal and external affairs to educate press and policy makers in DC and beyond about our products and principles. The ideal candidate should be someone who is a highly skilled in media relations and used to working in a fast-paced environment. They should have the ability to move fast, think critically and work collaboratively on complex issues. A deep understanding of the DC media environment, the technology sector and Anthropic’s varied audiences is key. Responsibilities: Develop and execute proactive communications strategies that effectively communicate our products and plans to key stakeholders Work with the policy team to craft our responses to policy developments that impact the AI industry and architect reactive communications strategies Partner cross functionally with the policy, legal and product teams to prepare for major company announcements and product launches, and to handle inbound media requests Build strong relationships with journalists and relevant influencers in DC and important policy hubs Orchestrate and write company blog posts and other communications materials. Manage executive interviews and speaking engagements. You may be a good fit if you: Have 10+ years directing policy communications at high-growth tech companies and/or successful political campaigns. Want to be part of a fast-paced, small, experienced and impactful team. Enjoy and are excellent at media relations Are a superb written and verbal communicator Enjoy working cross-functionally with a range of technical and non-technical teams. Are excited to translate insights about AI for broader audiences. Are results-oriented and high agency, with a bias towards flexibility and impact. Care about ensuring that transformative AI systems are developed safely. Sample Projects: Lead the communications planning and execution of major company announcements. Oversee executive visits to DC and elsewhere Manage fast moving inbound press enquiries on complex issues. Provide counsel and support to team members across the organization. Deadline to apply: None. Applications will be reviewed on a rolling basis.The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$255,000 - $255,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4979661008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4979661008",
    "title": "Policy Communications Manager",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY; San Francisco, CA | Washington, DC",
    "locations": [
      "San Francisco, CA | New York City, NY; San Francisco, CA | Washington, DC"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4979661008",
    "departments": [
      "Communications"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic seeks an exceptional policy communications professional to promote understanding and awareness of the organization’s mission and policy perspectives.&lt;/p&gt;\n&lt;p&gt;Reporting into the Head of Policy Communications, you will work with policy, legal and external affairs to educate press and policy makers in DC and beyond about our products and principles.&amp;nbsp; The ideal candidate should be someone who is a highly skilled in media relations and used to working in a fast-paced environment.&amp;nbsp; They should have the ability to move fast, think critically and work collaboratively on complex issues. A deep understanding of the DC media environment, the technology sector and Anthropic’s varied audiences is key.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and execute proactive communications strategies that effectively communicate our products and plans to key stakeholders&lt;/li&gt;\n&lt;li&gt;Work with the policy team to craft our responses to policy developments that impact the AI industry and architect reactive communications strategies&lt;/li&gt;\n&lt;li&gt;Partner cross functionally with the policy, legal and product teams to prepare for major company announcements and product launches, and to handle inbound media requests&lt;/li&gt;\n&lt;li&gt;Build strong relationships with journalists and relevant influencers in DC and important policy hubs&lt;/li&gt;\n&lt;li&gt;Orchestrate and write company blog posts and other communications materials.&lt;/li&gt;\n&lt;li&gt;Manage executive interviews and speaking engagements.&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 10+ years directing policy communications at high-growth tech companies and/or successful political campaigns.&lt;/li&gt;\n&lt;li&gt;Want to be part of a fast-paced, small, experienced and impactful team.&lt;/li&gt;\n&lt;li&gt;Enjoy and are excellent at media relations&lt;/li&gt;\n&lt;li&gt;Are a superb written and verbal communicator&lt;/li&gt;\n&lt;li&gt;Enjoy working cross-functionally with a range of technical and non-technical teams.&lt;/li&gt;\n&lt;li&gt;Are excited to translate insights about AI for broader audiences.&lt;/li&gt;\n&lt;li&gt;Are results-oriented and high agency, with a bias towards flexibility and impact.&lt;/li&gt;\n&lt;li&gt;Care about ensuring that transformative AI systems are developed safely.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Sample Projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead the communications planning and execution of major company announcements.&lt;/li&gt;\n&lt;li&gt;Oversee executive visits to DC and elsewhere&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Manage fast moving inbound press enquiries on complex issues.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Provide counsel and support to team members across the organization.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply: &lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$255,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$255,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4979661008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Policy Manager, Chemical Weapons and High Yield Explosives",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5066951008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Responsibilities: Design and implement evaluation methodologies for assessing AI model capabilities relevant to chemical weapons, explosives synthesis, and energetic materials Develop and execute strategies to identify and mitigate potential C/E misuse in model outputs Create C/E threat models, including precursor identification, synthesis routes, and weaponization techniques Review and analyze traffic to identify potential policy violations related to C/E content Collaborate with software engineers to develop and refine detection systems and automated enforcement tools for C/E threats Conduct rapid response to escalations involving dangerous C/E queries Collaborate across teams to establish safety benchmarks and develop appropriate model guardrails Translate C/E domain knowledge into actionable safety requirements Develop approaches to assess C/E model knowledge boundaries for dual-use chemical information Monitor emerging threats in the C/E landscape to inform policy development You may be a good fit if you: Have a Ph.D. in Chemistry, Chemical Engineering, or a related field with focus on energetic materials, explosives, and/or chemical weapons Have 5-8+ years of experience in chemical weapons and/or explosives defense, with deep expertise in energetic materials, chemical weapon agents, or related areas Have knowledge of high yield explosives application to radiological dispersal devices (dirty bombs) and related radiological weapons Have a track record of translating specialized technical knowledge into actionable safety policies or guidelines Are comfortable navigating ambiguity and developing solutions for novel safety challenges Can work independently while maintaining strong collaboration with cross-functional teams including engineering, enforcement, and research Thrive in a fast-paced environment where you balance rigorous scientific standards with rapid threat response Are passionate about preventing misuse of dangerous technical knowledge while enabling beneficial applications Strong candidates may have: Experience with both chemical weapons and high yield explosives defense Experience working with defense, intelligence, or nonproliferation organizations (e.g., OPCW, IAEA, national labs, defense contractors) Published research or practical experience in explosives characterization, chemical weapons detection, or related security applications Knowledge of international chemical weapons conventions (CWC) and controlled substances regulations Demonstrated ability to communicate complex technical concepts to non-specialist audiences Experience with chemical databases (PubChem, Reaxys, SciFinder) and computational chemistry tools Understanding of radiological materials and their interaction with explosive dispersal mechanisms Familiarity with dual-use C/E research concerns and responsible disclosure practices This role offers a unique opportunity to shape how AI systems handle sensitive chemical and explosives information. You'll work with leading AI safety researchers while tackling critical problems in preventing catastrophic misuse. If you're excited about using your expertise to ensure AI systems remain safe and beneficial, we want to hear from you.The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$245,000 - $285,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5066951008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5066951008",
    "title": "Policy Manager, Chemical Weapons and High Yield Explosives",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5066951008",
    "departments": [
      "Safeguards (Trust & Safety) "
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement evaluation methodologies for assessing AI model capabilities relevant to chemical weapons, explosives synthesis, and energetic materials&lt;/li&gt;\n&lt;li&gt;Develop and execute strategies to identify and mitigate potential C/E misuse in model outputs&lt;/li&gt;\n&lt;li&gt;Create C/E threat models, including precursor identification, synthesis routes, and weaponization techniques&lt;/li&gt;\n&lt;li&gt;Review and analyze traffic to identify potential policy violations related to C/E content&lt;/li&gt;\n&lt;li&gt;Collaborate with software engineers to develop and refine detection systems and automated enforcement tools for C/E threats&lt;/li&gt;\n&lt;li&gt;Conduct rapid response to escalations involving dangerous C/E queries&lt;/li&gt;\n&lt;li&gt;Collaborate across teams to establish safety benchmarks and develop appropriate model guardrails&lt;/li&gt;\n&lt;li&gt;Translate C/E domain knowledge into actionable safety requirements&lt;/li&gt;\n&lt;li&gt;Develop approaches to assess C/E model knowledge boundaries for dual-use chemical information&lt;/li&gt;\n&lt;li&gt;Monitor emerging threats in the C/E landscape to inform policy development&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have a Ph.D. in Chemistry, Chemical Engineering, or a related field with focus on energetic materials, explosives, and/or chemical weapons&lt;/li&gt;\n&lt;li&gt;Have 5-8+ years of experience in chemical weapons and/or explosives defense, with deep expertise in energetic materials, chemical weapon agents, or related areas&lt;/li&gt;\n&lt;li&gt;Have knowledge of high yield explosives application to radiological dispersal devices (dirty bombs) and related radiological weapons&lt;/li&gt;\n&lt;li&gt;Have a track record of translating specialized technical knowledge into actionable safety policies or guidelines&lt;/li&gt;\n&lt;li&gt;Are comfortable navigating ambiguity and developing solutions for novel safety challenges&lt;/li&gt;\n&lt;li&gt;Can work independently while maintaining strong collaboration with cross-functional teams including engineering, enforcement, and research&lt;/li&gt;\n&lt;li&gt;Thrive in a fast-paced environment where you balance rigorous scientific standards with rapid threat response&lt;/li&gt;\n&lt;li&gt;Are passionate about preventing misuse of dangerous technical knowledge while enabling beneficial applications&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with both chemical weapons and high yield explosives defense&lt;/li&gt;\n&lt;li&gt;Experience working with defense, intelligence, or nonproliferation organizations (e.g., OPCW, IAEA, national labs, defense contractors)&lt;/li&gt;\n&lt;li&gt;Published research or practical experience in explosives characterization, chemical weapons detection, or related security applications&lt;/li&gt;\n&lt;li&gt;Knowledge of international chemical weapons conventions (CWC) and controlled substances regulations&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to communicate complex technical concepts to non-specialist audiences&lt;/li&gt;\n&lt;li&gt;Experience with chemical databases (PubChem, Reaxys, SciFinder) and computational chemistry tools&lt;/li&gt;\n&lt;li&gt;Understanding of radiological materials and their interaction with explosive dispersal mechanisms&lt;/li&gt;\n&lt;li&gt;Familiarity with dual-use C/E research concerns and responsible disclosure practices&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;This role offers a unique opportunity to shape how AI systems handle sensitive chemical and explosives information. You&#39;ll work with leading AI safety researchers while tackling critical problems in preventing catastrophic misuse. If you&#39;re excited about using your expertise to ensure AI systems remain safe and beneficial, we want to hear from you.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$245,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$285,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5066951008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Policy Manager, Harmful Persuasion ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5074933008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Safeguards Product Policy Manager for Harmful Persuasion, you will be responsible for developing, refining, and maintaining policies that prevent the misuse of AI systems for influence operations, harmful manipulation, and fraudulent behaviors at scale. In this role, you will function as the policy owner for a range of harmful persuasion risks and shape the policy frameworks across several policy areas including: election integrity, information integrity and fraud. As a member of the Safeguards team, your initial focus will be on translating the Harmful Persuasion risk framework into clear, enforceable policies, ensuring policy language addresses emerging threats identified by partner teams, and establishing guidelines that enable consistent enforcement decisions. This role may expand to include emerging manipulation vectors as AI capabilities advance. Safety is core to our mission and you'll help ensure our policies prevent our products from being weaponized to undermine civic processes, exploit vulnerable populations, or degrade information ecosystems. *Important context for this role: In this position you may be exposed to and engage with explicit content spanning a range of topics, including those of a sexual, violent, or psychologically disturbing nature. Responsibilities: Develop and maintain comprehensive policy frameworks for harmful persuasion risks, especially in the context of election integrity, influence operations, and fraud Design clear, enforceable policy language that can be consistently applied by enforcement teams and translated into technical detection requirements Design and oversee execution of evaluations to assess the model’s capability to leverage, produce and execute deceptive and harmful persuasive techniques. Write and refine external-facing Usage Policy language that clearly communicates policy violations and restrictions to users and external stakeholders Develop training guidelines, assessment rubrics, and evaluation protocols Validate enforcement decisions and automated assessments, providing qualitative analysis and policy guidance on complex edge cases Coordinate with external experts, civil society organizations, and academic to gather feedback on policy clarity and coverage Provide policy input on UX design for interventions, ensuring user-facing elements align with policy intent and minimize friction for legitimate use Contribute to model safety improvements in conjunction with the Finetuning team Support regulatory compliance efforts including consultations related to the EU AI Act and other emerging AI governance frameworks Function as an escalation point for complex harmful persuasion cases requiring expert policy judgment You may be a good fit if you have: 5+ years of experience in policy development, trust & safety policy, or platform policy with working experience across the following: election integrity, fraud/scams, coordinated inauthentic behavior, influence operations, or misinformation General knowledge of the global regulatory landscape around election integrity, platform regulation, and digital services accountability Strong policy writing skills with the ability to translate complex risk frameworks into clear, enforceable guidelines Experience designing policies and workflows that enable both clear human enforcement decision-making and technical implementation in ML classifiers and detection pipelines Strong collaboration skills and extensive experience partnering effectively with Engineering, Data Science, Legal, and Policy teams on cross-functional initiatives Excellent written and verbal communication skills, with the ability to explain complex manipulation tactics and policy rationales to diverse audiences Preferred qualifications: Strong familiarity in election integrity, political psychology, information integrity, and democratic resilience research Knowledge of persuasion theory, influence tactics, cognitive biases, and psychological manipulation techniques Experience working with EU institutions, regulatory bodies, or policy organizations on AI governance or digital platform regulation Experience conducting adversarial testing, red teaming, or vulnerability assessments for AI systems or platforms Familiarity with generative AI capabilities and understanding of how LLMs can be used for personalized persuasion, social engineering, or influence at scale The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$245,000 - $330,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5074933008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5074933008",
    "title": "Policy Manager, Harmful Persuasion ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5074933008",
    "departments": [
      "Safeguards (Trust & Safety) "
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Safeguards Product Policy Manager for Harmful Persuasion, you will be responsible for developing, refining, and maintaining policies that prevent the misuse of AI systems for influence operations, harmful manipulation, and fraudulent behaviors at scale. In this role, you will function as the policy owner for a range of harmful persuasion risks and shape the policy frameworks across several policy areas including: election integrity, information integrity and fraud.&lt;/p&gt;\n&lt;p&gt;As a member of the Safeguards team, your initial focus will be on translating the Harmful Persuasion risk framework into clear, enforceable policies, ensuring policy language addresses emerging threats identified by partner teams, and establishing guidelines that enable consistent enforcement decisions. This role may expand to include emerging manipulation vectors as AI capabilities advance. Safety is core to our mission and you&#39;ll help ensure our policies prevent our products from being weaponized to undermine civic processes, exploit vulnerable populations, or degrade information ecosystems.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;*Important context for this role: In this position you may be exposed to and engage with explicit content spanning a range of topics, including those of a sexual, violent, or psychologically disturbing nature.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and maintain comprehensive policy frameworks for harmful persuasion risks, especially in the context of election integrity, influence operations, and fraud&lt;/li&gt;\n&lt;li&gt;Design clear, enforceable policy language that can be consistently applied by enforcement teams and translated into technical detection requirements&lt;/li&gt;\n&lt;li&gt;Design and oversee execution of evaluations to assess the model’s capability to leverage, produce and execute deceptive and harmful persuasive techniques.&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;ul&gt;\n&lt;li&gt;Write and refine external-facing Usage Policy language that clearly communicates policy violations and restrictions to users and external stakeholders&lt;/li&gt;\n&lt;li&gt;Develop training guidelines, assessment rubrics, and evaluation protocols&lt;/li&gt;\n&lt;li&gt;Validate enforcement decisions and automated assessments, providing qualitative analysis and policy guidance on complex edge cases&lt;/li&gt;\n&lt;li&gt;Coordinate with external experts, civil society organizations, and academic to gather feedback on policy clarity and coverage&lt;/li&gt;\n&lt;li&gt;Provide policy input on UX design for interventions, ensuring user-facing elements align with policy intent and minimize friction for legitimate use&lt;/li&gt;\n&lt;li&gt;Contribute to model safety improvements in conjunction with the Finetuning team&lt;/li&gt;\n&lt;li&gt;Support regulatory compliance efforts including consultations related to the EU AI Act and other emerging AI governance frameworks&lt;/li&gt;\n&lt;li&gt;Function as an escalation point for complex harmful persuasion cases requiring expert policy judgment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in policy development, trust &amp;amp; safety policy, or platform policy with working experience across the following: election integrity, fraud/scams, coordinated inauthentic behavior, influence operations, or misinformation&lt;/li&gt;\n&lt;li&gt;General knowledge of the global regulatory landscape around election integrity, platform regulation, and digital services accountability&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Strong policy writing skills with the ability to translate complex risk frameworks into clear, enforceable guidelines&lt;/li&gt;\n&lt;li&gt;Experience designing policies and workflows that enable both clear human enforcement decision-making and technical implementation in ML classifiers and detection pipelines&lt;/li&gt;\n&lt;li&gt;Strong collaboration skills and extensive experience partnering effectively with Engineering, Data Science, Legal, and Policy teams on cross-functional initiatives&lt;/li&gt;\n&lt;li&gt;Excellent written and verbal communication skills, with the ability to explain complex manipulation tactics and policy rationales to diverse audiences&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Preferred qualifications:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Strong familiarity in election integrity, political psychology, information integrity,&amp;nbsp; and democratic resilience research&lt;/li&gt;\n&lt;li&gt;Knowledge of persuasion theory, influence tactics, cognitive biases, and psychological manipulation techniques&lt;/li&gt;\n&lt;li&gt;Experience working with EU institutions, regulatory bodies, or policy organizations on AI governance or digital platform regulation&lt;/li&gt;\n&lt;li&gt;Experience conducting adversarial testing, red teaming, or vulnerability assessments for AI systems or platforms&lt;/li&gt;\n&lt;li&gt;Familiarity with generative AI capabilities and understanding of how LLMs can be used for personalized persuasion, social engineering, or influence at scale&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$245,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$330,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5074933008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Manager, API ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4936029008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Product Manager for our API team at Anthropic, you will drive the development and adoption of our API platform across enterprise organizations. You'll own the end-to-end enterprise API experience, focusing on building scalable, secure, and compliant solutions that enable organizations to confidently integrate Claude into their systems and workflows. Working at the intersection of developer experience and enterprise needs, you'll transform our API into a trusted enterprise solution that delivers measurable value across teams and functions. Responsibilities: Customer Understanding & Advocacy Deeply engage with enterprise developers and technical leaders to understand their integration needs and pain points Run regular feedback sessions and technical reviews with key enterprise customers Build strong relationships with enterprise development teams to understand their workflows and challenges Transform customer insights into actionable product requirements and priorities Product Strategy & Vision Define and execute the enterprise API strategy, balancing security requirements with developer experience Develop a clear roadmap for enterprise API features including authentication, rate limiting, and compliance capabilities Identify and prioritize key enterprise integration patterns that drive organizational value Enterprise API Development Partner with engineering to build enterprise-grade API features, security controls, and deployment tools Design and implement enterprise integration frameworks and SDKs for common enterprise systems Drive development of industry-specific API features and compliance capabilities Cross-functional Leadership Partner with sales and customer success to understand enterprise requirements and support technical evaluations Work closely with security and compliance teams to meet enterprise standards Collaborate with platform teams on API architecture and scalability Engage with marketing to develop enterprise API positioning and technical materials You may be a good fit if you have: 5+ years of product management experience, with significant experience in API and enterprise software Strong technical background with understanding of API architecture and integration patterns Track record of successfully launching and scaling enterprise API products Demonstrated ability to build strong relationships with technical customers and translate their needs into product features Strong understanding of enterprise security, compliance, and deployment requirements Proficiency in with business analytics and experience with data-driven decision making Excellence in cross-functional collaboration and stakeholder management Clear communication skills with ability to engage with both technical and business stakeholders The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$305,000 - $385,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4936029008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4936029008",
    "title": "Product Manager, API ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4936029008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&amp;nbsp;&lt;/h2&gt;\n&lt;p&gt;As a Product Manager for our API team at Anthropic, you will drive the development and adoption of our API platform across enterprise organizations. You&#39;ll own the end-to-end enterprise API experience, focusing on building scalable, secure, and compliant solutions that enable organizations to confidently integrate Claude into their systems and workflows. Working at the intersection of developer experience and enterprise needs, you&#39;ll transform our API into a trusted enterprise solution that delivers measurable value across teams and functions.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Customer Understanding &amp;amp; Advocacy&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Deeply engage with enterprise developers and technical leaders to understand their integration needs and pain points&lt;/li&gt;\n&lt;li&gt;Run regular feedback sessions and technical reviews with key enterprise customers&lt;/li&gt;\n&lt;li&gt;Build strong relationships with enterprise development teams to understand their workflows and challenges&lt;/li&gt;\n&lt;li&gt;Transform customer insights into actionable product requirements and priorities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Product Strategy &amp;amp; Vision&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Define and execute the enterprise API strategy, balancing security requirements with developer experience&lt;/li&gt;\n&lt;li&gt;Develop a clear roadmap for enterprise API features including authentication, rate limiting, and compliance capabilities&lt;/li&gt;\n&lt;li&gt;Identify and prioritize key enterprise integration patterns that drive organizational value&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Enterprise API Development&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Partner with engineering to build enterprise-grade API features, security controls, and deployment tools&lt;/li&gt;\n&lt;li&gt;Design and implement enterprise integration frameworks and SDKs for common enterprise systems&lt;/li&gt;\n&lt;li&gt;Drive development of industry-specific API features and compliance capabilities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Cross-functional Leadership&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Partner with sales and customer success to understand enterprise requirements and support technical evaluations&lt;/li&gt;\n&lt;li&gt;Work closely with security and compliance teams to meet enterprise standards&lt;/li&gt;\n&lt;li&gt;Collaborate with platform teams on API architecture and scalability&lt;/li&gt;\n&lt;li&gt;Engage with marketing to develop enterprise API positioning and technical materials&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of product management experience, with significant experience in API and enterprise software&lt;/li&gt;\n&lt;li&gt;Strong technical background with understanding of API architecture and integration patterns&lt;/li&gt;\n&lt;li&gt;Track record of successfully launching and scaling enterprise API products&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to build strong relationships with technical customers and translate their needs into product features&lt;/li&gt;\n&lt;li&gt;Strong understanding of enterprise security, compliance, and deployment requirements&lt;/li&gt;\n&lt;li&gt;Proficiency in with business analytics and experience with data-driven decision making&lt;/li&gt;\n&lt;li&gt;Excellence in cross-functional collaboration and stakeholder management&lt;/li&gt;\n&lt;li&gt;Clear communication skills with ability to engage with both technical and business stakeholders&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$305,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$385,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4936029008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Manager, Claude Code",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4985920008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Product Manager for Claude Code, you will drive the evolution of the Claude Code product suite and help shape how developers work with AI. You will work closely with internal users and customers to prioritize their requirements and ship improvements to Claude Code. You will work closely with the engineering team, research team, and XFN teams to ensure Claude Code remains ahead of model capabilities and is seen as the best way to experience the most intelligent Claude models. In just a few months since launch, Claude Code has already redefined how developers interact with AI. Yet we are only scratching the surface. As model intelligence accelerates, the ultimate form factor of agentic software development remains unwritten. We seek a product manager who combines deep technical understanding, genuine love for developers, and strong product intuition. You should be equally comfortable discussing customer feedback with world-class researchers, debugging user workflows with engineers, and presenting product strategy to executives. Responsibilities: Define the roadmap for an area of the Claude Code product suite Translate cutting-edge AI advances into practical developer features Build an ecosystem around the CLI and other products so that developers can easily share best practices You might be a good fit if you: Have a combined 5+ years in product management and engineering, including at least 1 year as a professional engineer. Have a deep technical background with experience working cross-functionally with engineering teams to ship technical products. Track record of launching ambitious products that have achieved distribution or commercial success. Experience in dev tools is preferred. Stay up-to-date and hands-on with AI coding tools, model capabilities, and industry trends Have a creative, hacker spirit and love solving puzzles The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$285,000 - $305,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4985920008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4985920008",
    "title": "Product Manager, Claude Code",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | Seattle, WA",
    "locations": [
      "San Francisco, CA | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4985920008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a Product Manager for Claude Code, you will drive the evolution of the Claude Code product suite and help shape how developers work with AI. You will work closely with internal users and customers to prioritize their requirements and ship improvements to Claude Code. You will work closely with the engineering team, research team, and XFN teams to ensure Claude Code remains ahead of model capabilities and is seen as the best way to experience the most intelligent Claude models.&lt;/p&gt;\n&lt;p&gt;In just a few months since launch, Claude Code has already redefined how developers interact with AI. Yet we are only scratching the surface. As model intelligence accelerates, the ultimate form factor of agentic software development remains unwritten. We seek a product manager who combines deep technical understanding, genuine love for developers, and strong product intuition. You should be equally comfortable discussing customer feedback with world-class researchers, debugging user workflows with engineers, and presenting product strategy to executives.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Define the roadmap for an area of the Claude Code product suite&lt;/li&gt;\n&lt;li&gt;Translate cutting-edge AI advances into practical developer features&lt;/li&gt;\n&lt;li&gt;Build an ecosystem around the CLI and other products so that developers can easily share best practices&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You might be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have a combined 5+ years in product management and engineering, including at least 1 year as a professional engineer.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Have a deep technical background with experience working cross-functionally with engineering teams to ship technical products.&lt;/li&gt;\n&lt;li&gt;Track record of launching ambitious products that have achieved distribution or commercial success. Experience in dev tools is preferred.&lt;/li&gt;\n&lt;li&gt;Stay up-to-date and hands-on with AI coding tools, model capabilities, and industry trends&lt;/li&gt;\n&lt;li&gt;Have a creative, hacker spirit and love solving puzzles&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$285,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4985920008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Manager, Claude Code (Enterprise)",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4858247008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Product Manager for Claude Code, you will drive the adoption of Claude Code in the enterprise with the goal of making Claude Code the most widely used and trusted product for professional engineers to get work done. You will own working closely with our enterprise customers, understand their requirements, and build features that unlock adoption and that increase Claude Code’s utility. In just a few months since launch, Claude Code has already redefined how developers interact with AI. Yet we are only scratching the surface. As model intelligence accelerates, the ultimate form factor of agentic software development remains unwritten. We seek a product manager who combines deep technical understanding, genuine love for developers, strong product intuition, and passion for making enterprises successful. You should be equally comfortable discussing customer feedback with world-class researchers, debugging user workflows with engineers, and presenting product strategy to executives. Responsibilities: Define and execute the product vision and strategy to make Claude Code accessible and valuable to enterprise users Identify and prioritize key features that drive sustainable business growth Own pricing, packaging, and enterprise go-to-market strategy You might be a good fit if you: Have combined 5+ years in product management, with experience launching new products and scaling existing technical products. Possess a deep technical background with experience working cross-functionally with engineering teams to ship technical products. A data-driven mindset with Python and SQL working proficiency is a must. Have a track record of launching ambitious products that have achieved distribution or commercial success with enterprise customers. Stay up-to-date and hands-on with emerging research and industry trends Have a creative, hacker spirit and love solving puzzles The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$285,000 - $305,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4858247008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4858247008",
    "title": "Product Manager, Claude Code (Enterprise)",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | Seattle, WA",
    "locations": [
      "San Francisco, CA | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4858247008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a Product Manager for Claude Code, you will drive the adoption of Claude Code in the enterprise with the goal of making Claude Code the most widely used and trusted product for professional engineers to get work done. You will own working closely with our enterprise customers, understand their requirements, and build features that unlock adoption and that increase Claude Code’s utility.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;In just a few months since launch, Claude Code has already redefined how developers interact with AI. Yet we are only scratching the surface. As model intelligence accelerates, the ultimate form factor of agentic software development remains unwritten. We seek a product manager who combines deep technical understanding, genuine love for developers, strong product intuition, and passion for making enterprises successful. You should be equally comfortable discussing customer feedback with world-class researchers, debugging user workflows with engineers, and presenting product strategy to executives.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Define and execute the product vision and strategy to make Claude Code accessible and valuable to enterprise users&lt;/li&gt;\n&lt;li&gt;Identify and prioritize key features that drive sustainable business growth&lt;/li&gt;\n&lt;li&gt;Own pricing, packaging, and enterprise go-to-market strategy&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You might be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have combined 5+ years in product management, with experience launching new products and scaling existing technical products.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Possess a deep technical background with experience working cross-functionally with engineering teams to ship technical products. A data-driven mindset with Python and SQL working proficiency is a must.&lt;/li&gt;\n&lt;li&gt;Have a track record of launching ambitious products that have achieved distribution or commercial success with enterprise customers.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Stay up-to-date and hands-on with emerging research and industry trends&lt;/li&gt;\n&lt;li&gt;Have a creative, hacker spirit and love solving puzzles&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$285,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4858247008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Manager, Claude Code Growth",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5024981008",
    "job_posted_at_datetime_utc": "2026-01-29T17:49:55-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As a Product Manager for Claude Code Growth, you will play a crucial role in driving acquisition, monetization, retention, and virality for Claude Code. You'll work closely with a cross-functional team of engineers, designers, marketers, and data scientists to develop and execute strategies that accelerate our growth while maintaining our commitment to safety and beneficial AI. Responsibilities: Develop and execute a product strategy focused on acquisition, monetization, virality, and retention for Claude Code Lead the ideation, development, and launch of features that drive growth across our product suite Analyze product metrics and user feedback to identify opportunities and optimize performance Collaborate with engineering, design, and marketing teams to deliver high-impact growth initiatives Conduct user research to understand customer needs and pain points Define and track key performance indicators (KPIs) for growth initiatives Balance rapid iteration with our commitment to AI safety and ethics Qualifications: 6-10 years of product management experience, majority in growth focused roles Growth experience on mass-scale B2C products, bonus for subscription businesses Strong analytical skills, and experience with A/B testing and funnel optimization Excellent communication and stakeholder management skills Ability to thrive in a fast-paced, ambiguous environment Passion for AI technology and its potential impact on society Technical background or ability to work effectively with engineering teams Founder experience is a plus The annual compensation range for this role is listed below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.Annual Salary:$275,000 - $305,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5024981008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5024981008",
    "title": "Product Manager, Claude Code Growth",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5024981008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2026-01-29T17:49:55-05:00",
    "fetched_at": "2026-02-03T12:56:54.862Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Product Manager for Claude Code Growth, you will play a crucial role in driving acquisition, monetization, retention, and virality for Claude Code. You&#39;ll work closely with a cross-functional team of engineers, designers, marketers, and data scientists to develop and execute strategies that accelerate our growth while maintaining our commitment to safety and beneficial AI.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and execute a product strategy focused on acquisition, monetization, virality, and retention for Claude Code&lt;/li&gt;\n&lt;li&gt;Lead the ideation, development, and launch of features that drive growth across our product suite&lt;/li&gt;\n&lt;li&gt;Analyze product metrics and user feedback to identify opportunities and optimize performance&lt;/li&gt;\n&lt;li&gt;Collaborate with engineering, design, and marketing teams to deliver high-impact growth initiatives&lt;/li&gt;\n&lt;li&gt;Conduct user research to understand customer needs and pain points&lt;/li&gt;\n&lt;li&gt;Define and track key performance indicators (KPIs) for growth initiatives&lt;/li&gt;\n&lt;li&gt;Balance rapid iteration with our commitment to AI safety and ethics&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Qualifications:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;6-10 years of product management experience, majority in growth focused roles&lt;/li&gt;\n&lt;li&gt;Growth experience on mass-scale B2C products, bonus for subscription businesses&lt;/li&gt;\n&lt;li&gt;Strong analytical skills, and experience with A/B testing and funnel optimization&lt;/li&gt;\n&lt;li&gt;Excellent communication and stakeholder management skills&lt;/li&gt;\n&lt;li&gt;Ability to thrive in a fast-paced, ambiguous environment&lt;/li&gt;\n&lt;li&gt;Passion for AI technology and its potential impact on society&lt;/li&gt;\n&lt;li&gt;Technical background or ability to work effectively with engineering teams&lt;/li&gt;\n&lt;li&gt;Founder experience is a plus&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is listed below.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$275,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt; To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. In some cases, we may partner with vetted recruiting agencies who will identify themselves as working on behalf of Anthropic. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5024981008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]