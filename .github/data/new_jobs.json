[
  {
    "job_title": "Senior Client Partner, Large Customer Sales (Alcohol)",
    "employer_name": "reddit",
    "job_city": "New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/reddit/jobs/7367778",
    "job_posted_at_datetime_utc": "2026-01-11T18:27:39-05:00",
    "job_description": "Reddit is a community of communities. It’s built on shared interests, passion, and trust, and is home to the most open and authentic conversations on the internet. Every day, Reddit users submit, vote, and comment on the topics they care most about. With 100,000+ active communities and approximately 116 million daily active unique visitors, Reddit is one of the internet’s largest sources of information. For more information, visit www.redditinc.com. We're looking for an experienced seller to join the Restaurants & AlcBev vertical of our Large Customer Sales team. As a Senior Client Partner, you will be responsible for forming relationships with key brands and agencies while ensuring they meet their business objectives using Reddit's advertising suite. Responsibilities: Proactively manage and deepen relationships with existing advertising partners, both with agencies and directly with clients to drive year-over-year revenue growth Proactively construct upfront and joint business plans with top clients Establish mutually beneficial relationships with new clients, educating them on Reddit and the Reddit ads platform Leverage agency and client direct relationships to identify new buyers of Reddit advertising products Leverage data from internal and external sources to inform client strategies and pitch proposals Consistently meet deadlines for all projects, ensuring that clients receive the highest level of customer service Act as an internal lead by actively volunteering in team meetings and Reddit special projects Own client meetings from agenda to final presentation, instilling confidence and setting all interactions up for success by appropriately setting client expectations, identifying outcomes, and communicating clear next steps Act as the primary point of contact for clients to communicate major platform updates, releases, changes, and/or opportunities that will deepen or expand the relationship Provide strategic, proactive, and consultative advice to clients in order to uplevel and grow the relationship Persistently explore and uncover the needs of your clients, leveraging deep product knowledge to align their goals with new and unique opportunities on the platform Collaborate with Account Management and Ad Operations to meet and exceed clients’ marketing goals Shape Reddit’s ads product roadmap by aggregating and sharing client feedback and campaign metrics with cross-functional stakeholders Provide thought leadership and act as a Reddit evangelist with partners and at industry events Share your industry, client, and product expertise by mentoring and training other team members Collaborate closely with other Client Partners and Account Managers to craft a cohesive strategy across shared accounts Build and leverage deep internal relationships, both within your direct team and cross-functionally, working together to deliver on client and business goals Required Qualifications: 12+ years of experience in digital media with at least 7+ years of experience in sales, Alcohol client experience preferred Experience owning partnerships with complex enterprise tech organizations Proven experience managing relationships up through C-level executives Deep industry expertise in specific verticals, product types, and/or measurement solutions Deep existing relationships within the agency and client direct space Subject matter expertise in the social media landscape and native advertising Experience building and executing long-term account growth strategies Demonstrated top-performer achievement against sales targets Ability to lead special projects BA / BS degree or equivalent work experience Benefits: Comprehensive Healthcare Benefits and Income Replacement Programs 401k with Employer Match Global Benefit programs that fit your lifestyle, from workspace to professional development to caregiving support Family Planning Support Gender-Affirming Care Mental Health & Coaching Benefits Flexible Vacation & Paid Volunteer Time Off Generous Paid Parental Leave #LI-JS1 #LI-onsite Pay Transparency: This job posting may span more than one career level. In addition to base salary, this job is eligible to receive equity in the form of restricted stock units, and will also be eligible to receive a commission. Additionally, Reddit offers a wide range of benefits to U.S.-based employees, including medical, dental, and vision insurance, 401(k) program with employer match, generous time off for vacation, and parental leave. To learn more, please visit https://www.redditinc.com/careers/. To provide greater transparency to candidates, we share base pay ranges for all US-based job postings regardless of state. We set standard base pay ranges for all roles based on function, level, and country location, benchmarked against similar stage growth companies. Final offer amounts are determined by multiple factors including, skills, depth of work experience and relevant licenses/credentials, and may vary from the amounts listed below.The base pay range for this position is:$124,700 - $199,100 USDIn select roles and locations, the interviews will be recorded, transcribed and summarized by artificial intelligence (AI). You will have the opportunity to opt out of recording, transcription and summarization prior to any scheduled interviews. During the interview, we will collect the following categories of personal information: Identifiers, Professional and Employment-Related Information, Sensory Information (audio/video recording), and any other categories of personal information you choose to share with us. We will use this information to evaluate your application for employment or an independent contractor role, as applicable. We will not sell your personal information or disclose it to any third party for their marketing purposes. We will delete any recording of your interview promptly after making a hiring decision. For more information about how we will handle your personal information, including our retention of it, please refer to our Candidate Privacy Policy for Potential Employees and Contractors. Reddit is proud to be an equal opportunity employer, and is committed to building a workforce representative of the diverse communities we serve. Reddit is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If, due to a disability, you need an accommodation during the interview process, please let your recruiter know.",
    "id": "job-boards-greenhouse-io-reddit-jobs-7367778",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7367778",
    "title": "Senior Client Partner, Large Customer Sales (Alcohol)",
    "company_name": "reddit",
    "company_slug": "reddit",
    "location": "New York City, NY",
    "locations": [
      "New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/reddit/jobs/7367778",
    "departments": [
      "Large Customer Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-11T18:27:39-05:00",
    "fetched_at": "2026-01-12T18:26:19.675Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;div class=&quot;c-message_kit__blocks c-message_kit__blocks--rich_text&quot;&gt;\n&lt;div class=&quot;c-message__message_blocks c-message__message_blocks--rich_text&quot; data-qa=&quot;message-text&quot;&gt;\n&lt;div class=&quot;p-block_kit_renderer&quot; data-qa=&quot;block-kit-renderer&quot;&gt;\n&lt;div class=&quot;p-block_kit_renderer__block_wrapper p-block_kit_renderer__block_wrapper--first&quot;&gt;\n&lt;div class=&quot;p-rich_text_block&quot;&gt;\n&lt;div class=&quot;p-rich_text_section&quot;&gt;Reddit is a community of communities. It’s built on shared interests, passion, and trust, and is home to the most open and authentic conversations on the internet. Every day, Reddit users submit, vote, and comment on the topics they care most about. With 100,000+ active communities and approximately 116 million daily active unique visitors, Reddit is one of the internet’s largest sources of information. For more information, visit &lt;a class=&quot;c-link&quot; href=&quot;http://www.redditinc.com/&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://redditinc.com&quot; data-sk=&quot;tooltip_parent&quot;&gt;www.redditinc.com&lt;/a&gt;.&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;/div&gt;&lt;p&gt;We&#39;re looking for an experienced seller to join the Restaurants &amp;amp; AlcBev vertical of our Large Customer Sales team. As a Senior Client Partner, you will be responsible for forming relationships with key brands and agencies while ensuring they meet their business objectives using Reddit&#39;s advertising suite.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Proactively manage and deepen relationships with existing advertising partners, both with agencies and directly with clients to drive year-over-year revenue growth&lt;/li&gt;\n&lt;li&gt;Proactively construct upfront and joint business plans with top clients&lt;/li&gt;\n&lt;li&gt;Establish mutually beneficial relationships with new clients, educating them on Reddit and the Reddit ads platform&lt;/li&gt;\n&lt;li&gt;Leverage agency and client direct relationships to identify new buyers of Reddit advertising products&lt;/li&gt;\n&lt;li&gt;Leverage data from internal and external sources to inform client strategies and pitch proposals&lt;/li&gt;\n&lt;li&gt;Consistently meet deadlines for all projects, ensuring that clients receive the highest level of customer service&lt;/li&gt;\n&lt;li&gt;Act as an internal lead by actively volunteering in team meetings and Reddit special projects&lt;/li&gt;\n&lt;li&gt;Own client meetings from agenda to final presentation, instilling confidence and setting all interactions up for success by appropriately setting client expectations, identifying outcomes, and communicating clear next steps&lt;/li&gt;\n&lt;li&gt;Act as the primary point of contact for clients to communicate major platform updates, releases, changes, and/or opportunities that will deepen or expand the relationship&lt;/li&gt;\n&lt;li&gt;Provide strategic, proactive, and consultative advice to clients in order to uplevel and grow the relationship&lt;/li&gt;\n&lt;li&gt;Persistently explore and uncover the needs of your clients, leveraging deep product knowledge to align their goals with new and unique opportunities on the platform&lt;/li&gt;\n&lt;li&gt;Collaborate with Account Management and Ad Operations to meet and exceed clients’ marketing goals&lt;/li&gt;\n&lt;li&gt;Shape Reddit’s ads product roadmap by aggregating and sharing client feedback and campaign metrics with cross-functional stakeholders&lt;/li&gt;\n&lt;li&gt;Provide thought leadership and act as a Reddit evangelist with partners and at industry events&lt;/li&gt;\n&lt;li&gt;Share your industry, client, and product expertise by mentoring and training other team members&lt;/li&gt;\n&lt;li&gt;Collaborate closely with other Client Partners and Account Managers to craft a cohesive strategy across shared accounts&lt;/li&gt;\n&lt;li&gt;Build and leverage deep internal relationships, both within your direct team and cross-functionally, working together to deliver on client and business goals&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Required Qualifications:&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;12+ years of experience in digital media with at least 7+ years of experience in sales, Alcohol client experience preferred&lt;/li&gt;\n&lt;li&gt;Experience owning partnerships with complex enterprise tech organizations&lt;/li&gt;\n&lt;li&gt;Proven experience managing relationships up through C-level executives&lt;/li&gt;\n&lt;li&gt;Deep industry expertise in specific verticals, product types, and/or measurement solutions&lt;/li&gt;\n&lt;li&gt;Deep existing relationships within the agency and client direct space&lt;/li&gt;\n&lt;li&gt;Subject matter expertise in the social media landscape and native advertising&lt;/li&gt;\n&lt;li&gt;Experience building and executing long-term account growth strategies&lt;/li&gt;\n&lt;li&gt;Demonstrated top-performer achievement against sales targets&lt;/li&gt;\n&lt;li&gt;Ability to lead special projects&lt;/li&gt;\n&lt;li&gt;BA / BS degree or equivalent work experience&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Comprehensive Healthcare Benefits and Income Replacement Programs&lt;/li&gt;\n&lt;li&gt;401k with Employer Match&lt;/li&gt;\n&lt;li&gt;Global Benefit programs that fit your lifestyle, from workspace to professional development to caregiving support&lt;/li&gt;\n&lt;li&gt;Family Planning Support&lt;/li&gt;\n&lt;li&gt;Gender-Affirming Care&lt;/li&gt;\n&lt;li&gt;Mental Health &amp;amp; Coaching Benefits&lt;/li&gt;\n&lt;li&gt;Flexible Vacation &amp;amp; Paid Volunteer Time Off&lt;/li&gt;\n&lt;li&gt;Generous Paid Parental Leave &amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div&gt;\n&lt;p&gt;&lt;span style=&quot;color: rgb(255, 255, 255);&quot; data-sheets-root=&quot;1&quot;&gt;#LI-JS1 #LI-onsite&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;&lt;strong&gt;Pay Transparency:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;This job posting may span more than one career level.&lt;/p&gt;\n&lt;p&gt;In addition to base salary, this job is eligible to receive equity in the form of restricted stock units, and will also be eligible to receive a commission. Additionally, Reddit offers a wide range of benefits to U.S.-based employees, including medical, dental, and vision insurance, 401(k) program with employer match, generous time off for vacation, and parental leave. To learn more, please visit &lt;a href=&quot;https://www.redditinc.com/careers/&quot; target=&quot;_blank&quot;&gt;https://www.redditinc.com/careers/&lt;/a&gt;.&lt;/p&gt;\n&lt;p&gt;To provide greater transparency to candidates, we share base pay ranges for all US-based job postings regardless of state. We set standard base pay ranges for all roles based on function, level, and country location, benchmarked against similar stage growth companies. Final offer amounts are determined by multiple factors including, skills, depth of work experience and relevant licenses/credentials, and may vary from the amounts listed below.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;The base pay range for this position is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$124,700&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$199,100 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;p&gt;In select roles and locations, the interviews will be recorded, transcribed and summarized by artificial intelligence (AI). You will have the opportunity to opt out of recording, transcription and summarization prior to any scheduled interviews.&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;During the interview, we will collect the following categories of personal information: Identifiers, Professional and Employment-Related Information, Sensory Information (audio/video recording), and any other categories of personal information you choose to share with us. We will use this information to evaluate your application for employment or an independent contractor role, as applicable.&amp;nbsp; We will not sell your personal information or disclose it to any third party for their marketing purposes.&amp;nbsp; We will delete any recording of your interview promptly after making a hiring decision.&amp;nbsp; For more information about how we will handle your personal information, including our retention of it, please refer to our &lt;a href=&quot;https://redditinc.com/policies/candidate-privacy-policy&quot;&gt;Candidate Privacy Policy for Potential Employees and Contractors&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Reddit is proud to be an equal opportunity employer, and is committed to building a workforce representative of the diverse communities we serve.&amp;nbsp; Reddit is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If, due to a disability, you need an accommodation during the interview process, please let your recruiter know.&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7367778
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Software Engineer, Accelerator Build Infrastructure",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4943668008",
    "job_posted_at_datetime_utc": "2026-01-09T20:32:53-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role A systems-level engineer specializing in build infrastructure and low-level systems optimization, with expertise in maintaining and improving non-trivial C/C++ builds and other host level systems. This role requires deep technical knowledge of compilation processes, hardware-software interfaces, build systems, and the ability to debug and optimize at the system level. Responsibilities: Build Systems & Toolchains Expert-level proficiency with build/packaging systems (Nix, pip, uv, CMake, Bazel, Make, etc…) Nix experience in particular is a huge plus Experience managing complex builds and interacting in non-trivial ways with CI Skilled in diagnosing and resolving linking issues, symbol resolution problems, and toolchain/ABI incompatibilities Low-Level Systems/Embedded Programming Strong C/C++ debugging skills, especially nice if in embedded systems or in dealing with cross compiling/linking Comfortable with system calls, POSIX APIs, and kernel interfaces Experience with toolchain debugging tools like readelf, bloaty, c++filt, nm, etc… Compiler & Toolchain Experience Basic knowledge of compilers (understanding things like passes, having multiples levels of IR, what kinds of operations are done on it, etc…) Experience with cross-compilers (compiling code for target devices) Experience with detailed compiler flags optimization and custom toolchain configuration Understanding of linking processes, object file formats (ELF, DWARF), and ABI compatibility Strong candidates may have: Machine Learning Infrastructure Basic understanding of deep learning frameworks (PyTorch, Jax) from a systems perspective Understanding of tensor operations Experience with distributed training infrastructure is a plus You may be a good fit if you have: 5+ years of experience in systems programming or infrastructure roles Often comes from backgrounds in: HPC, game engine development, embedded systems, OS, or compiler teams Strong debugging mindset with patience for complex, multi-layered issues Self-directed problem solver who can navigate large, legacy codebases This profile would be ideal for roles in ML infrastructure teams, HPC environments, or any organization dealing with non-trivial C/C++ systems that need optimization at the build and runtime level. Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$315,000 - $405,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4943668008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4943668008",
    "title": "Software Engineer, Accelerator Build Infrastructure",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | Seattle, WA",
    "locations": [
      "San Francisco, CA | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4943668008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:32:53-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;A systems-level engineer specializing in build infrastructure and low-level systems optimization, with expertise in maintaining and improving non-trivial C/C++ builds and other host level systems. This role requires deep technical knowledge of compilation processes, hardware-software interfaces, build systems, and the ability to debug and optimize at the system level.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Build Systems &amp;amp; Toolchains&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Expert-level proficiency with build/packaging systems (Nix, pip, uv, CMake, Bazel, Make, etc…)&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Nix experience in particular is a huge plus&lt;/li&gt;\n&lt;li&gt;Experience managing complex builds and interacting in non-trivial ways with CI&lt;/li&gt;\n&lt;li&gt;Skilled in diagnosing and resolving linking issues, symbol resolution problems, and toolchain/ABI incompatibilities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Low-Level Systems/Embedded Programming&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Strong C/C++ debugging skills, especially nice if in embedded systems or in dealing with cross compiling/linking&lt;/li&gt;\n&lt;li&gt;Comfortable with system calls, POSIX APIs, and kernel interfaces&lt;/li&gt;\n&lt;li&gt;Experience with toolchain debugging tools like readelf, bloaty, c++filt, nm, etc…&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Compiler &amp;amp; Toolchain Experience&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Basic knowledge of compilers (understanding things like passes, having multiples levels of IR, what kinds of operations are done on it, etc…)&lt;/li&gt;\n&lt;li&gt;Experience with cross-compilers (compiling code for target devices)&lt;/li&gt;\n&lt;li&gt;Experience with detailed compiler flags optimization and custom toolchain configuration&lt;/li&gt;\n&lt;li&gt;Understanding of linking processes, object file formats (ELF, DWARF), and ABI compatibility&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may have:&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Machine Learning Infrastructure&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Basic understanding of deep learning frameworks (PyTorch, Jax) from a systems perspective&lt;/li&gt;\n&lt;li&gt;Understanding of tensor operations&lt;/li&gt;\n&lt;li&gt;Experience with distributed training infrastructure is a plus&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&amp;nbsp;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of experience in systems programming or infrastructure roles&lt;/li&gt;\n&lt;li&gt;Often comes from backgrounds in: HPC, game engine development, embedded systems, OS, or compiler teams&lt;/li&gt;\n&lt;li&gt;Strong debugging mindset with patience for complex, multi-layered issues&lt;/li&gt;\n&lt;li&gt;Self-directed problem solver who can navigate large, legacy codebases&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;This profile would be ideal for roles in ML infrastructure teams, HPC environments, or any organization dealing with non-trivial C/C++ systems that need optimization at the build and runtime level.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$315,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$405,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4943668008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": " Research Engineer / Research Scientist, Tokens",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; New York City, NY | Seattle, WA; San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4951814008",
    "job_posted_at_datetime_utc": "2026-01-09T20:31:16-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.You want to build large scale ML systems from the ground up. You care about making safe, steerable, trustworthy systems. As a Research Engineer, you'll touch all parts of our code and infrastructure, whether that's making the cluster more reliable for our big jobs, improving throughput and efficiency, running and designing scientific experiments, or improving our dev tooling. You're excited to write code when you understand the research context and more broadly why it's important. Note: This is an \"evergreen\" role that we keep open on an ongoing basis. We receive many applications for this position, and you may not hear back from us directly if we do not currently have an open role on any of our teams that matches your skills and experience. We encourage you to apply despite this, as we are continually evaluating for top talent to join our team. You are also welcome to reapply as you gain more experience, but we suggest only reapplying once per year. We may also put up separate, team-specific job postings. In those cases, the teams will give preference to candidates who apply to the team-specific postings, so if you are interested in a specific team please make sure to check for team-specific job postings! You may be a good fit if you: Have significant software engineering experience Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large-scale ML systems GPUs, Kubernetes, Pytorch, or OS internals Language modeling with transformers Reinforcement learning Large-scale ETL Representative projects: Optimizing the throughput of a new attention mechanism Comparing the compute efficiency of two Transformer variants Making a Wikipedia dataset in a format models can easily consume Scaling a distributed training job to thousands of GPUs Writing a design doc for fault tolerance strategies Creating an interactive visualization of attention between tokens in a language model The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$340,000 - $425,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4951814008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4951814008",
    "title": " Research Engineer / Research Scientist, Tokens",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; New York City, NY | Seattle, WA; San Francisco, CA",
    "locations": [
      "New York City, NY; New York City, NY | Seattle, WA; San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4951814008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:31:16-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;You want to build large scale ML systems from the ground up. You care about making safe, steerable, trustworthy systems. As a Research Engineer, you&#39;ll touch all parts of our code and infrastructure, whether that&#39;s making the cluster more reliable for our big jobs, improving throughput and efficiency, running and designing scientific experiments, or improving our dev tooling. You&#39;re excited to write code when you understand the research context and more broadly why it&#39;s important.&lt;/div&gt;\n&lt;div&gt;&amp;nbsp;&lt;/div&gt;\n&lt;div&gt;&lt;em&gt;Note: This is an &quot;evergreen&quot; role that we keep open on an ongoing basis. We receive many applications for this position, and you may not hear back from us directly if we do not currently have an open role on any of our teams that matches your skills and experience. We encourage you to apply despite this, as we are continually evaluating for top talent to join our team. You are also welcome to reapply as you gain more experience, but we suggest only reapplying once per year.&lt;/em&gt;&lt;/div&gt;\n&lt;div&gt;&amp;nbsp;&lt;/div&gt;\n&lt;div&gt;&lt;em&gt;We may also put up separate, team-specific&amp;nbsp;&lt;/em&gt;&lt;a class=&quot;postings-link&quot; href=&quot;https://www.anthropic.com/jobs&quot;&gt;&lt;em&gt;job postings&lt;/em&gt;&lt;/a&gt;&lt;em&gt;. In those cases, the teams will give preference to candidates who apply to the team-specific postings, so if you are interested in a specific team please make sure to check for team-specific job postings!&lt;/em&gt;&lt;/div&gt;\n&lt;div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant software engineering experience&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Want to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;High performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;GPUs, Kubernetes, Pytorch, or OS internals&lt;/li&gt;\n&lt;li&gt;Language modeling with transformers&lt;/li&gt;\n&lt;li&gt;Reinforcement learning&lt;/li&gt;\n&lt;li&gt;Large-scale ETL&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Optimizing the throughput of a new attention mechanism&lt;/li&gt;\n&lt;li&gt;Comparing the compute efficiency of two Transformer variants&lt;/li&gt;\n&lt;li&gt;Making a Wikipedia dataset in a format models can easily consume&lt;/li&gt;\n&lt;li&gt;Scaling a distributed training job to thousands of GPUs&lt;/li&gt;\n&lt;li&gt;Writing a design doc for fault tolerance strategies&lt;/li&gt;\n&lt;li&gt;Creating an interactive visualization of attention between tokens in a language model&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$340,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$425,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4951814008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Engineering Manager, ML Acceleration",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4741104008",
    "job_posted_at_datetime_utc": "2026-01-09T20:28:42-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: Anthropic’s performance and scaling teams focus on making the most efficient and impactful use of our compute resources, be it inference or training. As an Engineering Manager on these teams you will be responsible for ensuring you and your team are identifying and removing bottlenecks, building robust and durable solutions, and maximizing the efficiency of our systems. You also will help bring clarity, focus, and context to your teams in a fast paced, dynamic environment. Responsibilities: Provide front-line leadership of engineering efforts to improve model performance and scale our inference and training systems Become familiar with the team’s technical stack enough to make targeted contributions as an individual contributor Manage day-to-day execution of the team's work Prioritize the team’s work and manage projects in a highly dynamic, fast paced environment Coach and support your reports in understanding, and pursuing, their professional growth Maintain a deep understanding of the team's technical work and its implications for AI safety You may be a good fit if you: Have 1+ years of management experience in a technical environment, particularly performance or distributed systems Have a background in machine learning, AI, or a similar related technical field Are deeply interested in the potential transformative effects of advanced AI systems and are committed to ensuring their safe development Excel at building strong relationships with stakeholders at all levels Are a quick learner, capable of understanding and contributing to discussions on complex technical topics Have experience managing teams through periods of rapid growth and change Are a quick study: this team sits at the intersection of a large number of different complex technical systems that you’ll need to understand (at a high level of abstraction) to be effective Strong candidates may also have experience with: High performance, large-scale ML systems GPU/Accelerator programming ML framework internals OS internals Language modeling with transformers The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$425,000 - $560,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4741104008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4741104008",
    "title": "Engineering Manager, ML Acceleration",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4741104008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:28:42-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;Anthropic’s performance and scaling teams focus on making the most efficient and impactful use of our compute resources, be it inference or training.&amp;nbsp; As an Engineering Manager on these teams you will be responsible for ensuring you and your team are identifying and removing bottlenecks, building robust and durable solutions, and maximizing the efficiency of our systems.&amp;nbsp; You also will help bring clarity, focus, and context to your teams in a fast paced, dynamic environment.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;Responsibilities:&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Provide front-line leadership of engineering efforts to improve model performance and scale our inference and training systems&lt;/li&gt;\n&lt;li&gt;Become familiar with the team’s technical stack enough to make targeted contributions as an individual contributor&lt;/li&gt;\n&lt;li&gt;Manage day-to-day execution of the team&#39;s work&lt;/li&gt;\n&lt;li&gt;Prioritize the team’s work and manage projects in a highly dynamic, fast paced environment&lt;/li&gt;\n&lt;li&gt;Coach and support your reports in understanding, and pursuing, their professional growth&lt;/li&gt;\n&lt;li&gt;Maintain a deep understanding of the team&#39;s technical work and its implications for AI safety&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;You may be a good fit if you:&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 1+ years of management experience in a technical environment, particularly performance or distributed systems&lt;/li&gt;\n&lt;li&gt;Have a background in machine learning, AI, or a similar related technical field&lt;/li&gt;\n&lt;li&gt;Are deeply interested in the potential transformative effects of advanced AI systems and are committed to ensuring their safe development&lt;/li&gt;\n&lt;li&gt;Excel at building strong relationships with stakeholders at all levels&lt;/li&gt;\n&lt;li&gt;Are a quick learner, capable of understanding and contributing to discussions on complex technical topics&lt;/li&gt;\n&lt;li&gt;Have experience managing teams through periods of rapid growth and change&lt;/li&gt;\n&lt;li&gt;Are a quick study: this team sits at the intersection of a large number of different complex technical systems that you’ll need to understand (at a high level of abstraction) to be effective&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;Strong candidates may also have experience with:&amp;nbsp;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;High performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;GPU/Accelerator programming&lt;/li&gt;\n&lt;li&gt;ML framework internals&lt;/li&gt;\n&lt;li&gt;OS internals&lt;/li&gt;\n&lt;li&gt;Language modeling with transformers&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$425,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$560,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4741104008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Senior Research Scientist, Reward Models",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel Required) | San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5024835008",
    "job_posted_at_datetime_utc": "2026-01-09T20:27:23-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Senior Research Scientist on our Reward Models team, you'll lead research efforts to improve how we specify and learn human preferences at scale. Your work will directly shape how our models understand and optimize for what humans actually want — enabling Claude to be more useful, more reliable, and better aligned with human values. This role focuses on pushing the frontier of reward modeling for large language models. You'll develop novel architectures and training methodologies for RLHF, research new approaches to LLM-based evaluation and grading (including rubric-based methods), and investigate techniques to identify and mitigate reward hacking. You'll collaborate closely with teams across Anthropic, including Finetuning, Alignment Science, and our broader research organization, to ensure your work translates into concrete improvements in both model capabilities and safety. We're looking for someone who can drive ambitious research agendas while also shipping practical improvements to production systems. You'll have the opportunity to work on some of the most important open problems in AI alignment, with access to frontier models and significant computational resources. Your work will directly advance the science of how we train AI systems to be both highly capable and safe. Note: For this role, we conduct all interviews in Python. Responsibilities Lead research on novel reward model architectures and training approaches for RLHF Develop and evaluate LLM-based grading and evaluation methods, including rubric-driven approaches that improve consistency and interpretability Research techniques to detect, characterize, and mitigate reward hacking and specification gaming Design experiments to understand reward model generalization, robustness, and failure modes Collaborate with the Finetuning team to translate research insights into improvements for production training pipelines Contribute to research publications, blog posts, and internal documentation Mentor other researchers and help build institutional knowledge around reward modeling You may be a good fit if you Have a track record of research contributions in reward modeling, RLHF, or closely related areas of machine learning Have experience training and evaluating reward models for large language models Are comfortable designing and running large-scale experiments with significant computational resources Can work effectively across research and engineering, iterating quickly while maintaining scientific rigor Enjoy collaborative research and can communicate complex ideas clearly to diverse audiences Care deeply about building AI systems that are both highly capable and safe Strong candidates may also Have published research on reward modeling, preference learning, or RLHF Have experience with LLM-as-judge approaches, including calibration and reliability challenges Have worked on reward hacking, specification gaming, or related robustness problems Have experience with constitutional AI, debate, or other scalable oversight approaches Have contributed to production ML systems at scale Have familiarity with interpretability techniques as applied to understanding reward model behavior The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$340,000 - $425,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5024835008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5024835008",
    "title": "Senior Research Scientist, Reward Models",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel Required) | San Francisco, CA",
    "locations": [
      "Remote-Friendly (Travel Required) | San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5024835008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:27:23-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Senior Research Scientist on our Reward Models team, you&#39;ll lead research efforts to improve how we specify and learn human preferences at scale. Your work will directly shape how our models understand and optimize for what humans actually want — enabling Claude to be more useful, more reliable, and better aligned with human values.&lt;/p&gt;\n&lt;p&gt;This role focuses on pushing the frontier of reward modeling for large language models. You&#39;ll develop novel architectures and training methodologies for RLHF, research new approaches to LLM-based evaluation and grading (including rubric-based methods), and investigate techniques to identify and mitigate reward hacking. You&#39;ll collaborate closely with teams across Anthropic, including Finetuning, Alignment Science, and our broader research organization, to ensure your work translates into concrete improvements in both model capabilities and safety.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;We&#39;re looking for someone who can drive ambitious research agendas while also shipping practical improvements to production systems. You&#39;ll have the opportunity to work on some of the most important open problems in AI alignment, with access to frontier models and significant computational resources. Your work will directly advance the science of how we train AI systems to be both highly capable and safe.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead research on novel reward model architectures and training approaches for RLHF&lt;/li&gt;\n&lt;li&gt;Develop and evaluate LLM-based grading and evaluation methods, including rubric-driven approaches that improve consistency and interpretability&lt;/li&gt;\n&lt;li&gt;Research techniques to detect, characterize, and mitigate reward hacking and specification gaming&lt;/li&gt;\n&lt;li&gt;Design experiments to understand reward model generalization, robustness, and failure modes&lt;/li&gt;\n&lt;li&gt;Collaborate with the Finetuning team to translate research insights into improvements for production training pipelines&lt;/li&gt;\n&lt;li&gt;Contribute to research publications, blog posts, and internal documentation&lt;/li&gt;\n&lt;li&gt;Mentor other researchers and help build institutional knowledge around reward modeling&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have a track record of research contributions in reward modeling, RLHF, or closely related areas of machine learning&lt;/li&gt;\n&lt;li&gt;Have experience training and evaluating reward models for large language models&lt;/li&gt;\n&lt;li&gt;Are comfortable designing and running large-scale experiments with significant computational resources&lt;/li&gt;\n&lt;li&gt;Can work effectively across research and engineering, iterating quickly while maintaining scientific rigor&lt;/li&gt;\n&lt;li&gt;Enjoy collaborative research and can communicate complex ideas clearly to diverse audiences&lt;/li&gt;\n&lt;li&gt;Care deeply about building AI systems that are both highly capable and safe&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have published research on reward modeling, preference learning, or RLHF&lt;/li&gt;\n&lt;li&gt;Have experience with LLM-as-judge approaches, including calibration and reliability challenges&lt;/li&gt;\n&lt;li&gt;Have worked on reward hacking, specification gaming, or related robustness problems&lt;/li&gt;\n&lt;li&gt;Have experience with constitutional AI, debate, or other scalable oversight approaches&lt;/li&gt;\n&lt;li&gt;Have contributed to production ML systems at scale&lt;/li&gt;\n&lt;li&gt;Have familiarity with interpretability techniques as applied to understanding reward model behavior&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$340,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$425,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5024835008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Staff Infrastructure Engineer, Pre-training",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4973067008",
    "job_posted_at_datetime_utc": "2026-01-09T20:27:04-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking Staff level Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems. Responsibilities Design and implement high-performance data processing infrastructure for large language model training Develop and maintain core processing primitives (e.g., tokenization, deduplication, chunking) with a focus on scalability Build robust systems for data quality assurance and validation at scale Implement comprehensive monitoring systems for data processing infrastructure Create and optimize distributed computing systems for processing web-scale datasets Collaborate with research teams to implement novel data processing architectures Build and maintain documentation for infrastructure components and systems Design and implement systems for reproducibility and traceability in data preparation You may be a good fit if you have: 7+ YOE outside of internships Strong software engineering skills with experience in building distributed systems Expertise in Python and Rust Hands-on experience with distributed computing frameworks, particularly Apache Spark Deep understanding of cloud computing platforms and distributed systems architecture Experience with high-throughput, fault-tolerant system design Strong background in performance optimization and system scaling Excellent problem-solving skills and attention to detail Strong communication skills and ability to work in a collaborative environment Advanced degree in Computer Science or related field Experience with language model training infrastructure Strong background in distributed systems and parallel computing Expertise in tokenization algorithms and techniques Experience building high-throughput, fault-tolerant systems Deep knowledge of monitoring and observability practices Experience with infrastructure-as-code and configuration management Background in MLOps or ML infrastructure Strong candidates may have: Have significant experience building and maintaining large-scale distributed systems Are passionate about system reliability and performance Enjoy solving complex technical challenges at scale Are comfortable working with ambiguous requirements and evolving specifications Take ownership of problems and drive solutions independently Are excited about contributing to the development of safe and ethical AI systems Can balance technical excellence with practical delivery Are eager to learn about machine learning research and its infrastructure requirements Sample Projects Designing and implementing distributed computing architecture for web-scale data processing Building scalable infrastructure for model training data preparation Creating comprehensive monitoring and alerting systems Optimizing tokenization infrastructure for improved throughput Developing fault-tolerant distributed processing systems Implementing new infrastructure components based on research requirements Building automated testing frameworks for distributed systems The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$340,000 - $425,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4973067008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4973067008",
    "title": "Staff Infrastructure Engineer, Pre-training",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4973067008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:27:04-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the Role&lt;/h2&gt;\n&lt;p&gt;Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking Staff level Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Responsibilities&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement high-performance data processing infrastructure for large language model training&lt;/li&gt;\n&lt;li&gt;Develop and maintain core processing primitives (e.g., tokenization, deduplication, chunking) with a focus on scalability&lt;/li&gt;\n&lt;li&gt;Build robust systems for data quality assurance and validation at scale&lt;/li&gt;\n&lt;li&gt;Implement comprehensive monitoring systems for data processing infrastructure&lt;/li&gt;\n&lt;li&gt;Create and optimize distributed computing systems for processing web-scale datasets&lt;/li&gt;\n&lt;li&gt;Collaborate with research teams to implement novel data processing architectures&lt;/li&gt;\n&lt;li&gt;Build and maintain documentation for infrastructure components and systems&lt;/li&gt;\n&lt;li&gt;Design and implement systems for reproducibility and traceability in data preparation&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;7+ YOE outside of internships&lt;/li&gt;\n&lt;li&gt;Strong software engineering skills with experience in building distributed systems&lt;/li&gt;\n&lt;li&gt;Expertise in Python and Rust&lt;/li&gt;\n&lt;li&gt;Hands-on experience with distributed computing frameworks, particularly Apache Spark&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Deep understanding of cloud computing platforms and distributed systems architecture&lt;/li&gt;\n&lt;li&gt;Experience with high-throughput, fault-tolerant system design&lt;/li&gt;\n&lt;li&gt;Strong background in performance optimization and system scaling&lt;/li&gt;\n&lt;li&gt;Excellent problem-solving skills and attention to detail&lt;/li&gt;\n&lt;li&gt;Strong communication skills and ability to work in a collaborative environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;ul&gt;\n&lt;li&gt;Advanced degree in Computer Science or related field&lt;/li&gt;\n&lt;li&gt;Experience with language model training infrastructure&lt;/li&gt;\n&lt;li&gt;Strong background in distributed systems and parallel computing&lt;/li&gt;\n&lt;li&gt;Expertise in tokenization algorithms and techniques&lt;/li&gt;\n&lt;li&gt;Experience building high-throughput, fault-tolerant systems&lt;/li&gt;\n&lt;li&gt;Deep knowledge of monitoring and observability practices&lt;/li&gt;\n&lt;li&gt;Experience with infrastructure-as-code and configuration management&lt;/li&gt;\n&lt;li&gt;Background in MLOps or ML infrastructure&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 data-pm-slice=&quot;1 1 [&amp;quot;checkbox_list&amp;quot;,{},&amp;quot;checkbox_item&amp;quot;,{&amp;quot;checked&amp;quot;:false},&amp;quot;bullet_list&amp;quot;,{},&amp;quot;list_item&amp;quot;,{}]&quot;&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant experience building and maintaining large-scale distributed systems&lt;/li&gt;\n&lt;li&gt;Are passionate about system reliability and performance&lt;/li&gt;\n&lt;li&gt;Enjoy solving complex technical challenges at scale&lt;/li&gt;\n&lt;li&gt;Are comfortable working with ambiguous requirements and evolving specifications&lt;/li&gt;\n&lt;li&gt;Take ownership of problems and drive solutions independently&lt;/li&gt;\n&lt;li&gt;Are excited about contributing to the development of safe and ethical AI systems&lt;/li&gt;\n&lt;li&gt;Can balance technical excellence with practical delivery&lt;/li&gt;\n&lt;li&gt;Are eager to learn about machine learning research and its infrastructure requirements&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 class=&quot;heading&quot;&gt;Sample Projects&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Designing and implementing distributed computing architecture for web-scale data processing&lt;/li&gt;\n&lt;li&gt;Building scalable infrastructure for model training data preparation&lt;/li&gt;\n&lt;li&gt;Creating comprehensive monitoring and alerting systems&lt;/li&gt;\n&lt;li&gt;Optimizing tokenization infrastructure for improved throughput&lt;/li&gt;\n&lt;li&gt;Developing fault-tolerant distributed processing systems&lt;/li&gt;\n&lt;li&gt;Implementing new infrastructure components based on research requirements&lt;/li&gt;\n&lt;li&gt;Building automated testing frameworks for distributed systems&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$340,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$425,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4973067008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Reward Models Platform",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5024831008",
    "job_posted_at_datetime_utc": "2026-01-09T20:26:23-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role You will deeply understand the research workflows of our Finetuning teams and automate the high-friction parts – turning days of manual experimentation into hours. You’ll build the tools and infrastructure that enable researchers across the organization to develop, evaluate, and optimize reward signals for training our models. Your scalable platforms will make it easy to experiment with different reward methodologies, assess their robustness, and iterate rapidly on improvements to help the rest of Anthropic train our reward models. This is a role for someone who wants to stay close to the science while having outsized leverage. You'll partner directly with researchers on the Rewards team and across the broader Fine-Tuning organization to understand what slows them down: running human data experiments before adding to preference models, debugging reward hacks, comparing rubric methodologies across domains. Then you'll build the systems that make those workflows 10x faster. When you have bandwidth, you'll contribute directly to research projects yourself. Your work will directly impact our ability to scale reward development across domains, from crafting and evaluating rubrics to understanding the effects of human feedback data to detecting and mitigating reward hacks. We're looking for someone who combines strong engineering fundamentals with research experience – someone who can scope ambiguous problems, ship quickly, and cares as much about the science as the systems. Note: For this role, we conduct all interviews in Python. Responsibilities Design and build infrastructure that enables researchers to rapidly iterate on reward signals, including tools for rubric development, human feedback data analysis, and reward robustness evaluation Develop systems for automated quality assessment of rewards, including detection of reward hacks and other pathologies Create tooling that allows researchers to easily compare different reward methodologies (preference models, rubrics, programmatic rewards) and understand their effects Build pipelines and workflows that reduce toil in reward development, from dataset preparation to evaluation to deployment Implement monitoring and observability systems to track reward signal quality and surface issues during training runs Collaborate with researchers to translate science requirements into platform capabilities Optimize existing systems for performance, reliability, and ease of use Contribute to the development of best practices and documentation for reward development workflows You may be a good fit if you Have prior research experience Are excited to work closely with researchers and translate ambiguous requirements into well-scoped engineering projects Have strong Python skills Have experience with ML workflows and data pipelines, and building related infrastructure/tooling/platforms Are comfortable working across the stack, ranging from data pipelines to experiment tracking to user-facing tooling Can balance building robust, maintainable systems with the need to move quickly in a research environment Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Care about the societal impacts of your work and are motivated by Anthropic's mission to develop safe AI Strong candidates may also have experience with Experience with ML research Building internal tooling and platforms for ML researchers Data quality assessment and pipeline optimization Experiment tracking, evaluation frameworks, or MLOps tooling Large-scale data processing (e.g., Spark, Hive, or similar) Kubernetes, distributed systems, or cloud infrastructure Familiarity with reinforcement learning or fine-tuning workflows Representative projects Building infrastructure that allows researchers to rapidly test new rubric designs against small models before scaling up Developing automated systems to detect reward hacks and surface problematic behaviors during training Creating tooling for comparing different grading methodologies and understanding their effects on model behavior Building a data quality flywheel that helps researchers identify problematic transcripts and feed improvements back into the system Developing dashboards and monitoring systems that give researchers visibility into reward signal quality across training runs Streamlining dataset preparation workflows to reduce latency and operational overhead The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$315,000 - $340,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-5024831008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5024831008",
    "title": "Research Engineer, Reward Models Platform",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5024831008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:26:23-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;You will deeply understand the research workflows of our Finetuning teams and automate the high-friction parts – turning days of manual experimentation into hours. You’ll build the tools and infrastructure that enable researchers across the organization to develop, evaluate, and optimize reward signals for training our models. Your scalable platforms will make it easy to experiment with different reward methodologies, assess their robustness, and iterate rapidly on improvements to help the rest of Anthropic train our reward models.&lt;/p&gt;\n&lt;p&gt;This is a role for someone who wants to stay close to the science while having outsized leverage. You&#39;ll partner directly with researchers on the Rewards team and across the broader Fine-Tuning organization to understand what slows them down: running human data experiments before adding to preference models, debugging reward hacks, comparing rubric methodologies across domains. Then you&#39;ll build the systems that make those workflows 10x faster. When you have bandwidth, you&#39;ll contribute directly to research projects yourself. Your work will directly impact our ability to scale reward development across domains, from crafting and evaluating rubrics to understanding the effects of human feedback data to detecting and mitigating reward hacks.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;We&#39;re looking for someone who combines strong engineering fundamentals with research experience – someone who can scope ambiguous problems, ship quickly, and cares as much about the science as the systems.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and build infrastructure that enables researchers to rapidly iterate on reward signals, including tools for rubric development, human feedback data analysis, and reward robustness evaluation&lt;/li&gt;\n&lt;li&gt;Develop systems for automated quality assessment of rewards, including detection of reward hacks and other pathologies&lt;/li&gt;\n&lt;li&gt;Create tooling that allows researchers to easily compare different reward methodologies (preference models, rubrics, programmatic rewards) and understand their effects&lt;/li&gt;\n&lt;li&gt;Build pipelines and workflows that reduce toil in reward development, from dataset preparation to evaluation to deployment&lt;/li&gt;\n&lt;li&gt;Implement monitoring and observability systems to track reward signal quality and surface issues during training runs&lt;/li&gt;\n&lt;li&gt;Collaborate with researchers to translate science requirements into platform capabilities&lt;/li&gt;\n&lt;li&gt;Optimize existing systems for performance, reliability, and ease of use&lt;/li&gt;\n&lt;li&gt;Contribute to the development of best practices and documentation for reward development workflows&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have prior research experience&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Are excited to work closely with researchers and translate ambiguous requirements into well-scoped engineering projects&lt;/li&gt;\n&lt;li&gt;Have strong Python skills&lt;/li&gt;\n&lt;li&gt;Have experience with ML workflows and data pipelines, and building related infrastructure/tooling/platforms&lt;/li&gt;\n&lt;li&gt;Are comfortable working across the stack, ranging from data pipelines to experiment tracking to user-facing tooling&lt;/li&gt;\n&lt;li&gt;Can balance building robust, maintainable systems with the need to move quickly in a research environment&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work and are motivated by Anthropic&#39;s mission to develop safe AI&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have experience with&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with ML research&lt;/li&gt;\n&lt;li&gt;Building internal tooling and platforms for ML researchers&lt;/li&gt;\n&lt;li&gt;Data quality assessment and pipeline optimization&lt;/li&gt;\n&lt;li&gt;Experiment tracking, evaluation frameworks, or MLOps tooling&lt;/li&gt;\n&lt;li&gt;Large-scale data processing (e.g., Spark, Hive, or similar)&lt;/li&gt;\n&lt;li&gt;Kubernetes, distributed systems, or cloud infrastructure&lt;/li&gt;\n&lt;li&gt;Familiarity with reinforcement learning or fine-tuning workflows&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative projects&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Building infrastructure that allows researchers to rapidly test new rubric designs against small models before scaling up&lt;/li&gt;\n&lt;li&gt;Developing automated systems to detect reward hacks and surface problematic behaviors during training&lt;/li&gt;\n&lt;li&gt;Creating tooling for comparing different grading methodologies and understanding their effects on model behavior&lt;/li&gt;\n&lt;li&gt;Building a data quality flywheel that helps researchers identify problematic transcripts and feed improvements back into the system&lt;/li&gt;\n&lt;li&gt;Developing dashboards and monitoring systems that give researchers visibility into reward signal quality across training runs&lt;/li&gt;\n&lt;li&gt;Streamlining dataset preparation workflows to reduce latency and operational overhead&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$315,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$340,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5024831008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Pre-training",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4616971008",
    "job_posted_at_datetime_utc": "2026-01-09T20:26:17-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems. Key Responsibilities: Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development Independently lead small research projects while collaborating with team members on larger initiatives Design, run, and analyze scientific experiments to advance our understanding of large language models Optimize and scale our training infrastructure to improve efficiency and reliability Develop and improve dev tooling to enhance team productivity Contribute to the entire stack, from low-level optimizations to high-level model design Qualifications: Advanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field Strong software engineering skills with a proven track record of building complex systems Expertise in Python and experience with deep learning frameworks (PyTorch preferred) Familiarity with large-scale machine learning, particularly in the context of language models Ability to balance research goals with practical engineering constraints Strong problem-solving skills and a results-oriented mindset Excellent communication skills and ability to work in a collaborative environment Care about the societal impacts of your work Preferred Experience: Work on high-performance, large-scale ML systems Familiarity with GPUs, Kubernetes, and OS internals Experience with language modeling using transformer architectures Knowledge of reinforcement learning techniques Background in large-scale ETL processes You'll thrive in this role if you: Have significant software engineering experience Are results-oriented with a bias towards flexibility and impact Willingly take on tasks outside your job description to support the team Enjoy pair programming and collaborative work Are eager to learn more about machine learning research Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects Are working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research View research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights Have ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term. Sample Projects: Optimizing the throughput of novel attention mechanisms Comparing compute efficiency of different Transformer variants Preparing large-scale datasets for efficient model consumption Scaling distributed training jobs to thousands of GPUs Designing fault tolerance strategies for our training infrastructure Creating interactive visualizations of model internals, such as attention patterns At Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech. If you're excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$340,000 - $425,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4616971008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4616971008",
    "title": "Research Engineer, Pre-training",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4616971008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:26:17-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Key Responsibilities:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development&lt;/li&gt;\n&lt;li&gt;Independently lead small research projects while collaborating with team members on larger initiatives&lt;/li&gt;\n&lt;li&gt;Design, run, and analyze scientific experiments to advance our understanding of large language models&lt;/li&gt;\n&lt;li&gt;Optimize and scale our training infrastructure to improve efficiency and reliability&lt;/li&gt;\n&lt;li&gt;Develop and improve dev tooling to enhance team productivity&lt;/li&gt;\n&lt;li&gt;Contribute to the entire stack, from low-level optimizations to high-level model design&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Qualifications:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Advanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field&lt;/li&gt;\n&lt;li&gt;Strong software engineering skills with a proven track record of building complex systems&lt;/li&gt;\n&lt;li&gt;Expertise in Python and experience with deep learning frameworks (PyTorch preferred)&lt;/li&gt;\n&lt;li&gt;Familiarity with large-scale machine learning, particularly in the context of language models&lt;/li&gt;\n&lt;li&gt;Ability to balance research goals with practical engineering constraints&lt;/li&gt;\n&lt;li&gt;Strong problem-solving skills and a results-oriented mindset&lt;/li&gt;\n&lt;li&gt;Excellent communication skills and ability to work in a collaborative environment&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Preferred Experience:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Work on high-performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;Familiarity with GPUs, Kubernetes, and OS internals&lt;/li&gt;\n&lt;li&gt;Experience with language modeling using transformer architectures&lt;/li&gt;\n&lt;li&gt;Knowledge of reinforcement learning techniques&lt;/li&gt;\n&lt;li&gt;Background in large-scale ETL processes&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;You&#39;ll thrive in this role if you:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant software engineering experience&lt;/li&gt;\n&lt;li&gt;Are results-oriented with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Willingly take on tasks outside your job description to support the team&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming and collaborative work&lt;/li&gt;\n&lt;li&gt;Are eager to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects&lt;/li&gt;\n&lt;li&gt;Are working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research&lt;/li&gt;\n&lt;li&gt;View research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights&lt;/li&gt;\n&lt;li&gt;Have ambitious goals for AI safety and general progress in the next few years, and you’re working to create the best outcomes over the long-term.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Sample Projects:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Optimizing the throughput of novel attention mechanisms&lt;/li&gt;\n&lt;li&gt;Comparing compute efficiency of different Transformer variants&lt;/li&gt;\n&lt;li&gt;Preparing large-scale datasets for efficient model consumption&lt;/li&gt;\n&lt;li&gt;Scaling distributed training jobs to thousands of GPUs&lt;/li&gt;\n&lt;li&gt;Designing fault tolerance strategies for our training infrastructure&lt;/li&gt;\n&lt;li&gt;Creating interactive visualizations of model internals, such as attention patterns&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;At Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech.&lt;/p&gt;\n&lt;p&gt;If you&#39;re excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$340,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$425,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4616971008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Discovery",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4669581008",
    "job_posted_at_datetime_utc": "2026-01-09T20:25:40-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Team Our team is organized around the north star goal of building an AI scientist – a system capable of solving the long term reasoning challenges and basic capabilities necessary to push the scientific frontier. About the role As a Research Engineer on our team you will work end to end across the whole model stack, identifying and addressing key infra blockers on the path to scientific AGI. Strong candidates should have familiarity with elements of language model training, evaluation, and inference and eagerness to quickly dive and get up to speed in areas they are not yet an expert on. This may include performance optimization, distributed systems, VM/sandboxing/container deployment, and large scale data pipelines. Join us in our mission to develop advanced AI systems pushing the frontiers of science and benefiting humanity. Responsibilities: Design and implement large-scale infrastructure systems to support AI scientist training, evaluation, and deployment across distributed environments Identify and resolve infrastructure bottlenecks impeding progress toward scientific capabilities Develop robust and reliable evaluation frameworks for measuring progress towards scientific AGI. Build scalable and performant VM/sandboxing/container architectures to safely execute long-horizon AI tasks and scientific workflows Collaborate to translate experimental requirements into production-ready infrastructure Develop large scale data pipelines to handle advanced language model training requirements Optimize large scale training and inference pipelines for stable and efficient reinforcement learning You may be a good fit if you: Have 6+ years of highly-relevant experience in infrastructure engineering with demonstrated expertise in large-scale distributed systems Are a strong communicator and enjoy working collaboratively Possess deep knowledge of performance optimization techniques and system architectures for high-throughput ML workloads Have experience with containerization technologies (Docker, Kubernetes) and orchestration at scale Have proven track record of building large-scale data pipelines and distributed storage systems Excel at diagnosing and resolving complex infrastructure challenges in production environments Can work effectively across the full ML stack from data pipelines to performance optimization Have experience collaborating with other researchers to scale experimental ideas Thrive in fast-paced environments and can rapidly iterate from experimentation to production Strong candidates may also have: Experience with language model training infrastructure and distributed ML frameworks (PyTorch, JAX, etc.) Background in building infrastructure for AI research labs or large-scale ML organizations Knowledge of GPU/TPU architectures and language model inference optimization Experience with cloud platforms (AWS, GCP) at enterprise scale Familiarity with VM and container orchestration. Experience with workflow orchestration tools and experiment management systems History working with large scale reinforcement learning Comfort with large scale data pipelines (Beam, Spark, Dask, …) The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$340,000 - $425,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4669581008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4669581008",
    "title": "Research Engineer, Discovery",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4669581008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:25:40-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Team&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Our team is organized around the north star goal of building an AI scientist – a system capable of solving the long term reasoning challenges and basic capabilities necessary to push the scientific frontier.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Research Engineer on our team you will work end to end across the whole model stack, identifying and addressing key infra blockers on the path to scientific AGI. Strong candidates should have familiarity with elements of language model training, evaluation, and inference and eagerness to quickly dive and get up to speed in areas they are not yet an expert on. This may include performance optimization, distributed systems, VM/sandboxing/container deployment, and large scale data pipelines. Join us in our mission to develop advanced AI systems pushing the frontiers of science and benefiting humanity.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement large-scale infrastructure systems to support AI scientist training, evaluation, and deployment across distributed environments&lt;/li&gt;\n&lt;li&gt;Identify and resolve infrastructure bottlenecks impeding progress toward scientific capabilities&lt;/li&gt;\n&lt;li&gt;Develop robust and reliable evaluation frameworks for measuring progress towards scientific AGI.&lt;/li&gt;\n&lt;li&gt;Build scalable and performant VM/sandboxing/container architectures to safely execute long-horizon AI tasks and scientific workflows&lt;/li&gt;\n&lt;li&gt;Collaborate to translate experimental requirements into production-ready infrastructure&lt;/li&gt;\n&lt;li&gt;Develop large scale data pipelines to handle advanced language model training requirements&lt;/li&gt;\n&lt;li&gt;Optimize large scale training and inference pipelines for stable and efficient reinforcement learning&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 6+ years of highly-relevant experience in infrastructure engineering with demonstrated expertise in large-scale distributed systems&lt;/li&gt;\n&lt;li&gt;Are a strong communicator and enjoy working collaboratively&lt;/li&gt;\n&lt;li&gt;Possess deep knowledge of performance optimization techniques and system architectures for high-throughput ML workloads&lt;/li&gt;\n&lt;li&gt;Have experience with containerization technologies (Docker, Kubernetes) and orchestration at scale&lt;/li&gt;\n&lt;li&gt;Have proven track record of building large-scale data pipelines and distributed storage systems&lt;/li&gt;\n&lt;li&gt;Excel at diagnosing and resolving complex infrastructure challenges in production environments&lt;/li&gt;\n&lt;li&gt;Can work effectively across the full ML stack from data pipelines to performance optimization&lt;/li&gt;\n&lt;li&gt;Have experience collaborating with other researchers to scale experimental ideas&lt;/li&gt;\n&lt;li&gt;Thrive in fast-paced environments and can rapidly iterate from experimentation to production&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with language model training infrastructure and distributed ML frameworks (PyTorch, JAX, etc.)&lt;/li&gt;\n&lt;li&gt;Background in building infrastructure for AI research labs or large-scale ML organizations&lt;/li&gt;\n&lt;li&gt;Knowledge of GPU/TPU architectures and&amp;nbsp; language model inference optimization&lt;/li&gt;\n&lt;li&gt;Experience with cloud platforms (AWS, GCP) at enterprise scale&lt;/li&gt;\n&lt;li&gt;Familiarity with VM and container orchestration.&lt;/li&gt;\n&lt;li&gt;Experience with workflow orchestration tools and experiment management systems&lt;/li&gt;\n&lt;li&gt;History working with large scale reinforcement learning&lt;/li&gt;\n&lt;li&gt;Comfort with large scale data pipelines (Beam, Spark, Dask, …)&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$340,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$425,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4669581008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Staff Research Engineer, Discovery Team",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4593216008",
    "job_posted_at_datetime_utc": "2026-01-09T20:24:51-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Team Our team is organized around the north star goal of building an AI scientist – a system capable of solving the long term reasoning challenges and basic capabilities necessary to push the scientific frontier. Our team likes to think across the whole model stack. Currently the team is focused on improving models' abilities to use computers – as a laboratory for long horizon tasks and a key blocker to many scientific workflows. About the role As a Research Engineer on our team you will work end to end, identifying and addressing key blockers on the path to scientific AGI. Strong candidates should have familiarity with language model training, evaluation, and inference, be comfortable triaging research ideas and diagnosing problems and enjoy working collaboratively. Familiarity with performance optimization, distributed systems, vm/sandboxing/container deployment, and large scale data pipelines is highly encouraged. Join us in our mission to develop advanced AI systems that are both powerful and beneficial for humanity. Responsibilities: Working across the full stack to identify and remove bottlenecks preventing progress toward scientific AGI Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery Scaling research ideas from prototype to production Create benchmarks and evaluation frameworks to measure model capabilities in scientific workflows and computer use Implement distributed training systems and performance optimizations to support large-scale model development You may be a good fit if you: Have 8+ years of ML research experience Are familiar with large scale language model training, evaluation, and inference pipelines Enjoy obsessively iterating on immediate blockers towards longterm goals Thrive working collaboratively to solve problems Have expertise in performance optimization and distributed computing systems Show strong problem-solving skills and ability to identify technical bottlenecks in complex systems Can translate research concepts into scalable engineering solutions Have a track record of shipping ML systems that tackle challenging multi-step reasoning problems Strong candidates may also have: Expertise with performance optimization for language model inference and training Experience with computer use automation and agentic AI systems A history working on reinforcement learning approaches for complex task completion Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing) Have experience with VM/sandboxing/container deployment and large-scale data processing Experience working with large scale data problem solving and infrastructure Published research or practical experience in scientific AI applications or long-horizon reasoning The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$340,000 - $425,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "job-boards-greenhouse-io-anthropic-jobs-4593216008",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4593216008",
    "title": "Staff Research Engineer, Discovery Team",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4593216008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-09T20:24:51-05:00",
    "fetched_at": "2026-01-12T18:26:14.167Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Team&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Our team is organized around the north star goal of building an AI scientist – a system capable of solving the long term reasoning challenges and basic capabilities necessary to push the scientific frontier. Our team likes to think across the whole model stack. Currently the team is focused on improving models&#39; abilities to use computers – as a laboratory for long horizon tasks and a key blocker to many scientific workflows.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Research Engineer on our team you will work end to end, identifying and addressing key blockers on the path to scientific AGI. Strong candidates should have familiarity with language model training, evaluation, and inference, be comfortable triaging research ideas and diagnosing problems and enjoy working collaboratively. Familiarity with performance optimization, distributed systems, vm/sandboxing/container deployment, and large scale data pipelines is highly encouraged.&lt;/p&gt;\n&lt;p&gt;Join us in our mission to develop advanced AI systems that are both powerful and beneficial for humanity.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Working across the full stack to identify and remove bottlenecks preventing progress toward scientific AGI&lt;/li&gt;\n&lt;li&gt;Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery&lt;/li&gt;\n&lt;li&gt;Scaling research ideas from prototype to production&lt;/li&gt;\n&lt;li&gt;Create benchmarks and evaluation frameworks to measure model capabilities in scientific workflows and computer use&lt;/li&gt;\n&lt;li&gt;Implement distributed training systems and performance optimizations to support large-scale model development&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 8+ years of ML research experience&lt;/li&gt;\n&lt;li&gt;Are familiar with large scale language model training, evaluation, and inference pipelines&lt;/li&gt;\n&lt;li&gt;Enjoy obsessively iterating on immediate blockers towards longterm goals&lt;/li&gt;\n&lt;li&gt;Thrive working collaboratively to solve problems&lt;/li&gt;\n&lt;li&gt;Have expertise in performance optimization and distributed computing systems&lt;/li&gt;\n&lt;li&gt;Show strong problem-solving skills and ability to identify technical bottlenecks in complex systems&lt;/li&gt;\n&lt;li&gt;Can translate research concepts into scalable engineering solutions&lt;/li&gt;\n&lt;li&gt;Have a track record of shipping ML systems that tackle challenging multi-step reasoning problems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Expertise with performance optimization for language model inference and training&lt;/li&gt;\n&lt;li&gt;Experience with computer use automation and agentic AI systems&lt;/li&gt;\n&lt;li&gt;A history working on reinforcement learning approaches for complex task completion&lt;/li&gt;\n&lt;li&gt;Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing)&lt;/li&gt;\n&lt;li&gt;Have experience with VM/sandboxing/container deployment and large-scale data processing&lt;/li&gt;\n&lt;li&gt;Experience working with large scale data problem solving and infrastructure&lt;/li&gt;\n&lt;li&gt;Published research or practical experience in scientific AI applications or long-horizon reasoning&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$340,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$425,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4593216008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]